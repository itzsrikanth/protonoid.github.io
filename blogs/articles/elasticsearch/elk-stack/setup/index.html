<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1"/><meta name="next-head-count" content="2"/><link rel="preload" href="/_next/static/8Mis-cZ22Xko4dzTOJNkr/pages/articles.js" as="script"/><link rel="preload" href="/_next/static/8Mis-cZ22Xko4dzTOJNkr/pages/_app.js" as="script"/><link rel="preload" href="/_next/static/runtime/webpack-4b444dab214c6491079c.js" as="script"/><link rel="preload" href="/_next/static/chunks/commons.33617edd7b180839ed18.js" as="script"/><link rel="preload" href="/_next/static/chunks/styles.67314864e5ee77300274.js" as="script"/><link rel="preload" href="/_next/static/runtime/main-c2a874049c0d0e609626.js" as="script"/><link rel="stylesheet" href="/_next/static/css/styles.14dc81c0.chunk.css"/></head><body><div id="__next"><div><h1 id="elk-with-filebeats">ELK with filebeats</h1>
<h2 id="introduction">Introduction</h2>
<h2 id="need-for-beats">Need for beats</h2>
<h2 id="installation">Installation</h2>
<ul>
<li>install filebeat as mentioned in procedure</li>
<li>to run:
<code>filebeat -e -c ./filebeat.yml -d &quot;*&quot;</code>
-d specifies debug level
-e report error on <code>STDERR</code>
-c specify config file (default: filebeat.yml)</li>
<li>Set <code>output.console</code> configs to verify/debug</li>
</ul>
<h3 id="x-pack">X-Pack</h3>
<h2 id="logstash">Logstash</h2>
<h3 id="mac">Mac</h3>
<ul>
<li>install location: /usr/local/Cellar/logstash/7.3.0</li>
<li>config: /usr/local/Cellar/logstash/7.3.0/libexec/config -&gt; /usr/local/etc/logstash
within the config, we can edit <code>logstash.yml</code></li>
</ul>
<h2 id="elasticsearch">Elasticsearch</h2>
<h3 id="theory">Theory</h3>
<ul>
<li>Index -&gt; Database</li>
<li>Type -&gt; TableName</li>
<li>Document -&gt; Rows/Records</li>
<li>Fields  -&gt; columns<h3 id="api">API</h3>
</li>
<li>Document<ul>
<li>Single<ul>
<li>Index: Adds or updates typed JSON doc in specific index, making it searchable<pre><code>POST &lt;index-name&gt;/&lt;type-name&gt;/&lt;id&gt;
{
&quot;key1&quot;: &quot;value1&quot;
}</code></pre></li>
<li>Get<pre><code>GET /&lt;index-name&gt;/&lt;type-name&gt;/_search?size=20</code></pre></li>
<li>Delete<pre><code>DELETE /&lt;index-name&gt;/&lt;type-name&gt;/&lt;id&gt;</code></pre></li>
<li>Update<pre><code>POST &lt;index-name&gt;/&lt;type-name&gt;/&lt;id&gt;/update
{
&quot;script&quot;: {
&quot;source&quot;: &quot;ctx._source.Age=params.val&quot;,
&quot;lang&quot;: &quot;painless&quot;,
&quot;params&quot;: {
&quot;val&quot;: {
  &quot;Age&quot;: 32,
  &quot;Gender&quot;: &quot;Female&quot;
}
}
}
}</code></pre></li>
</ul>
</li>
<li>Multi<ul>
<li>Get<pre><code>GET /_mget
{
&quot;abc&quot;: [
{
&quot;_index&quot;: &quot;index-name&quot;,
&quot;_type&quot;: &quot;type-name&quot;
},
{
&quot;_index&quot;: &quot;&quot;,
&quot;_type&quot;: &quot;&quot;
}
]
}</code></pre></li>
<li>Bulk</li>
<li>Delete by query<pre><code>POST /&lt;index-name&gt;/_delete_by_query
{
&quot;query&quot;: {
&quot;match&quot;: {
&quot;name&quot;: &quot;xyz&quot;
}
}
}</code></pre></li>
<li>Update by query</li>
<li>Reindex</li>
</ul>
</li>
</ul>
</li>
<li>Search</li>
<li>Indices</li>
<li>Cat</li>
<li>Cluster<h3 id="mac-1">Mac</h3>
</li>
<li>Data storage location: <code>~/logs/logstash/elasticsearch-7.3.1/data/nodes/0</code></li>
<li>Go to <code>http://localhost:9200/_cat/indices</code> to see the list of indexes created.</li>
<li>when indices status is <code>yellow</code> in development machine, setting <code>index.number_of_replicas</code> to <code>0</code> will resolve the issue. It will be available in kibana UI -&gt; management menu -&gt; elasticsearch -&gt; index management -&gt; edit settings</li>
</ul>
<h2 id="filebeat">Filebeat</h2>
<h3 id="mac-2">Mac</h3>
<ul>
<li>while using filebeat with any module, we need to enable it. for that, the following config setting needs to be done:<pre><code>filebeat.config.modules:
enabled: true
path: ${path.config}/modules.d/*.yml</code></pre>followed by<pre><code>./filebeat modules enable logstash</code></pre></li>
</ul>
<h2 id="analysis">Analysis</h2>
<ul>
<li>Query</li>
<li>Mapping parameter</li>
<li>Index setting</li>
</ul>
<h3 id="analyzer">Analyzer</h3>
<ul>
<li>It tokenises the text i.e. it splits them into tokens using tokeniser</li>
<li>Then we have n number of token filters to filter, say, <ul>
<li>stop words like ‘a’, ‘the’ etc</li>
<li>uppercase to lowercase</li>
</ul>
</li>
<li>api<pre><code>POST &lt;index-name&gt;/_analyze</code></pre></li>
<li>types<ul>
<li>standard</li>
<li>whitespace</li>
<li>simple</li>
<li>keyword</li>
<li>stop: stop word, stopword_path</li>
<li>pattern: stopword, stopword_path, pattern, lowercase</li>
<li>custom: tokeniser, char_filter, filter</li>
</ul>
</li>
</ul>
<h3 id="tokeniser">Tokeniser</h3>
<ul>
<li>word<ul>
<li>standard</li>
<li>lowercase</li>
<li>whitespace</li>
</ul>
</li>
<li>partial<ul>
<li>ngram</li>
<li>edge_ngram</li>
</ul>
</li>
<li>structured<ul>
<li>keyword</li>
<li>pattern</li>
<li>simple_pattern</li>
</ul>
</li>
</ul>
</div></div><script id="__NEXT_DATA__" type="application/json">{"dataManager":"[]","props":{"pageProps":{}},"page":"/articles","query":{"attributes":{},"body":"\u003ch1 id=\"elk-with-filebeats\"\u003eELK with filebeats\u003c/h1\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003ch2 id=\"need-for-beats\"\u003eNeed for beats\u003c/h2\u003e\n\u003ch2 id=\"installation\"\u003eInstallation\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003einstall filebeat as mentioned in procedure\u003c/li\u003e\n\u003cli\u003eto run:\n\u003ccode\u003efilebeat -e -c ./filebeat.yml -d \u0026quot;*\u0026quot;\u003c/code\u003e\n-d specifies debug level\n-e report error on \u003ccode\u003eSTDERR\u003c/code\u003e\n-c specify config file (default: filebeat.yml)\u003c/li\u003e\n\u003cli\u003eSet \u003ccode\u003eoutput.console\u003c/code\u003e configs to verify/debug\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"x-pack\"\u003eX-Pack\u003c/h3\u003e\n\u003ch2 id=\"logstash\"\u003eLogstash\u003c/h2\u003e\n\u003ch3 id=\"mac\"\u003eMac\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003einstall location: /usr/local/Cellar/logstash/7.3.0\u003c/li\u003e\n\u003cli\u003econfig: /usr/local/Cellar/logstash/7.3.0/libexec/config -\u0026gt; /usr/local/etc/logstash\nwithin the config, we can edit \u003ccode\u003elogstash.yml\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"elasticsearch\"\u003eElasticsearch\u003c/h2\u003e\n\u003ch3 id=\"theory\"\u003eTheory\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eIndex -\u0026gt; Database\u003c/li\u003e\n\u003cli\u003eType -\u0026gt; TableName\u003c/li\u003e\n\u003cli\u003eDocument -\u0026gt; Rows/Records\u003c/li\u003e\n\u003cli\u003eFields  -\u0026gt; columns\u003ch3 id=\"api\"\u003eAPI\u003c/h3\u003e\n\u003c/li\u003e\n\u003cli\u003eDocument\u003cul\u003e\n\u003cli\u003eSingle\u003cul\u003e\n\u003cli\u003eIndex: Adds or updates typed JSON doc in specific index, making it searchable\u003cpre\u003e\u003ccode\u003ePOST \u0026lt;index-name\u0026gt;/\u0026lt;type-name\u0026gt;/\u0026lt;id\u0026gt;\n{\n\u0026quot;key1\u0026quot;: \u0026quot;value1\u0026quot;\n}\u003c/code\u003e\u003c/pre\u003e\u003c/li\u003e\n\u003cli\u003eGet\u003cpre\u003e\u003ccode\u003eGET /\u0026lt;index-name\u0026gt;/\u0026lt;type-name\u0026gt;/_search?size=20\u003c/code\u003e\u003c/pre\u003e\u003c/li\u003e\n\u003cli\u003eDelete\u003cpre\u003e\u003ccode\u003eDELETE /\u0026lt;index-name\u0026gt;/\u0026lt;type-name\u0026gt;/\u0026lt;id\u0026gt;\u003c/code\u003e\u003c/pre\u003e\u003c/li\u003e\n\u003cli\u003eUpdate\u003cpre\u003e\u003ccode\u003ePOST \u0026lt;index-name\u0026gt;/\u0026lt;type-name\u0026gt;/\u0026lt;id\u0026gt;/update\n{\n\u0026quot;script\u0026quot;: {\n\u0026quot;source\u0026quot;: \u0026quot;ctx._source.Age=params.val\u0026quot;,\n\u0026quot;lang\u0026quot;: \u0026quot;painless\u0026quot;,\n\u0026quot;params\u0026quot;: {\n\u0026quot;val\u0026quot;: {\n  \u0026quot;Age\u0026quot;: 32,\n  \u0026quot;Gender\u0026quot;: \u0026quot;Female\u0026quot;\n}\n}\n}\n}\u003c/code\u003e\u003c/pre\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eMulti\u003cul\u003e\n\u003cli\u003eGet\u003cpre\u003e\u003ccode\u003eGET /_mget\n{\n\u0026quot;abc\u0026quot;: [\n{\n\u0026quot;_index\u0026quot;: \u0026quot;index-name\u0026quot;,\n\u0026quot;_type\u0026quot;: \u0026quot;type-name\u0026quot;\n},\n{\n\u0026quot;_index\u0026quot;: \u0026quot;\u0026quot;,\n\u0026quot;_type\u0026quot;: \u0026quot;\u0026quot;\n}\n]\n}\u003c/code\u003e\u003c/pre\u003e\u003c/li\u003e\n\u003cli\u003eBulk\u003c/li\u003e\n\u003cli\u003eDelete by query\u003cpre\u003e\u003ccode\u003ePOST /\u0026lt;index-name\u0026gt;/_delete_by_query\n{\n\u0026quot;query\u0026quot;: {\n\u0026quot;match\u0026quot;: {\n\u0026quot;name\u0026quot;: \u0026quot;xyz\u0026quot;\n}\n}\n}\u003c/code\u003e\u003c/pre\u003e\u003c/li\u003e\n\u003cli\u003eUpdate by query\u003c/li\u003e\n\u003cli\u003eReindex\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eSearch\u003c/li\u003e\n\u003cli\u003eIndices\u003c/li\u003e\n\u003cli\u003eCat\u003c/li\u003e\n\u003cli\u003eCluster\u003ch3 id=\"mac-1\"\u003eMac\u003c/h3\u003e\n\u003c/li\u003e\n\u003cli\u003eData storage location: \u003ccode\u003e~/logs/logstash/elasticsearch-7.3.1/data/nodes/0\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eGo to \u003ccode\u003ehttp://localhost:9200/_cat/indices\u003c/code\u003e to see the list of indexes created.\u003c/li\u003e\n\u003cli\u003ewhen indices status is \u003ccode\u003eyellow\u003c/code\u003e in development machine, setting \u003ccode\u003eindex.number_of_replicas\u003c/code\u003e to \u003ccode\u003e0\u003c/code\u003e will resolve the issue. It will be available in kibana UI -\u0026gt; management menu -\u0026gt; elasticsearch -\u0026gt; index management -\u0026gt; edit settings\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"filebeat\"\u003eFilebeat\u003c/h2\u003e\n\u003ch3 id=\"mac-2\"\u003eMac\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003ewhile using filebeat with any module, we need to enable it. for that, the following config setting needs to be done:\u003cpre\u003e\u003ccode\u003efilebeat.config.modules:\nenabled: true\npath: ${path.config}/modules.d/*.yml\u003c/code\u003e\u003c/pre\u003efollowed by\u003cpre\u003e\u003ccode\u003e./filebeat modules enable logstash\u003c/code\u003e\u003c/pre\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"analysis\"\u003eAnalysis\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eQuery\u003c/li\u003e\n\u003cli\u003eMapping parameter\u003c/li\u003e\n\u003cli\u003eIndex setting\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"analyzer\"\u003eAnalyzer\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eIt tokenises the text i.e. it splits them into tokens using tokeniser\u003c/li\u003e\n\u003cli\u003eThen we have n number of token filters to filter, say, \u003cul\u003e\n\u003cli\u003estop words like ‘a’, ‘the’ etc\u003c/li\u003e\n\u003cli\u003euppercase to lowercase\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eapi\u003cpre\u003e\u003ccode\u003ePOST \u0026lt;index-name\u0026gt;/_analyze\u003c/code\u003e\u003c/pre\u003e\u003c/li\u003e\n\u003cli\u003etypes\u003cul\u003e\n\u003cli\u003estandard\u003c/li\u003e\n\u003cli\u003ewhitespace\u003c/li\u003e\n\u003cli\u003esimple\u003c/li\u003e\n\u003cli\u003ekeyword\u003c/li\u003e\n\u003cli\u003estop: stop word, stopword_path\u003c/li\u003e\n\u003cli\u003epattern: stopword, stopword_path, pattern, lowercase\u003c/li\u003e\n\u003cli\u003ecustom: tokeniser, char_filter, filter\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"tokeniser\"\u003eTokeniser\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eword\u003cul\u003e\n\u003cli\u003estandard\u003c/li\u003e\n\u003cli\u003elowercase\u003c/li\u003e\n\u003cli\u003ewhitespace\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003epartial\u003cul\u003e\n\u003cli\u003engram\u003c/li\u003e\n\u003cli\u003eedge_ngram\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003estructured\u003cul\u003e\n\u003cli\u003ekeyword\u003c/li\u003e\n\u003cli\u003epattern\u003c/li\u003e\n\u003cli\u003esimple_pattern\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n"},"buildId":"8Mis-cZ22Xko4dzTOJNkr","nextExport":true}</script><script async="" data-next-page="/articles" src="/_next/static/8Mis-cZ22Xko4dzTOJNkr/pages/articles.js"></script><script async="" data-next-page="/_app" src="/_next/static/8Mis-cZ22Xko4dzTOJNkr/pages/_app.js"></script><script src="/_next/static/runtime/webpack-4b444dab214c6491079c.js" async=""></script><script src="/_next/static/chunks/commons.33617edd7b180839ed18.js" async=""></script><script src="/_next/static/chunks/styles.67314864e5ee77300274.js" async=""></script><script src="/_next/static/runtime/main-c2a874049c0d0e609626.js" async=""></script></body></html>