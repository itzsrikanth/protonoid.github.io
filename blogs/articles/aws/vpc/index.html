<!DOCTYPE html><html><head><meta charSet="utf-8"/><title>VPC - AWS</title><meta charset="utf-8"/><meta name="viewport" content="initial-scale=1.0, width=device-width"/><meta http-equiv="Content-Type" content="text/html; charset=utf-8"/><meta name="next-head-count" content="5"/><link rel="preload" href="/_next/static/css/commons.be16d001.chunk.css" as="style"/><link rel="stylesheet" href="/_next/static/css/commons.be16d001.chunk.css"/><link rel="preload" href="/_next/static/c_R24dhd8hjJEXWGIGUO-/pages/articleHomepage.js" as="script"/><link rel="preload" href="/_next/static/c_R24dhd8hjJEXWGIGUO-/pages/_app.js" as="script"/><link rel="preload" href="/_next/static/runtime/webpack-9369c5c69dbf6d4912cb.js" as="script"/><link rel="preload" href="/_next/static/chunks/commons.b6dc333151af4a74b05a.js" as="script"/><link rel="preload" href="/_next/static/runtime/main-5b3d9dcbbf35909ee5a1.js" as="script"/></head><body><div id="__next"><nav class="d-flex align-items-center"><div class="container"><ul><li><a href="/blogs">Blogs</a></li></ul></div></nav><div class="container"><div class="row"><div class="col-md-12"></div></div><ul class="row"><li class="col-md-3"><div><a href="/blogs/articles/aws/vpc/best-practices/">VPC Best Practices - AWS</a></div></li></ul></div></div><script id="__NEXT_DATA__" type="application/json">{"dataManager":"[]","props":{"pageProps":{"categories":[{"location":"/","markdown":{"attributes":{"title":"Blog articles - Protonoid","keywords":"AWS,CPP,cryptography,database,docker,elasticsearch,git,GraphQL,Javascript,SEO,Python,Kubernetes,OpenCV"},"body":"\u003ch1 id=\"blog-articles\"\u003eBlog Articles\u003c/h1\u003e\n","frontmatter":"title: Blog articles - Protonoid\nkeywords: AWS,CPP,cryptography,database,docker,elasticsearch,git,GraphQL,Javascript,SEO,Python,Kubernetes,OpenCV"}},{"location":"/shell-script/","markdown":{"attributes":{"title":"Linux Shell Scripting - sh, bash, zsh, tcsh, csh"},"body":"","frontmatter":"title: Linux Shell Scripting - sh, bash, zsh, tcsh, csh"}},{"location":"/shell-script/simple-use-cases/","markdown":{"attributes":{"title":"Simple Use Cases - Shell Script","description":"Some simple use cases to have an exposure on its applications"},"body":"\u003ch1 id=\"shell-script-simple-use-cases\"\u003eShell Script Simple Use Cases\u003c/h1\u003e\n\u003ch2 id=\"to-convert-nunjuck-template-without-space\"\u003eTo convert nunjuck template without space\u003c/h2\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e#!/bin/bash\n\nfind . -name index.html | while read line; do\n    perl -pi -e \u0026#39;s/{(%|#)(?=[^-])/{\\1-/g\u0026#39; $line\n    perl -pi -e \u0026#39;s/(?\u0026lt;=[^-])(%|#)}/-\\1}/g\u0026#39; $line\ndone\u003c/code\u003e\u003c/pre\u003e\n","frontmatter":"title: Simple Use Cases - Shell Script\ndescription: Some simple use cases to have an exposure on its applications"}},{"location":"/shell-script/one-liner/","markdown":{"attributes":{"title":"Shell script one liners"},"body":"\u003ch1 id=\"one-liners\"\u003eOne-liners\u003c/h1\u003e\n\u003ch2 id=\"perl\"\u003ePerl\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003e-e\u003c/code\u003e: allows you to specify the Perl code to be executed right on the command line\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e-p\u003c/code\u003e: code gets executed on every line, and that the line gets printed out after that\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e-i\u003c/code\u003e: opens the file, executes the substitution for each line, prints the output to a temporary file, and then replaces the original file\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"\"\u003e\u003c/h3\u003e\n\u003ch2 id=\"awk\"\u003eawk\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eCombine multiline text into single line\u003c/li\u003e\n\u003cli\u003esource: \u003ca href=\"https://www.rexegg.com/regex-perl-one-liners.html\"\u003ePerl Regex One-Liner Cookbook\u003c/a\u003e*\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e\u0026lt;multiline_output_command\u0026gt; | awk \u0026#39;{printf(\u0026quot;%s\u0026quot;, $0)}\u0026#39;\u003c/code\u003e\u003c/pre\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"references\"\u003eReferences\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"http://www.pement.org/sed/sed1line.txt\"\u003eSed One-liners\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://catonmat.net/introduction-to-perl-one-liners\"\u003eIntroduction to Perl one-liners\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n","frontmatter":"title: Shell script one liners"}},{"location":"/serverless/","markdown":{"attributes":{"title":"Serverless Architecture"},"body":"","frontmatter":"title: Serverless Architecture"}},{"location":"/serverless/serverless-framework/","markdown":{"attributes":{"title":"AWS Serverless Framework","description":"Using Serverless Framework for creating a Serverless microservices architecture using Lambda, DynamoDB, S3 Buckets, API Gateways and IAM Access."},"body":"\u003ch1 id=\"serverless-framework\"\u003eServerless Framework\u003c/h1\u003e\n\u003cp\u003e\u003cimg src=\"https://theburningmonk.com/wp-content/uploads/2019/05/img_5cddfd8fe678a.png\" alt=\"Serverless comparisons\"\u003e\u003c/p\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eServerless framework brings in multi cloud serverless capability in the form of automated descriptive programming. Here, in AWS, it will be leveraging the CloudFormation to build on top of it. It has got many built in templates and plugins ecosystem to choose from.\u003c/p\u003e\n\u003ch2 id=\"access-required\"\u003eAccess required\u003c/h2\u003e\n\u003cpre\u003e\u003ccode\u003e{\n    \u0026quot;Version\u0026quot;: \u0026quot;2012-10-17\u0026quot;,\n    \u0026quot;Statement\u0026quot;: [\n        {\n            \u0026quot;Sid\u0026quot;: \u0026quot;VisualEditor0\u0026quot;,\n            \u0026quot;Effect\u0026quot;: \u0026quot;Allow\u0026quot;,\n            \u0026quot;Action\u0026quot;: [\n                \u0026quot;iam:PassRole\u0026quot;,\n                \u0026quot;iam:ListAttachedRolePolicies\u0026quot;,\n                \u0026quot;iam:CreateRole\u0026quot;,\n                \u0026quot;iam:PutRolePolicy\u0026quot;,\n                \u0026quot;iam:AttachRolePolicy\u0026quot;,\n                \u0026quot;iam:GetRole\u0026quot;,\n                \u0026quot;s3:*\u0026quot;,\n                \u0026quot;apigateway:*\u0026quot;,\n                \u0026quot;logs:*\u0026quot;,\n                \u0026quot;lambda:*\u0026quot;,\n                \u0026quot;cloudformation:*\u0026quot;\n            ],\n            \u0026quot;Resource\u0026quot;: \u0026quot;*\u0026quot;\n        }\n    ]\n}\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"troubleshooting\"\u003eTroubleshooting\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eCustomDashresourceDashapigwDashcwDashroleLambdaFunction - The role defined for the function cannot be assumed by Lambda\u003cpre\u003e\u003ccode\u003eAn error occurred: CustomDashresourceDashapigwDashcwDashroleLambdaFunction - The role defined for the function cannot be assumed by Lambda. (Service: AWSLambdaInternal; Status Code: 400; Error Code: InvalidParameterValueException; Request ID: XXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXX).\u003c/code\u003e\u003c/pre\u003eNeed to add \u003ccode\u003elambda.amazonaws.com\u003c/code\u003e to the \u003ccode\u003ecfnRole\u003c/code\u003e\nRef: \u003ca href=\"https://github.com/serverless/serverless/issues/6876\"\u003e\u0026quot;The role defined for the function cannot be assumed by Lambda\u0026quot; error after upgrading to 1.55.0 · Issue #6876 · serverless/serverless · GitHub\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"resources\"\u003eResources\u003c/h2\u003e\n\u003ch3 id=\"documentation\"\u003eDocumentation\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://serverless.com/framework/docs/providers/aws/guide/serverless.yml/\"\u003eServerless Framework - AWS Lambda Guide - Serverless.yml Reference\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n","frontmatter":"title: AWS Serverless Framework\ndescription: Using Serverless Framework for creating a Serverless microservices architecture using Lambda, DynamoDB, S3 Buckets, API Gateways and IAM Access."}},{"location":"/python/","markdown":{"attributes":{"title":"Python"},"body":"","frontmatter":"title: Python"}},{"location":"/python/troubleshoot/","markdown":{"attributes":{"title":"Troubleshooting - Python"},"body":"\u003ch1 id=\"python-troubleshoot\"\u003ePython troubleshoot\u003c/h1\u003e\n\u003ch2 id=\"importerror-bad-magic-number-in-xml-bx03xf3rn\"\u003eImportError: bad magic number in \u0026#39;xml\u0026#39;: b\u0026#39;\\x03\\xf3\\r\\n\u0026#39;\u003c/h2\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003efind . -name \u0026quot;*.pyc\u0026quot; -exec rm -f {} \\;\u003c/code\u003e\u003c/pre\u003e\n","frontmatter":"title: Troubleshooting - Python"}},{"location":"/opencv/","markdown":{"attributes":{"title":"OpenCV Introduction"},"body":"\u003ch2 id=\"with-c\"\u003eWith C++\u003c/h2\u003e\n\u003cp\u003eWhen compiling \u003ccode\u003ecpp\u003c/code\u003e files with \u003ccode\u003eOpenCV\u003c/code\u003e, it looks for \u003ccode\u003eopencv4.pc\u003c/code\u003e to locate the installed libraries. We can use this file with \u003ccode\u003epkg-config\u003c/code\u003e to get a list of \u003ccode\u003ecflags\u003c/code\u003e and \u003ccode\u003elibs\u003c/code\u003e to be specified while compiling the program.\u003c/p\u003e\n\u003cp\u003eSo, we can build it using following command:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003eopencv_lib=`pkg-config --cflags --libs /usr/local/Cellar/opencv/4.1.0_1/lib/pkgconfig/opencv4.pc`\ng++ $opencv_lib -std=c++11 file.cpp -o file.o\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id=\"opencv-410-library-location\"\u003eOpenCV-4.1.0 Library location\u003c/h3\u003e\n\u003cp\u003epkg-config --cflags --libs /usr/local/Cellar/opencv/4.1.0_1/lib/pkgconfig/opencv4.pc\u003c/p\u003e\n\u003ch3 id=\"important-locations\"\u003eImportant locations\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003e/usr/local/lib/pkgconfig/opencv4.pc\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e/usr/local/Cellar/opencv/4.0.0/lib/pkgconfig/opencv4.pc\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e/usr/local/Cellar/opencv/4.1.0_1/lib/pkgconfig/opencv4.pc\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e/anaconda3/pkgs/libopencv-3.4.1-h0f2e407_1/lib/pkgconfig/opencv.pc\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e/anaconda3/pkgs/libopencv-3.4.2-h7c891bd_1/lib/pkgconfig/opencv.pc\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e/anaconda3/lib/pkgconfig/opencv.pc\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n","frontmatter":"title: OpenCV Introduction"}},{"location":"/open-specifications/","markdown":{"attributes":{"title":"Open Specifications"},"body":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n","frontmatter":"title: Open Specifications"}},{"location":"/open-specifications/swagger/","markdown":{"attributes":{"title":"Swagger 2.0 Specification"},"body":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n","frontmatter":"title: Swagger 2.0 Specification"}},{"location":"/kubernetes/","markdown":{"attributes":{"title":"Kubernetes Introduction"},"body":"\u003ch1 id=\"kubernetes\"\u003eKubernetes\u003c/h1\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eRoot level YAML keys:\u003c/li\u003e\n\u003c/ul\u003e\n","frontmatter":"title: Kubernetes Introduction"}},{"location":"/kubernetes/minikube/","markdown":{"attributes":{"title":"Minikube"},"body":"\u003ch2 id=\"references\"\u003eReferences:\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://blog.hasura.io/sharing-a-local-registry-for-minikube-37c7240d0615/\"\u003eSharing a local registry with minikube\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n","frontmatter":"title: Minikube"}},{"location":"/kubernetes/minikube/access-mongodb-in-host-from-kubernetes-container/","markdown":{"attributes":{"title":"Access services like mongodb on host inside kubernetes pods"},"body":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003essh -i $(minikube ssh-key) docker@$(minikube ip) -R 27000:localhost:27017\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow if we want to access port \u003ccode\u003e27000\u003c/code\u003e inside a pod, we can do it by getting IP address of minikube and connecting to that port from inside the pod.\u003c/p\u003e\n\u003cp\u003e```bash\nmongo 172.12.0.1:27000\n``\u003c/p\u003e\n\u003ch2 id=\"references\"\u003eReferences\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://medium.com/tarkalabs/proxying-services-into-minikube-8355db0065fd\"\u003eProxying services into minikube - Tarka Labs Blog - Medium\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n","frontmatter":"title: Access services like mongodb on host inside kubernetes pods"}},{"location":"/javascript/","markdown":{"attributes":{"title":"Javascript"},"body":"","frontmatter":"title: Javascript"}},{"location":"/javascript/performance/","markdown":{"attributes":{"title":"Javascript Performance"},"body":"","frontmatter":"title: Javascript Performance"}},{"location":"/javascript/performance/benchmark/","markdown":{"attributes":{"title":"Performance Benchmark - Javascript"},"body":"\u003ch1 id=\"javascript-performance-benchmarks\"\u003eJavascript performance benchmarks\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003eSuperior performance of \u003ccode\u003efor\u003c/code\u003e loop over \u003ccode\u003ewhile\u003c/code\u003e and prefix increment over postfix increment.\nRef: \u003ca href=\"https://jsperf.com/for-loop-research\"\u003ehttps://jsperf.com/for-loop-research\u003c/a\u003e\nNote: Benchmark not \nThe following syntax performance seems to be consistent in modern v8 (chrome/nodejs), (excluding ES6 syntax):\u003cpre\u003e\u003ccode\u003efor (var i=0; i \u0026lt; arr.length; ++i) {\nworker();\n}\u003c/code\u003e\u003c/pre\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cp\u003eString, Number === is generally performant\n\u003ca href=\"https://jsperf.com/string-compare-vs-number-compare/2\"\u003eString compare VS number compare · jsPerf\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003estring vs buffer comparison\n\u003ca href=\"https://jsperf.com/compare-string-vs-buffer\"\u003ecompare string vs buffer · jsPerf\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003ca href=\"https://jsperf.com/adding-to-a-set-vs-pushing-to-an-array\"\u003eAdding to a Set vs Pushing to an Array · jsPerf\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch5 id=\"array-category-finding-if-exists\"\u003earray category finding if exists\u003c/h5\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://jsperf.com/array-time-space-complexity-comparison/1\"\u003earray-time-space-complexity-comparison · jsPerf\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://jsperf.com/find-if-array-element-exists-and-category-if-yes/1\"\u003efind-if-array-element-exists-and-category-if-yes · jsPerf\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch5 id=\"try-catch-vs-code-error-check-even-for-very-nested-js-object\"\u003etry-catch vs code error check (even for very nested js object)\u003c/h5\u003e\n","frontmatter":"title: Performance Benchmark - Javascript"}},{"location":"/javascript/packages/","markdown":{"attributes":{"title":"Javascript Packages"},"body":"","frontmatter":"title: Javascript Packages"}},{"location":"/javascript/packages/lerna/","markdown":{"attributes":{"title":"Lerna package - Introduction"},"body":"\u003ch1 id=\"lerna\"\u003eLerna\u003c/h1\u003e\n\u003ch2 id=\"commands\"\u003eCommands\u003c/h2\u003e\n\u003ch3 id=\"list\"\u003e\u003ca href=\"https://www.npmjs.com/package/@lerna/list\"\u003eList\u003c/a\u003e\u003c/h3\u003e\n\u003ch2 id=\"cookbooks\"\u003eCookbooks\u003c/h2\u003e\n\u003ch4 id=\"add-local-package-to-other-package\"\u003eAdd local package to other package\u003c/h4\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003enpm install ../package-name -S\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis will add \u003ccode\u003e\u0026quot;package-name\u0026quot;: \u0026quot;file:../package-name\u0026quot;\u003c/code\u003e in \u003ccode\u003edependencies\u003c/code\u003e\u003c/p\u003e\n\u003ch4 id=\"trigger-npm-install-in-all-packages\"\u003eTrigger npm install in all packages\u003c/h4\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003enpx lerna bootstrap\u003c/code\u003e\u003c/pre\u003e\n","frontmatter":"title: Lerna package - Introduction"}},{"location":"/javascript/asynchronous-iterator-in-array/","markdown":{"attributes":{"title":"Asynchronous Iterator in Array"},"body":"\u003ch1 id=\"tldr\"\u003eTL:DR;\u003c/h1\u003e\n","frontmatter":"title: Asynchronous Iterator in Array"}},{"location":"/javascript/array-generator/","markdown":{"attributes":{"title":"Array Generator - Javascript"},"body":"\u003cp\u003eArray Generator\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-javascript\"\u003econst gen = N =\u0026gt; [...(function*(){let i=0;while(i\u0026lt;N)yield i++})()]\nperformance.mark(\u0026#39;test1\u0026#39;);\ngen(100000);\nperformance.measure(\u0026#39;test1\u0026#39;);\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe duration for above \u003ca href=\"https://stackoverflow.com/a/36828957/5305151\"\u003ecode\u003c/a\u003e is observed to be 3168.09.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-javascript\"\u003evar foo = [];\nperformance.mark(\u0026#39;test2\u0026#39;)\nfor (var i = 1; i \u0026lt;= 100000; i++) {\n   foo.push(i);\n}\nperformance.measure(\u0026#39;test2\u0026#39;);\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe duration for above \u003ca href=\"https://stackoverflow.com/q/3746725/5305151\"\u003ecode\u003c/a\u003e is observed to be 2420.01.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-javascript\"\u003eperformance.mark(\u0026#39;test3\u0026#39;);\nfor(foo=[x=100000]; x; foo[x-1]=x--);\nperformance.measure(\u0026#39;test3\u0026#39;);\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe duration for above \u003ca href=\"https://stackoverflow.com/a/36324319/5305151\"\u003ecode\u003c/a\u003e is observed to be 1888.52.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-javascript\"\u003eperformance.mark(\u0026#39;test4\u0026#39;);\nArray.from({length: 100000}, (v, k) =\u0026gt; k+1); \nperformance.measure(\u0026#39;test4\u0026#39;);\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe duration for above \u003ca href=\"https://stackoverflow.com/a/38213213/5305151\"\u003ecode\u003c/a\u003e is observed to be 2254.72.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-javascript\"\u003eperformance.mark(\u0026#39;test5\u0026#39;);\n[...Array(100000)].map((_, i) =\u0026gt; i + 1)\nperformance.measure(\u0026#39;test5\u0026#39;);\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe duration for above \u003ca href=\"https://stackoverflow.com/a/40772491/5305151\"\u003ecode\u003c/a\u003e is observed to be 4273.46.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-javascript\"\u003eperformance.mark(\u0026#39;test6\u0026#39;);\nfor(var i,a=[i=0];i\u0026lt;100000;a[i++]=i);\nperformance.measure(\u0026#39;test6\u0026#39;);\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe duration for above \u003ca href=\"https://stackoverflow.com/a/41293227/5305151\"\u003ecode\u003c/a\u003e is observed to be 17016.45.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-javascript\"\u003eperformance.mark(\u0026#39;test7\u0026#39;);\nvar arr = Array(100000).fill(0);\nperformance.measure(\u0026#39;test7\u0026#39;);\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe duration for above code is 3098.02\u003c/p\u003e\n","frontmatter":"title: Array Generator - Javascript"}},{"location":"/graphql/","markdown":{"attributes":{"title":"GraphQL"},"body":"\u003ch1 id=\"graphql\"\u003eGraphQL\u003c/h1\u003e\n","frontmatter":"title: GraphQL"}},{"location":"/git/","markdown":{"attributes":{"title":"Git Introduction"},"body":"\u003ch1 id=\"git\"\u003eGit\u003c/h1\u003e\n\u003ch2 id=\"import-commits-from-other-repo\"\u003eImport commits from other repo\u003c/h2\u003e\n\u003cp\u003eTo import commits, we can add the other repo as an origin in our current repo\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-sh\"\u003egit remote add \u0026lt;origin_name\u0026gt; git@github.com:username/other_reponame.git\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow, we can either create new branch from newly added origin\u0026#39;s any branch or rebase any of our existing branch\u003c/p\u003e\n\u003cp\u003eThen, we can even delete that origin\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-sh\"\u003egit remote rm \u0026lt;origin_name\u0026gt;\u003c/code\u003e\u003c/pre\u003e\n","frontmatter":"title: Git Introduction"}},{"location":"/git/replace-gui-with-cli/","markdown":{"attributes":{"title":"Replace Git GUI with CLI"},"body":"\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e\n# get all changes list\ngit fetch --all\n\n# get a branch to work on\ngit checkout -b \u0026lt;branch_name\u0026gt; origin/\u0026lt;remote_branch_name\u0026gt;\n\n# add files for staging\ngit add *\n\n# commit the files\ngit commit -m \u0026quot;message\u0026quot;\n\n# push to remote repo\ngit push origin \u0026lt;remote_branch_name\u0026gt;\n\n# set a local branch to track the remote one\ngit branch -u origin/\u0026lt;remote_branch_name\u0026gt;\n# --set-upstream-to\n# --track\n\n# list only untracked files\ngit ls-files --exclude-standard --others\n\n# to see local branch tracks which remote branch\ngit branch -vv\n\n# rebase with a particular remote branch and force push to another\ngit rebase origin/remote_branch_1\ngit push -f origin remote_branch_2\n\n## Commit processing\n# to get last commit hash\ngit log -n 1 --format=\u0026quot;%H\u0026quot;\ngit log origin/master -n 1 --format=\u0026quot;%H\u0026quot;\n\n# Unstage all files\ngit reset HEAD -- .\n\n# Discard all changes\ngit checkout -- .\n\n# Delete untracked files\ngit clean -fd\u003c/code\u003e\u003c/pre\u003e\n","frontmatter":"title: Replace Git GUI with CLI"}},{"location":"/git/github/","markdown":{"attributes":{"title":"Github"},"body":"","frontmatter":"title: Github"}},{"location":"/git/github/packages/","markdown":{"attributes":{"title":"Github Packages"},"body":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003ch2 id=\"docker\"\u003eDocker\u003c/h2\u003e\n\u003cp\u003eThe Image Registry URL is \u003ccode\u003edocker.pkg.github.com\u003c/code\u003e.\u003c/p\u003e\n\u003ch4 id=\"download-image-from-private-repo\"\u003eDownload image from private repo\u003c/h4\u003e\n\u003ch5 id=\"related-issues\"\u003eRelated issues:\u003c/h5\u003e\n\u003cul\u003e\n\u003cli\u003e\u0026quot;Error response from daemon: unauthorized: Your request could not be authenticated by the GitHub Packages service. Please ensure your access token is valid and has the appropriate scopes configured.\u0026quot;\u003c/li\u003e\n\u003cli\u003e\u0026quot;Error response from daemon: unauthorized: Resource protected by organization SAML enforcement. You must grant your personal token access to this organization.\u0026quot;\u003c/li\u003e\n\u003cli\u003e\u0026quot;Failed to pull image: rpc error: code = Unknown desc = Error response from daemon: pull access denied for repository does not exist or may require \u0026#39;docker login\u0026#39;\u0026quot;\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWe need to have a \u0026quot;Personal Access Token\u0026quot; generated for our account from \u003ccode\u003ehttps://github.com/settings/tokens\u003c/code\u003e. The will be our password while logging in CLI for Github Packages.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003edocker login -u \u0026lt;username\u0026gt; docker.pkg.github.com\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eOnce logged in, you can check \u003ccode\u003e~/.docker/config.json\u003c/code\u003e for confirmation. It will be like:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-json\"\u003e{\n    \u0026quot;auths\u0026quot;: {\n        \u0026quot;docker.pkg.github.com\u0026quot;: {\n            \u0026quot;auth\u0026quot;: \u0026quot;xxxxxxxxxxxxxxxxxxxxxx=\u0026quot;\n        }\n    },\n    \u0026quot;HttpHeaders\u0026quot;: {\n        \u0026quot;User-Agent\u0026quot;: \u0026quot;Docker-Client/18.09.9 (linux)\u0026quot;\n    }\n}\u003c/code\u003e\u003c/pre\u003e\n","frontmatter":"title: Github Packages"}},{"location":"/git/github/actions/","markdown":{"attributes":{"title":"Github Actions"},"body":"","frontmatter":"title: Github Actions"}},{"location":"/git/github/actions/introduction/","markdown":{"attributes":{"title":"Github actions introduction","description":"Conceptual introduction to CI/CD using Github Actions"},"body":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003eNewest and powerful entrant in the field of CI/CD. It is built natively as part of GitHub itself, so the CI/CD pipeline, test and build timing reduces drastically. Many features are introduced as part of Actions. Some of them are as follows:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003esecret \u0026quot;vault\u0026quot; for storing sensitive keys and passwords\u003c/li\u003e\n\u003cli\u003eworkflow trigger filter based on events, branch name, file path\u003c/li\u003e\n\u003cli\u003eprecise event hooks like push, pull_request, release, public etc\u003c/li\u003e\n\u003cli\u003emultiple OS like Ubuntu, Mac and Windows\u003c/li\u003e\n\u003cli\u003eparallel execution of jobs\u003c/li\u003e\n\u003cli\u003elive logs\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"global-variables\"\u003eGlobal variables\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003e$GITHUB_WORKSPACE\u003c/code\u003e - checkout happens to this variable\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eGITHUB_REPOSITORY\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eGITHUB_EVENT_NAME\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"theory\"\u003eTheory\u003c/h2\u003e\n\u003cp\u003eThe workflow can be triggered based on number of events. If \u003ccode\u003epush\u003c/code\u003e and \u003ccode\u003epull_request\u003c/code\u003e specifically, we can specify branch/tag name(s).\u003c/p\u003e\n","frontmatter":"title: Github actions introduction\ndescription: Conceptual introduction to CI/CD using Github Actions"}},{"location":"/elasticsearch/","markdown":{"attributes":{"title":"Elastic Search"},"body":"","frontmatter":"title: Elastic Search"}},{"location":"/elasticsearch/elk-stack/","markdown":{"attributes":{"title":"ELK Stack - Elasticsearch, Logstash, Kibana"},"body":"","frontmatter":"title: ELK Stack - Elasticsearch, Logstash, Kibana"}},{"location":"/elasticsearch/elk-stack/setup/","markdown":{"attributes":{"title":"ELK with filebeats"},"body":"\u003ch1 id=\"elk-with-filebeats\"\u003eELK with filebeats\u003c/h1\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003ch2 id=\"need-for-beats\"\u003eNeed for beats\u003c/h2\u003e\n\u003ch2 id=\"installation\"\u003eInstallation\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003einstall filebeat as mentioned in procedure\u003c/li\u003e\n\u003cli\u003eto run:\n\u003ccode\u003efilebeat -e -c ./filebeat.yml -d \u0026quot;*\u0026quot;\u003c/code\u003e\n-d specifies debug level\n-e report error on \u003ccode\u003eSTDERR\u003c/code\u003e\n-c specify config file (default: filebeat.yml)\u003c/li\u003e\n\u003cli\u003eSet \u003ccode\u003eoutput.console\u003c/code\u003e configs to verify/debug\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"x-pack\"\u003eX-Pack\u003c/h3\u003e\n\u003ch2 id=\"logstash\"\u003eLogstash\u003c/h2\u003e\n\u003ch3 id=\"mac\"\u003eMac\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003einstall location: /usr/local/Cellar/logstash/7.3.0\u003c/li\u003e\n\u003cli\u003econfig: /usr/local/Cellar/logstash/7.3.0/libexec/config -\u0026gt; /usr/local/etc/logstash\nwithin the config, we can edit \u003ccode\u003elogstash.yml\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"elasticsearch\"\u003eElasticsearch\u003c/h2\u003e\n\u003ch3 id=\"theory\"\u003eTheory\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eIndex -\u0026gt; Database\u003c/li\u003e\n\u003cli\u003eType -\u0026gt; TableName\u003c/li\u003e\n\u003cli\u003eDocument -\u0026gt; Rows/Records\u003c/li\u003e\n\u003cli\u003eFields  -\u0026gt; columns\u003ch3 id=\"api\"\u003eAPI\u003c/h3\u003e\n\u003c/li\u003e\n\u003cli\u003eDocument\u003cul\u003e\n\u003cli\u003eSingle\u003cul\u003e\n\u003cli\u003eIndex: Adds or updates typed JSON doc in specific index, making it searchable\u003cpre\u003e\u003ccode\u003ePOST \u0026lt;index-name\u0026gt;/\u0026lt;type-name\u0026gt;/\u0026lt;id\u0026gt;\n{\n\u0026quot;key1\u0026quot;: \u0026quot;value1\u0026quot;\n}\u003c/code\u003e\u003c/pre\u003e\u003c/li\u003e\n\u003cli\u003eGet\u003cpre\u003e\u003ccode\u003eGET /\u0026lt;index-name\u0026gt;/\u0026lt;type-name\u0026gt;/_search?size=20\u003c/code\u003e\u003c/pre\u003e\u003c/li\u003e\n\u003cli\u003eDelete\u003cpre\u003e\u003ccode\u003eDELETE /\u0026lt;index-name\u0026gt;/\u0026lt;type-name\u0026gt;/\u0026lt;id\u0026gt;\u003c/code\u003e\u003c/pre\u003e\u003c/li\u003e\n\u003cli\u003eUpdate\u003cpre\u003e\u003ccode\u003ePOST \u0026lt;index-name\u0026gt;/\u0026lt;type-name\u0026gt;/\u0026lt;id\u0026gt;/update\n{\n\u0026quot;script\u0026quot;: {\n\u0026quot;source\u0026quot;: \u0026quot;ctx._source.Age=params.val\u0026quot;,\n\u0026quot;lang\u0026quot;: \u0026quot;painless\u0026quot;,\n\u0026quot;params\u0026quot;: {\n\u0026quot;val\u0026quot;: {\n  \u0026quot;Age\u0026quot;: 32,\n  \u0026quot;Gender\u0026quot;: \u0026quot;Female\u0026quot;\n}\n}\n}\n}\u003c/code\u003e\u003c/pre\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eMulti\u003cul\u003e\n\u003cli\u003eGet\u003cpre\u003e\u003ccode\u003eGET /_mget\n{\n\u0026quot;abc\u0026quot;: [\n{\n\u0026quot;_index\u0026quot;: \u0026quot;index-name\u0026quot;,\n\u0026quot;_type\u0026quot;: \u0026quot;type-name\u0026quot;\n},\n{\n\u0026quot;_index\u0026quot;: \u0026quot;\u0026quot;,\n\u0026quot;_type\u0026quot;: \u0026quot;\u0026quot;\n}\n]\n}\u003c/code\u003e\u003c/pre\u003e\u003c/li\u003e\n\u003cli\u003eBulk\u003c/li\u003e\n\u003cli\u003eDelete by query\u003cpre\u003e\u003ccode\u003ePOST /\u0026lt;index-name\u0026gt;/_delete_by_query\n{\n\u0026quot;query\u0026quot;: {\n\u0026quot;match\u0026quot;: {\n\u0026quot;name\u0026quot;: \u0026quot;xyz\u0026quot;\n}\n}\n}\u003c/code\u003e\u003c/pre\u003e\u003c/li\u003e\n\u003cli\u003eUpdate by query\u003c/li\u003e\n\u003cli\u003eReindex\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eSearch\u003c/li\u003e\n\u003cli\u003eIndices\u003c/li\u003e\n\u003cli\u003eCat\u003c/li\u003e\n\u003cli\u003eCluster\u003ch3 id=\"mac-1\"\u003eMac\u003c/h3\u003e\n\u003c/li\u003e\n\u003cli\u003eData storage location: \u003ccode\u003e~/logs/logstash/elasticsearch-7.3.1/data/nodes/0\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eGo to \u003ccode\u003ehttp://localhost:9200/_cat/indices\u003c/code\u003e to see the list of indexes created.\u003c/li\u003e\n\u003cli\u003ewhen indices status is \u003ccode\u003eyellow\u003c/code\u003e in development machine, setting \u003ccode\u003eindex.number_of_replicas\u003c/code\u003e to \u003ccode\u003e0\u003c/code\u003e will resolve the issue. It will be available in kibana UI -\u0026gt; management menu -\u0026gt; elasticsearch -\u0026gt; index management -\u0026gt; edit settings\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"filebeat\"\u003eFilebeat\u003c/h2\u003e\n\u003ch3 id=\"mac-2\"\u003eMac\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003ewhile using filebeat with any module, we need to enable it. for that, the following config setting needs to be done:\u003cpre\u003e\u003ccode\u003efilebeat.config.modules:\nenabled: true\npath: ${path.config}/modules.d/*.yml\u003c/code\u003e\u003c/pre\u003efollowed by\u003cpre\u003e\u003ccode\u003e./filebeat modules enable logstash\u003c/code\u003e\u003c/pre\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"analysis\"\u003eAnalysis\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eQuery\u003c/li\u003e\n\u003cli\u003eMapping parameter\u003c/li\u003e\n\u003cli\u003eIndex setting\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"analyzer\"\u003eAnalyzer\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eIt tokenises the text i.e. it splits them into tokens using tokeniser\u003c/li\u003e\n\u003cli\u003eThen we have n number of token filters to filter, say, \u003cul\u003e\n\u003cli\u003estop words like ‘a’, ‘the’ etc\u003c/li\u003e\n\u003cli\u003euppercase to lowercase\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eapi\u003cpre\u003e\u003ccode\u003ePOST \u0026lt;index-name\u0026gt;/_analyze\u003c/code\u003e\u003c/pre\u003e\u003c/li\u003e\n\u003cli\u003etypes\u003cul\u003e\n\u003cli\u003estandard\u003c/li\u003e\n\u003cli\u003ewhitespace\u003c/li\u003e\n\u003cli\u003esimple\u003c/li\u003e\n\u003cli\u003ekeyword\u003c/li\u003e\n\u003cli\u003estop: stop word, stopword_path\u003c/li\u003e\n\u003cli\u003epattern: stopword, stopword_path, pattern, lowercase\u003c/li\u003e\n\u003cli\u003ecustom: tokeniser, char_filter, filter\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"tokeniser\"\u003eTokeniser\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eword\u003cul\u003e\n\u003cli\u003estandard\u003c/li\u003e\n\u003cli\u003elowercase\u003c/li\u003e\n\u003cli\u003ewhitespace\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003epartial\u003cul\u003e\n\u003cli\u003engram\u003c/li\u003e\n\u003cli\u003eedge_ngram\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003estructured\u003cul\u003e\n\u003cli\u003ekeyword\u003c/li\u003e\n\u003cli\u003epattern\u003c/li\u003e\n\u003cli\u003esimple_pattern\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n","frontmatter":"title: ELK with filebeats"}},{"location":"/effective-communication/","markdown":{"attributes":{"title":"Effective Communication"},"body":"","frontmatter":"title: Effective Communication"}},{"location":"/effective-communication/presentation/","markdown":{"attributes":{"title":"Effective Presentation"},"body":"\u003ch1 id=\"effective-presentation\"\u003eEffective Presentation\u003c/h1\u003e\n\u003ch2 id=\"intro--start\"\u003eIntro / Start\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eBegin with a question that is going to get answered in the presentation. E.g:- \u003ca href=\"https://www.youtube.com/watch?v=1WM-LsH6tKc\u0026amp;list=PLMPZQTftRCS8Pp4wiiUruly5ODScvAwcQ\u0026amp;index=20\"\u003ehttps://www.youtube.com/watch?v=1WM-LsH6tKc\u0026amp;list=PLMPZQTftRCS8Pp4wiiUruly5ODScvAwcQ\u0026amp;index=20\u003c/a\u003e\u003ch3 id=\"key-ideas\"\u003eKey Ideas\u003c/h3\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n","frontmatter":"title: Effective Presentation"}},{"location":"/docker/","markdown":{"attributes":{"title":"Docker Introduction"},"body":"\u003ch1 id=\"docker\"\u003eDocker\u003c/h1\u003e\n\u003ch3 id=\"network\"\u003eNetwork\u003c/h3\u003e\n\u003ch3 id=\"network-namespace\"\u003eNetwork namespace\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003emultiple instances can be run in a \u003ccode\u003enetwork namespace\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eThe containers in a namespace or in separate namespace can be attached to one or more network(s)\u003c/li\u003e\n\u003cli\u003eDifference between having two containers in same network and network namespace is that, in the former the containers can freely communicate over all ports in network whereas in latter, they communicate on all ports using localhost itself \u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"volumes\"\u003eVolumes\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003enamed declarations can be done like\n\u003ccode\u003e--volume \u0026lt;vol_name\u0026gt;:/path/to/mount\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003enamed volumes will be created when not exists, or else reused everytime\u003c/li\u003e\n\u003cli\u003eWhen being used in Mac/Windows, docker runs on VM. So, we cannot view the files directly. To view the filesystem, use:\u003cpre\u003e\u003ccode class=\"language-bash\"\u003edocker run --rm -it -v /:/vm-root alpine:edge ls -l /vm-root\u003c/code\u003e\u003c/pre\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cem\u003eRef*\u003c/em\u003e: \u003ca href=\"https://forums.docker.com/t/host-path-of-volume/12277/2\"\u003ehttps://forums.docker.com/t/host-path-of-volume/12277/2\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"to-dos\"\u003eTo-Dos:\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eDistroless implementation \u003ca href=\"https://github.com/GoogleContainerTools/distroless/blob/master/examples/nodejs/Dockerfile\"\u003edistroless/Dockerfile at master · GoogleContainerTools/distroless · GitHub\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n","frontmatter":"title: Docker Introduction"}},{"location":"/docker/shell-vs-exec-form/","markdown":{"attributes":{"title":"Shell vs Exec Form"},"body":"\u003ch1 id=\"shell-vs-exec-form\"\u003eShell vs Exec Form\u003c/h1\u003e\n\u003cp\u003e\u003ccode\u003eSHELL\u003c/code\u003e form uses \u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e/bin/bash -c \u0026quot;command\u0026quot;\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eHere, the command will be child of \u003ccode\u003e/bin/bash\u003c/code\u003e. When we use \u003ccode\u003edocker exec\u003c/code\u003e, it will be hard to send signal to command because it will be sent to \u003ccode\u003e/bin/bash\u003c/code\u003e instead of getting sent to the command itself. \u003ccode\u003eExec\u003c/code\u003e form will be executed without a shell, directly it will be run.\nWhen both \u003ccode\u003eENTRYPOINT\u003c/code\u003e and \u003ccode\u003eCMD\u003c/code\u003e are used, \u003ccode\u003eCMD\u003c/code\u003e strings are appended to \u003ccode\u003eENTRYPOINT\u003c/code\u003e. So, the argument which we supposed to be easily overridden are specified in \u003ccode\u003eCMD\u003c/code\u003e, other parent or less frequently changing ones by \u003ccode\u003eENTRYPOINT\u003c/code\u003e. During this combination, always we use \u003ccode\u003eEXEC\u003c/code\u003e form.\u003c/p\u003e\n","frontmatter":"title: Shell vs Exec Form"}},{"location":"/docker/entrypoint-vs-cmd/","markdown":{"attributes":{"title":"Entrypoint vs CMD"},"body":"\u003ch1 id=\"entrypoint-vs-cmd\"\u003eEntrypoint vs CMD\u003c/h1\u003e\n\u003cp\u003eFor a image to be runnable, it should have \u003ccode\u003eENTRYPOINT\u003c/code\u003e or \u003ccode\u003eCMD\u003c/code\u003e. Without that, the image will result in an error. They are default executable which user can override. \u003ccode\u003eCMD\u003c/code\u003e can be overridden directly as below:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003edocker run --name ubuntu_bash -it ubuntu:latest bash\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWhereas, \u003ccode\u003eENTRYPOINT\u003c/code\u003e can be overridden as:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003edocker run --entrypoint \u0026lt;command\u0026gt;\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eDue to ease of override, \u003ccode\u003eCMD\u003c/code\u003e is preferred. In scenarios where we do not expect the user to override, we can opt for \u003ccode\u003eENTRYPOINT\u003c/code\u003e.\u003c/p\u003e\n","frontmatter":"title: Entrypoint vs CMD"}},{"location":"/docker/docker-machine/","markdown":{"attributes":{"title":"Docker Machine"},"body":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e$ docker-machine create --driver virtualbox default\n\n$ docker-machine ls\nNAME      ACTIVE   DRIVER       STATE     URL                         SWARM   DOCKER     ERRORS\ndefault   -        virtualbox   Running   tcp://192.168.99.106:2376           v19.03.5   \u003c/code\u003e\u003c/pre\u003e\n","frontmatter":"title: Docker Machine"}},{"location":"/docker/automations/","markdown":{"attributes":{"title":"Docker One-liner automations"},"body":"\u003cpre\u003e\u003ccode\u003edocker images | while read img; do\n    docker image rm $(grep -E \u0026#39;^\u0026lt;none\u0026gt;\u0026#39; | awk \u0026#39;{print $3}\u0026#39;);\ndone\u003c/code\u003e\u003c/pre\u003e","frontmatter":"title: Docker One-liner automations"}},{"location":"/db/","markdown":{"attributes":{"title":"Database Systems"},"body":"","frontmatter":"title: Database Systems"}},{"location":"/db/mongodb/","markdown":{"attributes":{"title":"Mongo DB"},"body":"","frontmatter":"title: Mongo DB"}},{"location":"/db/mongodb/client-cli/","markdown":{"attributes":{"title":"Tips working on Mongo Client CLI"},"body":"\u003ch2 id=\"prettify-cli-output\"\u003ePrettify CLI output\u003c/h2\u003e\n\u003ch3 id=\"temporary\"\u003eTemporary\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003edb.collection.find().pretty()\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"permananent\"\u003ePermananent\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003eDBQuery.prototype._prettyShell = true\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eRef: \u003ca href=\"https://stackoverflow.com/questions/9146123/pretty-print-in-mongodb-shell-as-default\"\u003ehttps://stackoverflow.com/questions/9146123/pretty-print-in-mongodb-shell-as-default\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"db-admin-commands\"\u003eDB Admin commands\u003c/h2\u003e\n\u003cpre\u003e\u003ccode\u003e# To restore from dump into different db and collection name\nmongorestore -v --host localhost:27017 -d \u0026quot;database_name\u0026quot; -c \u0026quot;collection_name\u0026quot; --dir /path/to/dump/data.bson  --objcheck\u003c/code\u003e\u003c/pre\u003e","frontmatter":"title: Tips working on Mongo Client CLI"}},{"location":"/dart/","markdown":{"attributes":{"title":"Dart - Introduction"},"body":"","frontmatter":"title: Dart - Introduction"}},{"location":"/dart/flutter/","markdown":{"attributes":{"title":"Flutter App - Introduction"},"body":"","frontmatter":"title: Flutter App - Introduction"}},{"location":"/dart/flutter/json_serializable/","markdown":{"attributes":{"title":"Dart Flutter json_serializable","description":"Utility to serialize and deserialize JSON objects in Dart / Flutter. This package depends on json_annotations and build_runner"},"body":"\u003ch1 id=\"json_serializable\"\u003ejson_serializable\u003c/h1\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eUnlike languages like NodeJs / Javascript or Python, which handles JSON values very easily, statically typed languages like Dart can be little challenging to implement the serialization and deserialization. For small projects, we can write serialization and deserialization by hand. For larger projects the boilerplate code itself will consume a lot of dev hours. So, we switch to \u003ca href=\"https://pub.dev/packages/json_serializable\"\u003ejson_serializable | Dart Package\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eHere, we take an example of \u0026quot;Books - Authors - Publishers\u0026quot;.\u003c/p\u003e\n\u003ch2 id=\"installation\"\u003eInstallation\u003c/h2\u003e\n\u003cp\u003eIn \u003ccode\u003epubspec.yaml\u003c/code\u003e file, you can declare the dependencies it as follows:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-yaml\"\u003edependencies:\n  json_annotation: ^3.0.1\n\ndev_dependencies:\n  build_runner: ^1.7.2\n  json_serializable: ^3.2.5\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow you can \u003ccode\u003epub get\u003c/code\u003e to install all the dependencies.\u003c/p\u003e\n\u003ch2 id=\"usage\"\u003eUsage\u003c/h2\u003e\n\u003ch3 id=\"project-directory-structure\"\u003eProject directory structure\u003c/h3\u003e\n\u003cp\u003eGenerally, we have \u003ccode\u003edart\u003c/code\u003e file in a \u003ccode\u003emodels\u003c/code\u003e directory like below\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003elib\n├── layout\n│   ├── primary.dart\n│   └── campaign.dart\n├── main.dart\n├── models\n│   ├── book.dart\n│   ├── author.dart\n│   ├── publisher.dart\n├── screens\n│   ├── dashboard.dart\n│   ├── loading.dart\n│   ├── login.dart\n│   ├── root.dart\n└── widgets\n    ├── book_list.dart\n    ├── author_list.dart\n    ├── publisher_list.dart\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id=\"class-declaration\"\u003eClass declaration\u003c/h3\u003e\n\u003cp\u003eInside \u003ccode\u003ebook.dart\u003c/code\u003e, we would have defined the class \u003ccode\u003eBook\u003c/code\u003e.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-dart\"\u003eclass Book {\n  String name;\n  String ISBN;\n  List\u0026lt;Author\u0026gt; authors;\n  Publisher publisher;\n  double price;\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eSimilarly for \u003ccode\u003eAuthor\u003c/code\u003e and \u003ccode\u003ePublisher\u003c/code\u003e, we have something like:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-dart\"\u003eclass Author {\n    String name;\n    int age;\n    int id;\n    List\u0026lt;Book\u0026gt; booksAuthored;\n}\n\nclass Publisher {\n    String name;\n    List\u0026lt;Book\u0026gt; booksPublished;\n}\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id=\"the-main-part\"\u003eThe main part\u003c/h3\u003e\n\u003cp\u003eSimply adding the annotation \u003ccode\u003e@JsonSerializable\u003c/code\u003e is enough to create the corresponding part files during build time.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-dart\"\u003eimport \u0026#39;package:json_annotation/json_annotation.dart\u0026#39;;\n\npart \u0026#39;book.g.dart\u0026#39;;\n\n@JsonSerializable\nclass Book {\n    // ...\n}\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003eLine 1: Since we are adding annotations to the file, we need to import \u003ccode\u003ejson_annotation\u003c/code\u003e package added in \u003ccode\u003edependencies\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003eLine 3: The build will generate a file with name \u003ccode\u003e\u0026lt;filename\u0026gt;.g.dart\u003c/code\u003e. So, the definitions for \u003ccode\u003efromJson\u003c/code\u003e and \u003ccode\u003etoJson\u003c/code\u003e will be available there. If the reference those functions from here, it will throw error. Since part of this file is separately available under another file named \u003ccode\u003ebook.g.dart\u003c/code\u003e, we need to add this line here.\u003c/li\u003e\n\u003cli\u003eLine 5: Annotation to generate the necessary functions like \u003ccode\u003e_$bookFromJson\u003c/code\u003e and \u003ccode\u003e_$bookToJson\u003c/code\u003e. These names are auto generated by the package.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"build\"\u003eBuild\u003c/h2\u003e\n\u003cp\u003eWe need to trigger the build to generate the corresponding \u003ccode\u003ebook.g.dart\u003c/code\u003e, \u003ccode\u003eauthor.g.dart\u003c/code\u003e and \u003ccode\u003epublishser.g.dart\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"references\"\u003eReferences\u003c/h2\u003e\n\u003cp\u003eTwo examples are give as part of main library itself:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/dart-lang/json_serializable/blob/master/example/lib/example.dart\"\u003ejson_serializable/example.dart at master · dart-lang/json_serializable · GitHub\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/dart-lang/json_serializable/blob/master/example/lib/json_converter_example.dart\"\u003ejson_serializable/json_converter_example.dart at master · dart-lang/json_serializable · GitHub\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n","frontmatter":"title: Dart Flutter json_serializable\ndescription: Utility to serialize and deserialize JSON objects in Dart / Flutter. This package depends on json_annotations and build_runner"}},{"location":"/cpp/","markdown":{"attributes":{"title":"CPP Introduction"},"body":"\u003ch1 id=\"c-basics\"\u003eC++ Basics\u003c/h1\u003e\n\u003col\u003e\n\u003cli\u003ePreprocessing\u003c/li\u003e\n\u003cli\u003eCompiling\u003c/li\u003e\n\u003cli\u003eAssembling compiled files\u003c/li\u003e\n\u003cli\u003eLinking object code file to create executable\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"preprocessing\"\u003ePreprocessing\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eheader files declarations are replace with the whole file, creating an expanded source code\u003c/li\u003e\n\u003cli\u003ethis is compiled to assembly lang code\u003c/li\u003e\n\u003cli\u003eassembler converts it into object code\u003c/li\u003e\n\u003cli\u003eobject code file is linked together with object coe files for any library functions to produce executables\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"include-guards\"\u003eInclude guards\u003c/h3\u003e\n\u003cp\u003eWhen we include a header file, which gets included as a part of some other header file, multiple definitions occur. This can be overcome by:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-cpp\"\u003e#ifndef \u0026lt;unique_name\u0026gt;\n  #define \u0026lt;unique_name\u0026gt;\n#endif\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003ee.g:- While including \u003ccode\u003elogger.hpp\u003c/code\u003e, we can define the \u003ccode\u003eunique_name\u003c/code\u003e as \u003ccode\u003eLOGGER_HPP\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"compiling\"\u003eCompiling\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eSyntax check\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"compiler\"\u003eCompiler\u003c/h3\u003e\n\u003ch4 id=\"options\"\u003eOptions\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003e-c\u003c/code\u003e: compiles the source code into object code file instead of generating the executable.\u003cpre\u003e\u003ccode class=\"language-sh\"\u003eg++ -c -o myfile.obj myfile.cpp\u003c/code\u003e\u003c/pre\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e-I\u003c/code\u003e: when we include custom header files, we need to specify its \u003ccode\u003einclude\u003c/code\u003e directory\u003cpre\u003e\u003ccode class=\"language-sh\"\u003eg++ -c -I include/ -o myfile.obj myfile.cpp\u003c/code\u003e\u003c/pre\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"linking\"\u003eLinking\u003c/h2\u003e\n\u003cpre\u003e\u003ccode class=\"language-sh\"\u003eg++ main.obj mylib.obj -o main\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eTo compile source files without producing intermediate state:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-sh\"\u003eg++ -I include/ mylib.cpp main.cpp -o main\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"datatypes\"\u003eDatatypes\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eint (4 bytes)\u003c/li\u003e\n\u003cli\u003eshort int ()\u003c/li\u003e\n\u003cli\u003elong int ()\u003c/li\u003e\n\u003cli\u003elong long int ()\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"debugging\"\u003eDebugging\u003c/h2\u003e\n\u003ch3 id=\"lldb\"\u003elldb\u003c/h3\u003e\n\u003ch4 id=\"examples\"\u003eexamples\u003c/h4\u003e\n\u003ch5 id=\"console-debug\"\u003econsole debug\u003c/h5\u003e\n\u003cul\u003e\n\u003cli\u003eEvaluating variables and methods\u003cul\u003e\n\u003cli\u003ep (int)strlen(str)\n(int) $1 = 4\u003c/li\u003e\n\u003cli\u003ep (char*)str\n(char *) $2 = \u0026quot;abc\u0026quot;\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n","frontmatter":"title: CPP Introduction"}},{"location":"/cpp/debugging/","markdown":{"attributes":{"title":"CPP Debugging"},"body":"\u003ch1 id=\"c-debugger\"\u003eC++ debugger\u003c/h1\u003e\n\u003ch2 id=\"gdb\"\u003egdb\u003c/h2\u003e\n\u003cp\u003eIn \u003ccode\u003egdb\u003c/code\u003e we have got \u003ccode\u003enext\u003c/code\u003e and \u003ccode\u003estep\u003c/code\u003e which are equivalent of pressing \u003ccode\u003eF10\u003c/code\u003e and \u003ccode\u003eF11\u003c/code\u003e respectively i.e. \u003ccode\u003enext\u003c/code\u003e goes to the following line by executing the function, if any, in the current line. Whereas \u003ccode\u003estep\u003c/code\u003e steps into the code of the function in current line, if any.\u003c/p\u003e\n\u003ch2 id=\"lldb-macosx\"\u003elldb (macOSx)\u003c/h2\u003e\n","frontmatter":"title: CPP Debugging"}},{"location":"/computing-theory/","markdown":{"attributes":{"title":"Computing Theory"},"body":"","frontmatter":"title: Computing Theory"}},{"location":"/computing-theory/DNS/","markdown":{"attributes":{"title":"DNS Basics simplified","keywords":"DNS,records,zones"},"body":"\u003ch1 id=\"dns-basics\"\u003eDNS Basics\u003c/h1\u003e\n\u003ch2 id=\"tools\"\u003eTools\u003c/h2\u003e\n\u003ch3 id=\"dig\"\u003edig\u003c/h3\u003e\n\u003ch2 id=\"records\"\u003eRecords\u003c/h2\u003e\n\u003ch3 id=\"a-record\"\u003eA record\u003c/h3\u003e\n\u003ch3 id=\"soa-record\"\u003eSOA record\u003c/h3\u003e\n\u003ch3 id=\"ns-record\"\u003eNS record\u003c/h3\u003e\n\u003ch3 id=\"cname-record\"\u003eCNAME record\u003c/h3\u003e\n\u003ch3 id=\"alias-record\"\u003eALIAS record\u003c/h3\u003e\n\u003ch3 id=\"aaaa-record\"\u003eAAAA record\u003c/h3\u003e\n\u003ch3 id=\"txt-record\"\u003eTXT record\u003c/h3\u003e\n\u003ch3 id=\"srv-record\"\u003eSRV record\u003c/h3\u003e\n\u003ch3 id=\"cert-record\"\u003eCERT record\u003c/h3\u003e\n\u003ch3 id=\"ptr-record\"\u003ePTR record\u003c/h3\u003e\n\u003ch2 id=\"dns-zones\"\u003eDNS Zones\u003c/h2\u003e\n\u003ch3 id=\"zone-files\"\u003eZone files\u003c/h3\u003e\n\u003ch2 id=\"classifications\"\u003eClassifications\u003c/h2\u003e\n\u003ch3 id=\"dns-queries\"\u003eDNS Queries\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eRecursive\u003c/li\u003e\n\u003cli\u003eIterative\u003c/li\u003e\n\u003cli\u003eNon-Recursive\u003ch3 id=\"dns-server-types\"\u003eDNS Server types\u003c/h3\u003e\n\u003c/li\u003e\n\u003cli\u003eDNS Resolver\u003c/li\u003e\n\u003cli\u003eDNS Root Server\u003c/li\u003e\n\u003cli\u003eAuthoritative Name Server\u003c/li\u003e\n\u003c/ul\u003e\n","frontmatter":"title: DNS Basics simplified\nkeywords: DNS,records,zones"}},{"location":"/aws/","markdown":{"attributes":{"title":"AWS"},"body":"","frontmatter":"title: AWS"}},{"location":"/aws/xray/","markdown":{"attributes":{"title":"AWS X-Ray"},"body":"","frontmatter":"title: AWS X-Ray"}},{"location":"/aws/xray/basics/","markdown":{"attributes":{"title":"X-ray basics - AWS"},"body":"\u003ch1 id=\"aws-x-ray-basics\"\u003eAWS X-Ray basics\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/aws/aws-xray-sdk-node/issues/85#issuecomment-448821172\"\u003ehttps://github.com/aws/aws-xray-sdk-node/issues/85#issuecomment-448821172\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"references\"\u003eReferences\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/functionalone/aws-least-privilege\"\u003eGitHub - functionalone/aws-least-privilege: Use AWS X-Ray to reach Least Privilege\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://medium.com/@glicht/using-aws-x-ray-to-achieve-least-privilege-permissions-93dfd6701318\"\u003eUsing AWS X-Ray to achieve Least Privilege Permissions\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/glicht/serverless-stack-demo-api/tree/add-xray\"\u003eGitHub - glicht/serverless-stack-demo-api at add-xray\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n","frontmatter":"title: X-ray basics - AWS"}},{"location":"/aws/vpc/","markdown":{"attributes":{"title":"VPC - AWS"},"body":"","frontmatter":"title: VPC - AWS"}},{"location":"/aws/vpc/best-practices/","markdown":{"attributes":{"title":"VPC Best Practices - AWS"},"body":"","frontmatter":"title: VPC Best Practices - AWS"}},{"location":"/aws/vpc/best-practices/new-aws-account-configure/","markdown":{"attributes":{"title":"New account best practices"},"body":"\u003ch2 id=\"cloudformation\"\u003eCloudformation\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eAssign a service role to the stack for creating the resources rather than directly using the permissions of a console/CLI user.\u003c/li\u003e\n\u003cli\u003eSecurity posture of VPC can be improved by configuring CFN to use an interface VPC endpoint. \n  Ref:- \u003ca href=\"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cfn-vpce-bucketnames.html\"\u003eSetting Up VPC Endpoints for AWS CloudFormation - AWS CloudFormation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eOn empty/new AWS account, we need to create the following before proceeding to launch a CFN stack:\u003cul\u003e\n\u003cli\u003eS3 bucket to store the CFN stack template\u003c/li\u003e\n\u003cli\u003eservice role for CFN\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"resouces-required\"\u003eResouces required\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eAWS::EC2::SecurityGroup\u003c/li\u003e\n\u003cli\u003eNACL\u003c/li\u003e\n\u003cli\u003eAWS::EC2::VPC\u003c/li\u003e\n\u003cli\u003eSubnets\u003c/li\u003e\n\u003cli\u003eInternet gateway\u003c/li\u003e\n\u003c/ul\u003e\n","frontmatter":"title: New account best practices"}},{"location":"/aws/serverless/","markdown":{"attributes":{"title":"AWS Serverless"},"body":"","frontmatter":"title: AWS Serverless"}},{"location":"/aws/serverless/sam/","markdown":{"attributes":{"title":"AWS SAM serverless"},"body":"\u003ch1 id=\"aws-sam-serverless\"\u003eAWS SAM serverless\u003c/h1\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003ch2 id=\"steps\"\u003eSteps\u003c/h2\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003esam init\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"troubleshoot\"\u003eTroubleshoot\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e403 - \u0026quot;message forbidden\u0026quot;\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre\u003e\u003ccode class=\"language-json\"\u003e{ \u0026quot;message\u0026quot;: \u0026quot;forbidden\u0026quot; }\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe is a good probability that when API Gateway Endpoints are created, the path we hit should have \u0026quot;stage\u0026quot; included.\u003c/p\u003e\n\u003ch2 id=\"extra-miles\"\u003eExtra miles\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eWhen \u003ccode\u003esam deploy\u003c/code\u003e fails, it is pushed to \u003ccode\u003eROLLBACK_COMPLETE\u003c/code\u003e state. We need to delete it and proceed with re-deployment.\u003c/li\u003e\n\u003cli\u003eWe need to package SAM template before we deploy, else it will not detect changes to create \u003ccode\u003echangeSets\u003c/code\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"references\"\u003eReferences\u003c/h2\u003e\n\u003ch3 id=\"examples\"\u003eExamples\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/awslabs/serverless-application-model/blob/master/examples/2016-10-31/api_swagger_cors/template.yaml\"\u003eserverless-application-model/template.yaml at master · awslabs/serverless-application-model · GitHub\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n","frontmatter":"title: AWS SAM serverless"}},{"location":"/aws/serverless/sam/troubleshoot/","markdown":{"attributes":{"title":"SAM Lambda troubleshoot - AWS"},"body":"\u003ch1 id=\"aws-sam-lambda-troubleshoot\"\u003eAWS SAM Lambda troubleshoot\u003c/h1\u003e\n\u003ch2 id=\"sam-unable-to-connect-endpoint-url\"\u003eSAM unable to connect endpoint URL\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/awslabs/aws-sam-cli/issues/102#issuecomment-326177151\"\u003ehttps://github.com/awslabs/aws-sam-cli/issues/102#issuecomment-326177151\u003c/a\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003esudo ifconfig lo0 alias 172.16.123.1\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"language-javascript\"\u003eAWS.config.update({\n    endpoint: \u0026quot;http://172.16.123.1:8000\u0026quot;\n});\u003c/code\u003e\u003c/pre\u003e\n","frontmatter":"title: SAM Lambda troubleshoot - AWS"}},{"location":"/aws/serverless/sam/debugging/","markdown":{"attributes":{"title":"Debugging SAM lambda - AWS"},"body":"\u003ch1 id=\"aws-sam-lambda-local-debugging\"\u003eAWS SAM Lambda local debugging\u003c/h1\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e# General Syntax\n# sam local invoke \u0026lt;FunctionName\u0026gt; -e \u0026lt;eventFile.json\u0026gt; -d 5858\n# Example:\nsam local invoke HelloWorldFunction -e event.json -d 5858\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWe will get the URL to attach the debugger\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://pasteboard.co/IyQHOV3.png\"\u003eSAM local invoke debugging - Image on Pasteboard\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eOur function will be available in the docker container under \u003ccode\u003e/var/task/index.js\u003c/code\u003e. The SDK inbuilt function will be available in \u003ccode\u003e/var/runtime\u003c/code\u003e directory. \u003c/p\u003e\n\u003cp\u003eIn debugger, until we require/import the files, we will not able to see them listed. for that, we need to go to \u003ccode\u003e/var/runtime/UserFunction.js\u003c/code\u003e and place debugger in \u003ccode\u003e_tryRequire\u003c/code\u003e function. Once it resolves path and loads the file using \u003ccode\u003e_canLoadAsFile\u003c/code\u003e, we can view the files listed in the debugger to place the breakpoints.\u003c/p\u003e\n\u003cp\u003eHappy debugging..!\u003c/p\u003e\n","frontmatter":"title: Debugging SAM lambda - AWS"}},{"location":"/aws/opsworks/","markdown":{"attributes":{"title":"OpsWorks"},"body":"","frontmatter":"title: OpsWorks"}},{"location":"/aws/opsworks/detailed-introduction/","markdown":{"attributes":{"title":"Opsworks detailed introduction - AWS"},"body":"\u003ch1 id=\"aws-opsworks---detailed-introduction\"\u003eAWS Opsworks - Detailed Introduction\u003c/h1\u003e\n\u003ch2 id=\"opsworks-inner-workings\"\u003eOpsworks inner workings\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eRuby interpreter is located at \u003ccode\u003e/opt/aws/opsworks/local/bin/ruby\u003c/code\u003e\nOther executables are present at \u003ccode\u003e/opt/aws/opsworks/current\u003c/code\u003e like \u003ccode\u003eopsworks-agent\u003c/code\u003e, \u003ccode\u003eopsworks-agent-cli\u003c/code\u003e etc\u003c/li\u003e\n\u003cli\u003eWhen setup is run again \u003ccode\u003eaws_opsworks_users::default\u003c/code\u003e recipe is run, which includes the following actions:\u003cul\u003e\n\u003cli\u003ekill all processes of users\u003c/li\u003e\n\u003cli\u003eremove user (-r) options, which clears its home directory\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eWhen creating \u003ccode\u003euser\u003c/code\u003e using \u003ccode\u003echef\u003c/code\u003e, following things we need to be careful about\u003cul\u003e\n\u003cli\u003eThe application that we deploy as a user should be in directory other than its home directory because if some process executes \u003ccode\u003euserdel -r \u0026lt;username\u0026gt;\u003c/code\u003e all our files will be lost, especially persistent storage\u003c/li\u003e\n\u003cli\u003eWe need to be careful about \u003ccode\u003emanage_home\u003c/code\u003e being set to \u003ccode\u003etrue\u003c/code\u003e because of following line of command:\n\u003ccode\u003e/opt/aws/opsworks/current/vendor/bundle/ruby/\u0026lt;ruby_version\u0026gt;/gems/chef-\u0026lt;chef_version\u0026gt;/spec/support/shared/unit/provider/useradd_based_user_provider.rb:    it \u0026quot;should run userdel with the new resources user name and -r if manage_home is true\u0026quot; do\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eLogs for each run is stored in \u003ccode\u003e/var/chef/runs\u003c/code\u003e,\navailable at \u003ccode\u003ehttps://console.aws.amazon.com/opsworks/home?region=\u0026lt;region_name\u0026gt;#/stack/\u0026lt;stack_id\u0026gt;/instances/\u0026lt;instance_id\u0026gt;/log/\u0026lt;run_id\u0026gt;\u003c/code\u003e\n(Here, run id is obtained from \u003ccode\u003e/var/chef/runs\u003c/code\u003e)\u003c/li\u003e\n\u003c/ul\u003e\n","frontmatter":"title: Opsworks detailed introduction - AWS"}},{"location":"/aws/kms/","markdown":{"attributes":{"title":"KMS Encryption and Decryption","description":"Encrypt and decrypt secure text, passwords and keys using AWS KMS service using CLI"},"body":"\u003ch1 id=\"encrypt-and-decrypt-keys-using-aws-kms\"\u003eEncrypt and Decrypt Keys using AWS KMS\u003c/h1\u003e\n\u003ch2 id=\"encryption\"\u003eEncryption\u003c/h2\u003e\n\u003cp\u003eFor this we need to create a \u0026quot;Customer Managed Key\u0026quot; using either console or CLI, or any other programmatic way. Once we do that, we obtain a \u003ccode\u003ekey-id\u003c/code\u003e to use for encryption. We do not require \u003ccode\u003ekey-id\u003c/code\u003e for decryption. The reason is that, the encrypted hash will be self sufficiently having all the required data for decryption. We can set alias name and description for the keys along with tags for easy identification of the key\u0026#39;s purpose.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003eaws kms encrypt \\\n--key-id XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX \\\n--plaintext \u0026quot;secret text for encryption\u0026quot; \\\n--output text \\\n--query CiphertextBlob\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe drawback with above method is, if someone or admin checks the history, it will be visible as clear text and in many organisation it will be a clear violation of security policies. For that, we can store the password in a text file and call that file here. Say,\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003eaws kms encrypt \\\n--key-id XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX \\\n--plaintext fileb://secretfile \\\n--output text \\\n--query CiphertextBlob\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWhen we do this, the resulting hash will be \u003ccode\u003ebase64\u003c/code\u003e encoded. If we decode it, it will result in a binary value which we cannot store in yaml file. Or else, we can have the binary string written to a separate file and reference that file in our yaml files.\nFor decoding and storing in a file,\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003eaws kms encrypt \\\n--key-id XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX \\\n--plaintext fileb://secretfile \\\n--output text \\\n--query CiphertextBlob | base64 --decode \u0026gt; binaryFileName\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"decryption\"\u003eDecryption\u003c/h2\u003e\n\u003cp\u003eFor decryption,\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003eaws kms decrypt \\\n--ciphertext-blob fileb://binaryFileName\n--output text \\\n--query Plaintext\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eNote:- Again, the resulting text will be base64 encoded\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIf you have an encrypted base64 text string to obtain back the original secret key, you can do:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003eaws kms decrypt \\\n--ciphertext-blob fileb://\u0026lt;(echo \u0026quot;encryptedBase64EncodedString\u0026quot; | base64 --decode)\n--output text \\\n--query Plaintext | base64 --decode\u003c/code\u003e\u003c/pre\u003e\n","frontmatter":"title: KMS Encryption and Decryption\ndescription: Encrypt and decrypt secure text, passwords and keys using AWS KMS service using CLI"}},{"location":"/aws/iam/instance-profile/","markdown":{"attributes":{"title":"IAM instance profile","description":"Role of Instance profile in EC2 application access management and IAM Role containment"},"body":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003eUsing the console, when we create IAM Role, an instance profile is automatically created with same name as that of the role.\u003c/li\u003e\n\u003cli\u003eRelation from instance profile to IAM role is one to one but the reverse is one to many i.e. only one role can be added to an instance profile but same role can be part of many instance profiles.\u003c/li\u003e\n\u003cli\u003eFrom instance metadata, security credentials can be retrieved from the path \u003ccode\u003eiam/security-credentials/\u0026lt;role_name\u0026gt;\u003c/code\u003e. So the application will get access to all the resources and actions allowed for the role.\u003c/li\u003e\n\u003cli\u003eAccording to AWS Documentation, instance profile is a container for IAM role to pass role information from AWS to EC2 after boot because the applications within EC2 machines run within a VM abstraction / enclosure.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"temporary-security-credentials\"\u003eTemporary Security Credentials\u003c/h2\u003e\n\u003cp\u003eThe temporary credentials can be obtained:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003efor AWS CLI, we can use roles for EC2\u003c/li\u003e\n\u003cli\u003eor for SDKs, use AWS STS API - \u003ca href=\"https://sts.amazonaws.com\"\u003eAWS Identity \u0026amp; Access Management - Amazon Web Services\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"curl\"\u003eCurl\u003c/h3\u003e\n\u003cp\u003eUsing curl, if we hit \u003ccode\u003ehttp://169.254.169.254/latest/meta-data/iam/security-credentials/\u0026lt;role_name\u0026gt;\u003c/code\u003e, we will obtain a JSON with following structure:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-json\"\u003e{\n  \u0026quot;Code\u0026quot; : \u0026quot;Success\u0026quot;,\n  \u0026quot;LastUpdated\u0026quot; : \u0026quot;2020-01-02T10:31:04Z\u0026quot;,\n  \u0026quot;Type\u0026quot; : \u0026quot;AWS-HMAC\u0026quot;,\n  \u0026quot;AccessKeyId\u0026quot; : \u0026quot;XXXXXXXXXXXXXXXXXX\u0026quot;,\n  \u0026quot;SecretAccessKey\u0026quot; : \u0026quot;xxxxxxxxxxxxxxxxxxxxxxxxx\u0026quot;,\n  \u0026quot;Token\u0026quot; : \u0026quot;xxxxxxxxxxxxxxxxxxxxxxxxxx==\u0026quot;,\n  \u0026quot;Expiration\u0026quot; : \u0026quot;2020-01-02T16:35:14Z\u0026quot;\n}\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eusing the above values we can set the following global variables:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003eexport AWS_ACCESS_KEY_ID=\u0026quot;XXXXXXXXXXXXXXXXXX\u0026quot;\nexport AWS_SECRET_ACCESS_KEY=\u0026quot;xxxxxxxxxxxxxxxxxxxxxxxxx\u0026quot;\nexpoert AWS_SESSION_TOKEN=\u0026quot;xxxxxxxxxxxxxxxxxxxxxxxxxx==\u0026quot;\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow, we are ready use the AWS CLI or SDK.\u003c/p\u003e\n","frontmatter":"title: IAM instance profile\ndescription: Role of Instance profile in EC2 application access management and IAM Role containment"}},{"location":"/aws/dynamodb/","markdown":{"attributes":{"title":"DynamoDB Introduction - AWS"},"body":"\u003ch1 id=\"dynamodb\"\u003eDynamoDB\u003c/h1\u003e\n\u003ch2 id=\"theory---behind-the-time\"\u003eTheory - behind the time\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eStrong consistency model - RDBMS, bcz one change in table reflects everywhere.\u003c/li\u003e\n\u003cli\u003eTo achieve speed geographically, user needs to write consistently to all DBs in world -\u0026gt; slow.\u003c/li\u003e\n\u003cli\u003eAt large scale, data were denormalized for reducing join cost. Only \u003cul\u003e\n\u003cli\u003e10% of queries are join. \u003c/li\u003e\n\u003cli\u003e70% are on primary key.\u003c/li\u003e\n\u003cli\u003e20% operate on single returned value.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eConsistency is important for financial sectors. But speed and availability is more important than consistency in other sectors, which is gained by compromising the latter -\u0026gt; eventual consistency model.\u003c/li\u003e\n\u003cli\u003eConsistent Hashing to spread rows across nodes for infinite scaling.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"expression\"\u003eExpression\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eConditional - conditional manipulation of item\u003c/li\u003e\n\u003cli\u003eProjection\u003c/li\u003e\n\u003cli\u003eUpdate\u003c/li\u003e\n\u003cli\u003eKey condition - query table with composite key and limit selected item\u003c/li\u003e\n\u003cli\u003efilter - reduce resultset\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"options\"\u003eOptions\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003econdition-expression\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eexpression-attribute-names\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eexpression-attribute-values\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ekey\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eupdate-expression\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"condition-expression-function-list\"\u003e\u003ccode\u003econdition-expression\u003c/code\u003e function list\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003eattribute_exists\u003c/li\u003e\n\u003cli\u003eattribute_not_exists\u003c/li\u003e\n\u003cli\u003eattribute_type\u003c/li\u003e\n\u003cli\u003ebegins_with\u003c/li\u003e\n\u003cli\u003econtains\u003c/li\u003e\n\u003cli\u003esize\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eHASH key supports only equal comparison operations\u003c/p\u003e\n\u003ch4 id=\"range-key-operations\"\u003eRANGE key operations\u003c/h4\u003e\n\u003cp\u003eThese expressions are valid only on RANGE and secondary indexes, not on HASH keys\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eBETWEEN AND\u003c/li\u003e\n\u003cli\u003erelational operators\u003c/li\u003e\n\u003cli\u003eBEGINS_WITH\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"update-expression-clauses\"\u003e\u003ccode\u003eupdate-expression\u003c/code\u003e clauses\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eSET\u003c/code\u003e - add or modify attr\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eREMOVE\u003c/code\u003e - remove attr\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eADD\u003c/code\u003e - increment/decrement number/set\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eDELETE\u003c/code\u003e - remove item from set\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"reason-for-using-expression-attribute-names\"\u003eReason for using \u003ccode\u003eexpression-attribute-names\u003c/code\u003e\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/ReservedWords.html\"\u003eReserved Words in DynamoDB - Amazon DynamoDB\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003econtains dot - to access nested items\u003c/li\u003e\n\u003cli\u003ename begins with number\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"multi-item-actions\"\u003eMulti-item actions\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003ecannot use the UpdateItem API call with a BatchWriteItem request\u003c/li\u003e\n\u003cli\u003ecannot specify conditions for your Put and Delete operations \u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ekey-condition-expression\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eselect\u003c/code\u003e -\u0026gt; \u003ccode\u003e--select COUNT\u003c/code\u003e to return just no of elements\u003c/li\u003e\n\u003cli\u003eparallel scan on \u003ccode\u003esegments\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"secondary-index\"\u003eSecondary index\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003esparse index (item with missing attribute dropped in indexing)\u003ch3 id=\"lsi\"\u003eLSI\u003c/h3\u003e\n\u003c/li\u003e\n\u003cli\u003eonly on composite key\u003c/li\u003e\n\u003cli\u003eonly during creation time\u003c/li\u003e\n\u003cli\u003ecan choose strong vs eventual consistency\u003ch3 id=\"gsi\"\u003eGSI\u003c/h3\u003e\n\u003c/li\u003e\n\u003cli\u003eseparate throughtput\u003c/li\u003e\n\u003cli\u003eeventual consistency\u003c/li\u003e\n\u003cli\u003eboth simple/complex schema\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"references\"\u003eReferences\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://t.co/OwhN4xzkSV\"\u003ehttps://www.youtube.com/watch?v=HaEPXoXVf2k\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf\"\u003eAmazon DynamoDB research paper\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.allthingsdistributed.com/2017/10/a-decade-of-dynamo.html\"\u003eA Decade of Dynamo: Powering the next wave of high-performance, internet-scale applications - All Things Distributed\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://en.wikipedia.org/wiki/Consistent_hashing\"\u003eConsistent hashing - Wikipedia\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n","frontmatter":"title: DynamoDB Introduction - AWS"}},{"location":"/aws/cloudformation/","markdown":{"attributes":{"title":"Cloudformation"},"body":"","frontmatter":"title: Cloudformation"}},{"location":"/aws/cloudformation/introduction-basics/","markdown":{"attributes":{"title":"Basics of AWS Cloudformation"},"body":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eResources\u003c/code\u003e is mandatory\u003c/li\u003e\n\u003cli\u003eEach resource in \u003ccode\u003eResources\u003c/code\u003e is given a logical name which can be referenced in other parts of the template using \u003ccode\u003eFn::Ref\u003c/code\u003e of \u003ccode\u003e!Ref\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eResources\u003c/code\u003e declaration requires \u003ccode\u003eProperties\u003c/code\u003e attribute to specify the resource details.\u003c/li\u003e\n\u003cli\u003eWhen AWS CloudFormation creates the resource, it generates a physical name that is based on the combination of the logical name, the stack name, and a unique ID.\u003c/li\u003e\n\u003cli\u003ePseudo parameters are resolved by AWS CloudFormation when you create the stack.\u003c/li\u003e\n\u003cli\u003eBy default, the cfn-hup daemon runs every 15 minutes, so it may take up to 15 minutes for the application to change once the stack has been updated.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"cloudformation-built-in-functions\"\u003eCloudformation built in functions\u003c/h2\u003e\n\u003ch3 id=\"cookbook\"\u003eCookbook\u003c/h3\u003e\n\u003ch4 id=\"cross-reference\"\u003eCross reference\u003c/h4\u003e\n\u003cp\u003eSay, we have a S3 resource with name \u003ccode\u003eRawDataStorage\u003c/code\u003e and we output the bucket\u0026#39;s name. We can get it from some other resource defined in the template as:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e!GetAtt RawDataStorage.Outputs.BucketName\u003c/code\u003e\u003c/pre\u003e","frontmatter":"title: Basics of AWS Cloudformation"}},{"location":"/aws/case-study/","markdown":{"attributes":{"title":"AWS Case studies"},"body":"","frontmatter":"title: AWS Case studies"}},{"location":"/aws/case-study/node-expressjs-s3-integration/","markdown":{"attributes":{"title":"Node ExpressJS and S3 Integration","description":"Basic code snippet for pushing data from a ExpressJS POST call to AWS S3 bucket"},"body":"\u003cpre\u003e\u003ccode class=\"language-javascript\"\u003econst express = require(\u0026#39;express\u0026#39;);\nconst AWS = require(\u0026#39;aws-sdk\u0026#39;);\n\nAWS.config.update({\n    accessKeyId: \u0026#39;xxxxxxxxxx\u0026#39;,\n    secretAccessKey: \u0026#39;XXXXXXXXXXXXXXXXX\u0026#39;,\n    region: \u0026#39;us-east-1\u0026#39;\n});\nconst s3 = new AWS.S3();\nconst PORT = parseInt(process.env.PORT, 10) || 3000;\nconst app = express();\napp.use(express.json());\n\napp.get(\u0026#39;/list-objects\u0026#39;, (req, res) =\u0026gt; {\n    s3.listObjects({\n        Bucket: \u0026#39;bucket-name\u0026#39;\n    }, (err, data) =\u0026gt; {\n        if (err) {\n            res.status(400).send(err);\n        } else {\n            res.status(200).send(\n                JSON.stringify(data, null, 4)\n            );\n        }\n    });\n});\n\napp.post(\u0026#39;/push-object\u0026#39;, (req, res) =\u0026gt; {\n    const fileStamp = Date.now().toString();\n    const data = JSON.stringify(req.body);\n    if (data) {\n        s3.upload({\n            Bucket: \u0026#39;bucket-name\u0026#39;,\n            Key: fileStamp,\n            Body: \n        }, (err, data) =\u0026gt; {\n            if (err) {\n                res.status(err.statusCode).send(err);\n            } else {\n                res.status(200).send(\u0026#39;Ok\u0026#39;);\n            }\n        });\n    } else {\n        res.status(400).send(\u0026#39;Empty body\u0026#39;);\n    }\n});\n\napp.listen(PORT, () =\u0026gt; console.log(`Started at Port: ${PORT}`));\n\u003c/code\u003e\u003c/pre\u003e\n","frontmatter":"title: Node ExpressJS and S3 Integration\ndescription: Basic code snippet for pushing data from a ExpressJS POST call to AWS S3 bucket"}},{"location":"/aws/EKS/","markdown":{"attributes":{"title":"EKS Introduction"},"body":"\u003ch2 id=\"gotchas\"\u003eGotchas\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eWhen creating a role for associating with a EKS cluster using console, Instance profile will not be created\u003cblockquote\u003e\n\u003cp\u003eThe console does not create an instance profile for a role that is not associated with Amazon EC2.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003c/li\u003e\n\u003cli\u003eRef:- \u003ca href=\"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2_instance-profiles.html\"\u003ehttps://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2_instance-profiles.html\u003c/a\u003e*\u003c/li\u003e\n\u003c/ul\u003e\n","frontmatter":"title: EKS Introduction"}},{"location":"/aws/EFS/","markdown":{"attributes":{"title":"EFS Introduction - AWS"},"body":"\u003ch1 id=\"efs\"\u003eEFS\u003c/h1\u003e\n\u003ch4 id=\"gotchas\"\u003eGotchas\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003efor mounting an EFS in an EC2, they should be having same security group.\u003c/li\u003e\n\u003cli\u003eCheck if NFS inbound port 2049 is needed to be in open\u003c/li\u003e\n\u003c/ul\u003e\n","frontmatter":"title: EFS Introduction - AWS"}},{"location":"/aws/Cloudtrail/","markdown":{"attributes":{"title":"Cloudtrail Introduction - AWS"},"body":"\u003ch1 id=\"cloudtrail\"\u003eCloudTrail\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003emonitoring APA activity from\u003cul\u003e\n\u003cli\u003econsole\u003c/li\u003e\n\u003cli\u003eaws-cli\u003c/li\u003e\n\u003cli\u003eSDKs\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eExample when data events logging for s3 are enable in cloudTrail, cloudWatch event rule is used to trigger lambda for authorization\u003c/li\u003e\n\u003cli\u003eWhen certain APA activity causes outage, we can view a list of those activities in cloutTrail and revert them\u003c/li\u003e\n\u003c/ul\u003e\n","frontmatter":"title: Cloudtrail Introduction - AWS"}},{"location":"/SEO/","markdown":{"attributes":{"title":"Search Engine Optimization - SEO","description":"Basics introduction points for search engine optimization like meta information and other important aspects"},"body":"\u003ch2 id=\"meta-data\"\u003eMeta Data\u003c/h2\u003e\n\u003ch4 id=\"title\"\u003eTitle\u003c/h4\u003e\n\u003cpre\u003e\u003ccode\u003elimits: 55 characters\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003ccode\u003e\u0026lt;title\u0026gt;\u003c/code\u003e is very important for SEO which is the top line displayed by search engines in SERP (Search Engine Results Page).\u003c/p\u003e\n\u003ch4 id=\"description\"\u003eDescription\u003c/h4\u003e\n\u003cpre\u003e\u003ccode\u003elimits: 150 - 165 characters\u003c/code\u003e\u003c/pre\u003e\u003ch4 id=\"keywords\"\u003eKeywords\u003c/h4\u003e\n","frontmatter":"title: Search Engine Optimization - SEO\ndescription: Basics introduction points for search engine optimization like meta information and other important aspects"}},{"location":"/SEO/reference-sites/","markdown":{"attributes":{"title":"SEO - Reference sites"},"body":"\u003ch1 id=\"reference-sites-for-seo\"\u003eReference Sites for SEO\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.impactbnd.com/blog/seo-statistics\"\u003ehttps://www.impactbnd.com/blog/seo-statistics\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://seotribunal.com/blog/stats-to-understand-seo/\"\u003ehttps://seotribunal.com/blog/stats-to-understand-seo/\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://unbounce.com/landing-pages/7-page-speed-stats-for-marketers/\"\u003ehttps://unbounce.com/landing-pages/7-page-speed-stats-for-marketers/\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n","frontmatter":"title: SEO - Reference sites"}},{"location":"/IDE/","markdown":{"attributes":{"title":"Code Editors / IDEs"},"body":"","frontmatter":"title: Code Editors / IDEs"}},{"location":"/IDE/VSCode/","markdown":{"attributes":{"title":"Microsoft Visual Code - VS Code"},"body":"","frontmatter":"title: Microsoft Visual Code - VS Code"}},{"location":"/IDE/VSCode/Debugging/","markdown":{"attributes":{"title":"VSCode Debugging"},"body":"\u003cp\u003eVS Code Debugging\u003c/p\u003e\n\u003ch2 id=\"launchjson-configurations\"\u003e\u003ccode\u003elaunch.json\u003c/code\u003e configurations\u003c/h2\u003e\n\u003ch3 id=\"cwd\"\u003e\u003ccode\u003ecwd\u003c/code\u003e\u003c/h3\u003e\n\u003cp\u003eWhen we refer any configure files, it is searched in the \u003ccode\u003eworkspaceRoot\u003c/code\u003e unless we set \u003ccode\u003ecwd\u003c/code\u003e. \u003ca href=\"\"\u003eReference\u003c/a\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-json\"\u003e{\n    \u0026quot;version\u0026quot;: \u0026quot;0.2.0\u0026quot;,\n    \u0026quot;configurations\u0026quot;: [\n        {\n            \u0026quot;type\u0026quot;: \u0026quot;node\u0026quot;,\n            \u0026quot;request\u0026quot;: \u0026quot;launch\u0026quot;,\n            \u0026quot;name\u0026quot;: \u0026quot;programName\u0026quot;,\n            \u0026quot;cwd\u0026quot;: \u0026quot;${workspaceRoot}/packages\u0026quot;,\n            \u0026quot;program\u0026quot;: \u0026quot;${workspaceFolder}/src/index.js\u0026quot;,\n            \u0026quot;env\u0026quot;: {\n                \u0026quot;NODE_CONFIG_ENV\u0026quot;: \u0026quot;dev\u0026quot;\n            },\n            \u0026quot;outFiles\u0026quot;: [\u0026quot;${cwd}/dist/**/*.js\u0026quot;],\n            \u0026quot;sourceMaps\u0026quot;: true,\n            \u0026quot;smartStep\u0026quot;: true  \n        }\n    ]\n}\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id=\"args\"\u003eargs\u003c/h3\u003e\n\u003cp\u003eWe can specify array of CLI arguments as an array of string. The arguments can include command flags as well.\u003c/p\u003e\n\u003ch2 id=\"different-debugging-scenarios\"\u003eDifferent debugging scenarios\u003c/h2\u003e\n\u003ch3 id=\"setting-environment-variables\"\u003eSetting Environment variables\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-json\"\u003e{\n    \u0026quot;type\u0026quot;: \u0026quot;node\u0026quot;,\n    \u0026quot;request\u0026quot;: \u0026quot;launch\u0026quot;,\n    \u0026quot;name\u0026quot;: \u0026quot;module1\u0026quot;,\n    \u0026quot;restart\u0026quot;: true,\n    \u0026quot;console\u0026quot;: \u0026quot;integratedTerminal\u0026quot;,\n    \u0026quot;cwd\u0026quot;: \u0026quot;${workspaceRoot}/src\u0026quot;,\n    \u0026quot;program\u0026quot;: \u0026quot;${workspaceFolder}/src/index.js\u0026quot;,\n    \u0026quot;env\u0026quot;: {\n        \u0026quot;NODE_CONFIG_ENV\u0026quot;: \u0026quot;dev\u0026quot;\n    }\n}\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eHere, we are using npm package called \u003ccode\u003econfig\u003c/code\u003e, which expect the environment variable \u003ccode\u003eNODE_CONFIG_ENV\u003c/code\u003e to be set in order to load, say \u003ccode\u003edev.json\u003c/code\u003e, in this example\u003c/p\u003e\n\u003ch3 id=\"executing-process-monitoring-tools-like-pm2--nodemon\"\u003eExecuting process monitoring tools like pm2 / nodemon\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-json\"\u003e{\n    \u0026quot;type\u0026quot;: \u0026quot;node\u0026quot;,\n    \u0026quot;request\u0026quot;: \u0026quot;launch\u0026quot;,\n    \u0026quot;name\u0026quot;: \u0026quot;module1\u0026quot;,\n    \u0026quot;runtimeExecutable\u0026quot;: \u0026quot;nodemon\u0026quot;,\n    \u0026quot;restart\u0026quot;: true,\n    \u0026quot;console\u0026quot;: \u0026quot;integratedTerminal\u0026quot;,\n    \u0026quot;cwd\u0026quot;: \u0026quot;${workspaceRoot}/src\u0026quot;,\n    \u0026quot;program\u0026quot;: \u0026quot;${workspaceFolder}/src/index.js\u0026quot;,\n}\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eHere, the \u003ccode\u003eruntimeExecutable\u003c/code\u003e is used to launch the instance of the node script. Similarly other executables can be used for the same.\u003c/p\u003e\n\u003ch3 id=\"multi-module-debugging\"\u003eMulti-module debugging\u003c/h3\u003e\n\u003cp\u003eWhen we have setup like client-server or multi-repo managed by lerna, we can set the debug configurations for node apps as given below:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-json\"\u003e    \u0026quot;configurations\u0026quot;: [\n        {\n            \u0026quot;type\u0026quot;: \u0026quot;node\u0026quot;,\n            \u0026quot;request\u0026quot;: \u0026quot;launch\u0026quot;,\n            \u0026quot;name\u0026quot;: \u0026quot;module1\u0026quot;,\n            \u0026quot;restart\u0026quot;: true,\n            \u0026quot;console\u0026quot;: \u0026quot;integratedTerminal\u0026quot;,\n            \u0026quot;cwd\u0026quot;: \u0026quot;${workspaceRoot}/packages/abc\u0026quot;,\n            \u0026quot;program\u0026quot;: \u0026quot;${workspaceFolder}/packages/abc/src/index.js\u0026quot;,\n            \u0026quot;sourceMaps\u0026quot;: true\n        }, \n        {\n            \u0026quot;type\u0026quot;: \u0026quot;node\u0026quot;,\n            \u0026quot;request\u0026quot;: \u0026quot;launch\u0026quot;,\n            \u0026quot;name\u0026quot;: \u0026quot;module2\u0026quot;,\n            \u0026quot;cwd\u0026quot;: \u0026quot;${workspaceRoot}/packages/def\u0026quot;,\n            \u0026quot;program\u0026quot;: \u0026quot;${workspaceFolder}/packages/def/src/index.js\u0026quot;,\n            \u0026quot;args\u0026quot;: [\u0026quot;arg1\u0026quot;],\n            \u0026quot;sourceMaps\u0026quot;: true\n        }\n    ]\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eHere, we are mentioning the \u003ccode\u003ecwd\u003c/code\u003e (current working directory) of each of the repo in the workspace.\u003c/p\u003e\n\u003cp\u003eIn the scenario where we want to launch more than one module\u0026#39;s debugging session, the \u003ccode\u003elaunch.json\u003c/code\u003e can be configured as follows:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-json\"\u003e\u0026quot;compounds\u0026quot;: [\n        {\n            \u0026quot;name\u0026quot;: \u0026quot;abc/def\u0026quot;,\n            \u0026quot;configurations\u0026quot;: [\n                \u0026quot;module1\u0026quot;,\n                \u0026quot;module2\u0026quot;\n            ]\n        }\n    ]\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eBut in the above scenario, where one module depends on the launch of the next, it is desirable to have some delay which will give sufficient time to launch the former. This can be done by using \u003ccode\u003esleep\u003c/code\u003e command while defining \u003ccode\u003etasks\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eBoth the \u003ccode\u003etasks.json\u003c/code\u003e and \u003ccode\u003elaunch.json\u003c/code\u003e is attached below for reference:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-json\"\u003e{\n    \u0026quot;version\u0026quot;: \u0026quot;2.0.0\u0026quot;,\n    \u0026quot;tasks\u0026quot;: [\n        {\n            \u0026quot;label\u0026quot;: \u0026quot;Sleep\u0026quot;,\n            \u0026quot;type\u0026quot;: \u0026quot;shell\u0026quot;,\n            \u0026quot;command\u0026quot;: \u0026quot;sleep 3\u0026quot;,\n            \u0026quot;windows\u0026quot;: {\n                \u0026quot;command\u0026quot;: \u0026quot;ping 127.0.0.1 -n 6 \u0026gt; nul\u0026quot;\n            },\n            \u0026quot;group\u0026quot;: \u0026quot;none\u0026quot;,\n            \u0026quot;presentation\u0026quot;: {\n                \u0026quot;reveal\u0026quot;: \u0026quot;silent\u0026quot;,\n                \u0026quot;panel\u0026quot;: \u0026quot;new\u0026quot;\n            }\n        }\n    ]\n}\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"language-json\"\u003e{\n    \u0026quot;version\u0026quot;: \u0026quot;0.2.0\u0026quot;,\n    \u0026quot;configurations\u0026quot;: [\n        {\n            \u0026quot;type\u0026quot;: \u0026quot;node\u0026quot;,\n            \u0026quot;request\u0026quot;: \u0026quot;launch\u0026quot;,\n            \u0026quot;name\u0026quot;: \u0026quot;module3\u0026quot;,\n            \u0026quot;cwd\u0026quot;: \u0026quot;${workspaceRoot}/packages/module3\u0026quot;,\n            \u0026quot;program\u0026quot;: \u0026quot;${workspaceFolder}/packages/module3/src/index.js\u0026quot;,\n            \u0026quot;env\u0026quot;: {\n                \u0026quot;NODE_CONFIG_ENV\u0026quot;: \u0026quot;dev\u0026quot;\n            },\n            \u0026quot;sourceMaps\u0026quot;: true\n        },\n        {\n            \u0026quot;type\u0026quot;: \u0026quot;node\u0026quot;,\n            \u0026quot;request\u0026quot;: \u0026quot;launch\u0026quot;,\n            \u0026quot;name\u0026quot;: \u0026quot;module1\u0026quot;,\n            \u0026quot;runtimeExecutable\u0026quot;: \u0026quot;nodemon\u0026quot;,\n            \u0026quot;restart\u0026quot;: true,\n            \u0026quot;console\u0026quot;: \u0026quot;integratedTerminal\u0026quot;,\n            \u0026quot;cwd\u0026quot;: \u0026quot;${workspaceRoot}/packages/module1\u0026quot;,\n            \u0026quot;program\u0026quot;: \u0026quot;${workspaceFolder}/packages/module1/src/index.js\u0026quot;,\n            \u0026quot;env\u0026quot;: {\n                \u0026quot;NODE_CONFIG_ENV\u0026quot;: \u0026quot;dev\u0026quot;\n            },\n            \u0026quot;sourceMaps\u0026quot;: true\n        }, \n        {\n            \u0026quot;type\u0026quot;: \u0026quot;node\u0026quot;,\n            \u0026quot;request\u0026quot;: \u0026quot;launch\u0026quot;,\n            \u0026quot;name\u0026quot;: \u0026quot;module2\u0026quot;,\n            \u0026quot;cwd\u0026quot;: \u0026quot;${workspaceRoot}/packages/module2\u0026quot;,\n            \u0026quot;program\u0026quot;: \u0026quot;${workspaceFolder}/packages/module2/src/index.js\u0026quot;,\n            \u0026quot;env\u0026quot;: {\n                \u0026quot;NODE_CONFIG_ENV\u0026quot;: \u0026quot;dev\u0026quot;\n            },\n            \u0026quot;preLaunchTask\u0026quot;: \u0026quot;Sleep\u0026quot;,\n            \u0026quot;sourceMaps\u0026quot;: true\n        }\n    ],\n    \u0026quot;compounds\u0026quot;: [\n        {\n            \u0026quot;name\u0026quot;: \u0026quot;module1/module2\u0026quot;,\n            \u0026quot;configurations\u0026quot;: [\n                \u0026quot;module1\u0026quot;,\n                \u0026quot;module2\u0026quot;\n            ]\n        }\n    ]\n}\u003c/code\u003e\u003c/pre\u003e\n","frontmatter":"title: VSCode Debugging"}},{"location":"/Crypto/","markdown":{"attributes":{"title":"Cryptography"},"body":"","frontmatter":"title: Cryptography"}},{"location":"/Crypto/public-private-keys/","markdown":{"attributes":{"title":"Public Private keys - Cryptography / Security"},"body":"\u003ch1 id=\"public-private-keys\"\u003ePublic Private keys\u003c/h1\u003e\n\u003cp\u003eWe need to generate public and private key to ssh into remote machines and for authentication/authorization\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003essh-keygen\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eWhen automating servers, we need to add IP address of remote servers in known hosts\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003essh-keyscan github.com \u0026gt;\u0026gt; ~/.ssh/known_hosts\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eWhen we have got multiple github accounts, we can use one pub in for one account only. We need to generate another pair of pub-private key pair to add to another github account. We need to add the newly generated file name/location\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003essh-add /path/to/new/rsa/file\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eWhen we want to test from CLI that which github username is active:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003essh -T git@github.com\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eWhen we want to specifically muse a particular RSA key,\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003essh -i /file/to/private_key\u003c/code\u003e\u003c/pre\u003e","frontmatter":"title: Public Private keys - Cryptography / Security"}}]}},"page":"/articleHomepage","query":[{"location":"/","markdown":{"attributes":{"title":"Blog articles - Protonoid","keywords":"AWS,CPP,cryptography,database,docker,elasticsearch,git,GraphQL,Javascript,SEO,Python,Kubernetes,OpenCV"},"body":"\u003ch1 id=\"blog-articles\"\u003eBlog Articles\u003c/h1\u003e\n","frontmatter":"title: Blog articles - Protonoid\nkeywords: AWS,CPP,cryptography,database,docker,elasticsearch,git,GraphQL,Javascript,SEO,Python,Kubernetes,OpenCV"}},{"location":"/shell-script/","markdown":{"attributes":{"title":"Linux Shell Scripting - sh, bash, zsh, tcsh, csh"},"body":"","frontmatter":"title: Linux Shell Scripting - sh, bash, zsh, tcsh, csh"}},{"location":"/shell-script/simple-use-cases/","markdown":{"attributes":{"title":"Simple Use Cases - Shell Script","description":"Some simple use cases to have an exposure on its applications"},"body":"\u003ch1 id=\"shell-script-simple-use-cases\"\u003eShell Script Simple Use Cases\u003c/h1\u003e\n\u003ch2 id=\"to-convert-nunjuck-template-without-space\"\u003eTo convert nunjuck template without space\u003c/h2\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e#!/bin/bash\n\nfind . -name index.html | while read line; do\n    perl -pi -e \u0026#39;s/{(%|#)(?=[^-])/{\\1-/g\u0026#39; $line\n    perl -pi -e \u0026#39;s/(?\u0026lt;=[^-])(%|#)}/-\\1}/g\u0026#39; $line\ndone\u003c/code\u003e\u003c/pre\u003e\n","frontmatter":"title: Simple Use Cases - Shell Script\ndescription: Some simple use cases to have an exposure on its applications"}},{"location":"/shell-script/one-liner/","markdown":{"attributes":{"title":"Shell script one liners"},"body":"\u003ch1 id=\"one-liners\"\u003eOne-liners\u003c/h1\u003e\n\u003ch2 id=\"perl\"\u003ePerl\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003e-e\u003c/code\u003e: allows you to specify the Perl code to be executed right on the command line\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e-p\u003c/code\u003e: code gets executed on every line, and that the line gets printed out after that\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e-i\u003c/code\u003e: opens the file, executes the substitution for each line, prints the output to a temporary file, and then replaces the original file\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"\"\u003e\u003c/h3\u003e\n\u003ch2 id=\"awk\"\u003eawk\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eCombine multiline text into single line\u003c/li\u003e\n\u003cli\u003esource: \u003ca href=\"https://www.rexegg.com/regex-perl-one-liners.html\"\u003ePerl Regex One-Liner Cookbook\u003c/a\u003e*\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e\u0026lt;multiline_output_command\u0026gt; | awk \u0026#39;{printf(\u0026quot;%s\u0026quot;, $0)}\u0026#39;\u003c/code\u003e\u003c/pre\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"references\"\u003eReferences\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"http://www.pement.org/sed/sed1line.txt\"\u003eSed One-liners\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://catonmat.net/introduction-to-perl-one-liners\"\u003eIntroduction to Perl one-liners\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n","frontmatter":"title: Shell script one liners"}},{"location":"/serverless/","markdown":{"attributes":{"title":"Serverless Architecture"},"body":"","frontmatter":"title: Serverless Architecture"}},{"location":"/serverless/serverless-framework/","markdown":{"attributes":{"title":"AWS Serverless Framework","description":"Using Serverless Framework for creating a Serverless microservices architecture using Lambda, DynamoDB, S3 Buckets, API Gateways and IAM Access."},"body":"\u003ch1 id=\"serverless-framework\"\u003eServerless Framework\u003c/h1\u003e\n\u003cp\u003e\u003cimg src=\"https://theburningmonk.com/wp-content/uploads/2019/05/img_5cddfd8fe678a.png\" alt=\"Serverless comparisons\"\u003e\u003c/p\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eServerless framework brings in multi cloud serverless capability in the form of automated descriptive programming. Here, in AWS, it will be leveraging the CloudFormation to build on top of it. It has got many built in templates and plugins ecosystem to choose from.\u003c/p\u003e\n\u003ch2 id=\"access-required\"\u003eAccess required\u003c/h2\u003e\n\u003cpre\u003e\u003ccode\u003e{\n    \u0026quot;Version\u0026quot;: \u0026quot;2012-10-17\u0026quot;,\n    \u0026quot;Statement\u0026quot;: [\n        {\n            \u0026quot;Sid\u0026quot;: \u0026quot;VisualEditor0\u0026quot;,\n            \u0026quot;Effect\u0026quot;: \u0026quot;Allow\u0026quot;,\n            \u0026quot;Action\u0026quot;: [\n                \u0026quot;iam:PassRole\u0026quot;,\n                \u0026quot;iam:ListAttachedRolePolicies\u0026quot;,\n                \u0026quot;iam:CreateRole\u0026quot;,\n                \u0026quot;iam:PutRolePolicy\u0026quot;,\n                \u0026quot;iam:AttachRolePolicy\u0026quot;,\n                \u0026quot;iam:GetRole\u0026quot;,\n                \u0026quot;s3:*\u0026quot;,\n                \u0026quot;apigateway:*\u0026quot;,\n                \u0026quot;logs:*\u0026quot;,\n                \u0026quot;lambda:*\u0026quot;,\n                \u0026quot;cloudformation:*\u0026quot;\n            ],\n            \u0026quot;Resource\u0026quot;: \u0026quot;*\u0026quot;\n        }\n    ]\n}\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"troubleshooting\"\u003eTroubleshooting\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eCustomDashresourceDashapigwDashcwDashroleLambdaFunction - The role defined for the function cannot be assumed by Lambda\u003cpre\u003e\u003ccode\u003eAn error occurred: CustomDashresourceDashapigwDashcwDashroleLambdaFunction - The role defined for the function cannot be assumed by Lambda. (Service: AWSLambdaInternal; Status Code: 400; Error Code: InvalidParameterValueException; Request ID: XXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXX).\u003c/code\u003e\u003c/pre\u003eNeed to add \u003ccode\u003elambda.amazonaws.com\u003c/code\u003e to the \u003ccode\u003ecfnRole\u003c/code\u003e\nRef: \u003ca href=\"https://github.com/serverless/serverless/issues/6876\"\u003e\u0026quot;The role defined for the function cannot be assumed by Lambda\u0026quot; error after upgrading to 1.55.0 · Issue #6876 · serverless/serverless · GitHub\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"resources\"\u003eResources\u003c/h2\u003e\n\u003ch3 id=\"documentation\"\u003eDocumentation\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://serverless.com/framework/docs/providers/aws/guide/serverless.yml/\"\u003eServerless Framework - AWS Lambda Guide - Serverless.yml Reference\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n","frontmatter":"title: AWS Serverless Framework\ndescription: Using Serverless Framework for creating a Serverless microservices architecture using Lambda, DynamoDB, S3 Buckets, API Gateways and IAM Access."}},{"location":"/python/","markdown":{"attributes":{"title":"Python"},"body":"","frontmatter":"title: Python"}},{"location":"/python/troubleshoot/","markdown":{"attributes":{"title":"Troubleshooting - Python"},"body":"\u003ch1 id=\"python-troubleshoot\"\u003ePython troubleshoot\u003c/h1\u003e\n\u003ch2 id=\"importerror-bad-magic-number-in-xml-bx03xf3rn\"\u003eImportError: bad magic number in \u0026#39;xml\u0026#39;: b\u0026#39;\\x03\\xf3\\r\\n\u0026#39;\u003c/h2\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003efind . -name \u0026quot;*.pyc\u0026quot; -exec rm -f {} \\;\u003c/code\u003e\u003c/pre\u003e\n","frontmatter":"title: Troubleshooting - Python"}},{"location":"/opencv/","markdown":{"attributes":{"title":"OpenCV Introduction"},"body":"\u003ch2 id=\"with-c\"\u003eWith C++\u003c/h2\u003e\n\u003cp\u003eWhen compiling \u003ccode\u003ecpp\u003c/code\u003e files with \u003ccode\u003eOpenCV\u003c/code\u003e, it looks for \u003ccode\u003eopencv4.pc\u003c/code\u003e to locate the installed libraries. We can use this file with \u003ccode\u003epkg-config\u003c/code\u003e to get a list of \u003ccode\u003ecflags\u003c/code\u003e and \u003ccode\u003elibs\u003c/code\u003e to be specified while compiling the program.\u003c/p\u003e\n\u003cp\u003eSo, we can build it using following command:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003eopencv_lib=`pkg-config --cflags --libs /usr/local/Cellar/opencv/4.1.0_1/lib/pkgconfig/opencv4.pc`\ng++ $opencv_lib -std=c++11 file.cpp -o file.o\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id=\"opencv-410-library-location\"\u003eOpenCV-4.1.0 Library location\u003c/h3\u003e\n\u003cp\u003epkg-config --cflags --libs /usr/local/Cellar/opencv/4.1.0_1/lib/pkgconfig/opencv4.pc\u003c/p\u003e\n\u003ch3 id=\"important-locations\"\u003eImportant locations\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003e/usr/local/lib/pkgconfig/opencv4.pc\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e/usr/local/Cellar/opencv/4.0.0/lib/pkgconfig/opencv4.pc\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e/usr/local/Cellar/opencv/4.1.0_1/lib/pkgconfig/opencv4.pc\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e/anaconda3/pkgs/libopencv-3.4.1-h0f2e407_1/lib/pkgconfig/opencv.pc\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e/anaconda3/pkgs/libopencv-3.4.2-h7c891bd_1/lib/pkgconfig/opencv.pc\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e/anaconda3/lib/pkgconfig/opencv.pc\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n","frontmatter":"title: OpenCV Introduction"}},{"location":"/open-specifications/","markdown":{"attributes":{"title":"Open Specifications"},"body":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n","frontmatter":"title: Open Specifications"}},{"location":"/open-specifications/swagger/","markdown":{"attributes":{"title":"Swagger 2.0 Specification"},"body":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n","frontmatter":"title: Swagger 2.0 Specification"}},{"location":"/kubernetes/","markdown":{"attributes":{"title":"Kubernetes Introduction"},"body":"\u003ch1 id=\"kubernetes\"\u003eKubernetes\u003c/h1\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eRoot level YAML keys:\u003c/li\u003e\n\u003c/ul\u003e\n","frontmatter":"title: Kubernetes Introduction"}},{"location":"/kubernetes/minikube/","markdown":{"attributes":{"title":"Minikube"},"body":"\u003ch2 id=\"references\"\u003eReferences:\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://blog.hasura.io/sharing-a-local-registry-for-minikube-37c7240d0615/\"\u003eSharing a local registry with minikube\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n","frontmatter":"title: Minikube"}},{"location":"/kubernetes/minikube/access-mongodb-in-host-from-kubernetes-container/","markdown":{"attributes":{"title":"Access services like mongodb on host inside kubernetes pods"},"body":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003essh -i $(minikube ssh-key) docker@$(minikube ip) -R 27000:localhost:27017\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow if we want to access port \u003ccode\u003e27000\u003c/code\u003e inside a pod, we can do it by getting IP address of minikube and connecting to that port from inside the pod.\u003c/p\u003e\n\u003cp\u003e```bash\nmongo 172.12.0.1:27000\n``\u003c/p\u003e\n\u003ch2 id=\"references\"\u003eReferences\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://medium.com/tarkalabs/proxying-services-into-minikube-8355db0065fd\"\u003eProxying services into minikube - Tarka Labs Blog - Medium\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n","frontmatter":"title: Access services like mongodb on host inside kubernetes pods"}},{"location":"/javascript/","markdown":{"attributes":{"title":"Javascript"},"body":"","frontmatter":"title: Javascript"}},{"location":"/javascript/performance/","markdown":{"attributes":{"title":"Javascript Performance"},"body":"","frontmatter":"title: Javascript Performance"}},{"location":"/javascript/performance/benchmark/","markdown":{"attributes":{"title":"Performance Benchmark - Javascript"},"body":"\u003ch1 id=\"javascript-performance-benchmarks\"\u003eJavascript performance benchmarks\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003eSuperior performance of \u003ccode\u003efor\u003c/code\u003e loop over \u003ccode\u003ewhile\u003c/code\u003e and prefix increment over postfix increment.\nRef: \u003ca href=\"https://jsperf.com/for-loop-research\"\u003ehttps://jsperf.com/for-loop-research\u003c/a\u003e\nNote: Benchmark not \nThe following syntax performance seems to be consistent in modern v8 (chrome/nodejs), (excluding ES6 syntax):\u003cpre\u003e\u003ccode\u003efor (var i=0; i \u0026lt; arr.length; ++i) {\nworker();\n}\u003c/code\u003e\u003c/pre\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cp\u003eString, Number === is generally performant\n\u003ca href=\"https://jsperf.com/string-compare-vs-number-compare/2\"\u003eString compare VS number compare · jsPerf\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003estring vs buffer comparison\n\u003ca href=\"https://jsperf.com/compare-string-vs-buffer\"\u003ecompare string vs buffer · jsPerf\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cp\u003e\u003ca href=\"https://jsperf.com/adding-to-a-set-vs-pushing-to-an-array\"\u003eAdding to a Set vs Pushing to an Array · jsPerf\u003c/a\u003e\u003c/p\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch5 id=\"array-category-finding-if-exists\"\u003earray category finding if exists\u003c/h5\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://jsperf.com/array-time-space-complexity-comparison/1\"\u003earray-time-space-complexity-comparison · jsPerf\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://jsperf.com/find-if-array-element-exists-and-category-if-yes/1\"\u003efind-if-array-element-exists-and-category-if-yes · jsPerf\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch5 id=\"try-catch-vs-code-error-check-even-for-very-nested-js-object\"\u003etry-catch vs code error check (even for very nested js object)\u003c/h5\u003e\n","frontmatter":"title: Performance Benchmark - Javascript"}},{"location":"/javascript/packages/","markdown":{"attributes":{"title":"Javascript Packages"},"body":"","frontmatter":"title: Javascript Packages"}},{"location":"/javascript/packages/lerna/","markdown":{"attributes":{"title":"Lerna package - Introduction"},"body":"\u003ch1 id=\"lerna\"\u003eLerna\u003c/h1\u003e\n\u003ch2 id=\"commands\"\u003eCommands\u003c/h2\u003e\n\u003ch3 id=\"list\"\u003e\u003ca href=\"https://www.npmjs.com/package/@lerna/list\"\u003eList\u003c/a\u003e\u003c/h3\u003e\n\u003ch2 id=\"cookbooks\"\u003eCookbooks\u003c/h2\u003e\n\u003ch4 id=\"add-local-package-to-other-package\"\u003eAdd local package to other package\u003c/h4\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003enpm install ../package-name -S\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThis will add \u003ccode\u003e\u0026quot;package-name\u0026quot;: \u0026quot;file:../package-name\u0026quot;\u003c/code\u003e in \u003ccode\u003edependencies\u003c/code\u003e\u003c/p\u003e\n\u003ch4 id=\"trigger-npm-install-in-all-packages\"\u003eTrigger npm install in all packages\u003c/h4\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003enpx lerna bootstrap\u003c/code\u003e\u003c/pre\u003e\n","frontmatter":"title: Lerna package - Introduction"}},{"location":"/javascript/asynchronous-iterator-in-array/","markdown":{"attributes":{"title":"Asynchronous Iterator in Array"},"body":"\u003ch1 id=\"tldr\"\u003eTL:DR;\u003c/h1\u003e\n","frontmatter":"title: Asynchronous Iterator in Array"}},{"location":"/javascript/array-generator/","markdown":{"attributes":{"title":"Array Generator - Javascript"},"body":"\u003cp\u003eArray Generator\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-javascript\"\u003econst gen = N =\u0026gt; [...(function*(){let i=0;while(i\u0026lt;N)yield i++})()]\nperformance.mark(\u0026#39;test1\u0026#39;);\ngen(100000);\nperformance.measure(\u0026#39;test1\u0026#39;);\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe duration for above \u003ca href=\"https://stackoverflow.com/a/36828957/5305151\"\u003ecode\u003c/a\u003e is observed to be 3168.09.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-javascript\"\u003evar foo = [];\nperformance.mark(\u0026#39;test2\u0026#39;)\nfor (var i = 1; i \u0026lt;= 100000; i++) {\n   foo.push(i);\n}\nperformance.measure(\u0026#39;test2\u0026#39;);\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe duration for above \u003ca href=\"https://stackoverflow.com/q/3746725/5305151\"\u003ecode\u003c/a\u003e is observed to be 2420.01.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-javascript\"\u003eperformance.mark(\u0026#39;test3\u0026#39;);\nfor(foo=[x=100000]; x; foo[x-1]=x--);\nperformance.measure(\u0026#39;test3\u0026#39;);\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe duration for above \u003ca href=\"https://stackoverflow.com/a/36324319/5305151\"\u003ecode\u003c/a\u003e is observed to be 1888.52.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-javascript\"\u003eperformance.mark(\u0026#39;test4\u0026#39;);\nArray.from({length: 100000}, (v, k) =\u0026gt; k+1); \nperformance.measure(\u0026#39;test4\u0026#39;);\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe duration for above \u003ca href=\"https://stackoverflow.com/a/38213213/5305151\"\u003ecode\u003c/a\u003e is observed to be 2254.72.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-javascript\"\u003eperformance.mark(\u0026#39;test5\u0026#39;);\n[...Array(100000)].map((_, i) =\u0026gt; i + 1)\nperformance.measure(\u0026#39;test5\u0026#39;);\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe duration for above \u003ca href=\"https://stackoverflow.com/a/40772491/5305151\"\u003ecode\u003c/a\u003e is observed to be 4273.46.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-javascript\"\u003eperformance.mark(\u0026#39;test6\u0026#39;);\nfor(var i,a=[i=0];i\u0026lt;100000;a[i++]=i);\nperformance.measure(\u0026#39;test6\u0026#39;);\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe duration for above \u003ca href=\"https://stackoverflow.com/a/41293227/5305151\"\u003ecode\u003c/a\u003e is observed to be 17016.45.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-javascript\"\u003eperformance.mark(\u0026#39;test7\u0026#39;);\nvar arr = Array(100000).fill(0);\nperformance.measure(\u0026#39;test7\u0026#39;);\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe duration for above code is 3098.02\u003c/p\u003e\n","frontmatter":"title: Array Generator - Javascript"}},{"location":"/graphql/","markdown":{"attributes":{"title":"GraphQL"},"body":"\u003ch1 id=\"graphql\"\u003eGraphQL\u003c/h1\u003e\n","frontmatter":"title: GraphQL"}},{"location":"/git/","markdown":{"attributes":{"title":"Git Introduction"},"body":"\u003ch1 id=\"git\"\u003eGit\u003c/h1\u003e\n\u003ch2 id=\"import-commits-from-other-repo\"\u003eImport commits from other repo\u003c/h2\u003e\n\u003cp\u003eTo import commits, we can add the other repo as an origin in our current repo\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-sh\"\u003egit remote add \u0026lt;origin_name\u0026gt; git@github.com:username/other_reponame.git\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow, we can either create new branch from newly added origin\u0026#39;s any branch or rebase any of our existing branch\u003c/p\u003e\n\u003cp\u003eThen, we can even delete that origin\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-sh\"\u003egit remote rm \u0026lt;origin_name\u0026gt;\u003c/code\u003e\u003c/pre\u003e\n","frontmatter":"title: Git Introduction"}},{"location":"/git/replace-gui-with-cli/","markdown":{"attributes":{"title":"Replace Git GUI with CLI"},"body":"\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e\n# get all changes list\ngit fetch --all\n\n# get a branch to work on\ngit checkout -b \u0026lt;branch_name\u0026gt; origin/\u0026lt;remote_branch_name\u0026gt;\n\n# add files for staging\ngit add *\n\n# commit the files\ngit commit -m \u0026quot;message\u0026quot;\n\n# push to remote repo\ngit push origin \u0026lt;remote_branch_name\u0026gt;\n\n# set a local branch to track the remote one\ngit branch -u origin/\u0026lt;remote_branch_name\u0026gt;\n# --set-upstream-to\n# --track\n\n# list only untracked files\ngit ls-files --exclude-standard --others\n\n# to see local branch tracks which remote branch\ngit branch -vv\n\n# rebase with a particular remote branch and force push to another\ngit rebase origin/remote_branch_1\ngit push -f origin remote_branch_2\n\n## Commit processing\n# to get last commit hash\ngit log -n 1 --format=\u0026quot;%H\u0026quot;\ngit log origin/master -n 1 --format=\u0026quot;%H\u0026quot;\n\n# Unstage all files\ngit reset HEAD -- .\n\n# Discard all changes\ngit checkout -- .\n\n# Delete untracked files\ngit clean -fd\u003c/code\u003e\u003c/pre\u003e\n","frontmatter":"title: Replace Git GUI with CLI"}},{"location":"/git/github/","markdown":{"attributes":{"title":"Github"},"body":"","frontmatter":"title: Github"}},{"location":"/git/github/packages/","markdown":{"attributes":{"title":"Github Packages"},"body":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003ch2 id=\"docker\"\u003eDocker\u003c/h2\u003e\n\u003cp\u003eThe Image Registry URL is \u003ccode\u003edocker.pkg.github.com\u003c/code\u003e.\u003c/p\u003e\n\u003ch4 id=\"download-image-from-private-repo\"\u003eDownload image from private repo\u003c/h4\u003e\n\u003ch5 id=\"related-issues\"\u003eRelated issues:\u003c/h5\u003e\n\u003cul\u003e\n\u003cli\u003e\u0026quot;Error response from daemon: unauthorized: Your request could not be authenticated by the GitHub Packages service. Please ensure your access token is valid and has the appropriate scopes configured.\u0026quot;\u003c/li\u003e\n\u003cli\u003e\u0026quot;Error response from daemon: unauthorized: Resource protected by organization SAML enforcement. You must grant your personal token access to this organization.\u0026quot;\u003c/li\u003e\n\u003cli\u003e\u0026quot;Failed to pull image: rpc error: code = Unknown desc = Error response from daemon: pull access denied for repository does not exist or may require \u0026#39;docker login\u0026#39;\u0026quot;\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eWe need to have a \u0026quot;Personal Access Token\u0026quot; generated for our account from \u003ccode\u003ehttps://github.com/settings/tokens\u003c/code\u003e. The will be our password while logging in CLI for Github Packages.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003edocker login -u \u0026lt;username\u0026gt; docker.pkg.github.com\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eOnce logged in, you can check \u003ccode\u003e~/.docker/config.json\u003c/code\u003e for confirmation. It will be like:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-json\"\u003e{\n    \u0026quot;auths\u0026quot;: {\n        \u0026quot;docker.pkg.github.com\u0026quot;: {\n            \u0026quot;auth\u0026quot;: \u0026quot;xxxxxxxxxxxxxxxxxxxxxx=\u0026quot;\n        }\n    },\n    \u0026quot;HttpHeaders\u0026quot;: {\n        \u0026quot;User-Agent\u0026quot;: \u0026quot;Docker-Client/18.09.9 (linux)\u0026quot;\n    }\n}\u003c/code\u003e\u003c/pre\u003e\n","frontmatter":"title: Github Packages"}},{"location":"/git/github/actions/","markdown":{"attributes":{"title":"Github Actions"},"body":"","frontmatter":"title: Github Actions"}},{"location":"/git/github/actions/introduction/","markdown":{"attributes":{"title":"Github actions introduction","description":"Conceptual introduction to CI/CD using Github Actions"},"body":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cp\u003eNewest and powerful entrant in the field of CI/CD. It is built natively as part of GitHub itself, so the CI/CD pipeline, test and build timing reduces drastically. Many features are introduced as part of Actions. Some of them are as follows:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003esecret \u0026quot;vault\u0026quot; for storing sensitive keys and passwords\u003c/li\u003e\n\u003cli\u003eworkflow trigger filter based on events, branch name, file path\u003c/li\u003e\n\u003cli\u003eprecise event hooks like push, pull_request, release, public etc\u003c/li\u003e\n\u003cli\u003emultiple OS like Ubuntu, Mac and Windows\u003c/li\u003e\n\u003cli\u003eparallel execution of jobs\u003c/li\u003e\n\u003cli\u003elive logs\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"global-variables\"\u003eGlobal variables\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003e$GITHUB_WORKSPACE\u003c/code\u003e - checkout happens to this variable\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eGITHUB_REPOSITORY\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eGITHUB_EVENT_NAME\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"theory\"\u003eTheory\u003c/h2\u003e\n\u003cp\u003eThe workflow can be triggered based on number of events. If \u003ccode\u003epush\u003c/code\u003e and \u003ccode\u003epull_request\u003c/code\u003e specifically, we can specify branch/tag name(s).\u003c/p\u003e\n","frontmatter":"title: Github actions introduction\ndescription: Conceptual introduction to CI/CD using Github Actions"}},{"location":"/elasticsearch/","markdown":{"attributes":{"title":"Elastic Search"},"body":"","frontmatter":"title: Elastic Search"}},{"location":"/elasticsearch/elk-stack/","markdown":{"attributes":{"title":"ELK Stack - Elasticsearch, Logstash, Kibana"},"body":"","frontmatter":"title: ELK Stack - Elasticsearch, Logstash, Kibana"}},{"location":"/elasticsearch/elk-stack/setup/","markdown":{"attributes":{"title":"ELK with filebeats"},"body":"\u003ch1 id=\"elk-with-filebeats\"\u003eELK with filebeats\u003c/h1\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003ch2 id=\"need-for-beats\"\u003eNeed for beats\u003c/h2\u003e\n\u003ch2 id=\"installation\"\u003eInstallation\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003einstall filebeat as mentioned in procedure\u003c/li\u003e\n\u003cli\u003eto run:\n\u003ccode\u003efilebeat -e -c ./filebeat.yml -d \u0026quot;*\u0026quot;\u003c/code\u003e\n-d specifies debug level\n-e report error on \u003ccode\u003eSTDERR\u003c/code\u003e\n-c specify config file (default: filebeat.yml)\u003c/li\u003e\n\u003cli\u003eSet \u003ccode\u003eoutput.console\u003c/code\u003e configs to verify/debug\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"x-pack\"\u003eX-Pack\u003c/h3\u003e\n\u003ch2 id=\"logstash\"\u003eLogstash\u003c/h2\u003e\n\u003ch3 id=\"mac\"\u003eMac\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003einstall location: /usr/local/Cellar/logstash/7.3.0\u003c/li\u003e\n\u003cli\u003econfig: /usr/local/Cellar/logstash/7.3.0/libexec/config -\u0026gt; /usr/local/etc/logstash\nwithin the config, we can edit \u003ccode\u003elogstash.yml\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"elasticsearch\"\u003eElasticsearch\u003c/h2\u003e\n\u003ch3 id=\"theory\"\u003eTheory\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eIndex -\u0026gt; Database\u003c/li\u003e\n\u003cli\u003eType -\u0026gt; TableName\u003c/li\u003e\n\u003cli\u003eDocument -\u0026gt; Rows/Records\u003c/li\u003e\n\u003cli\u003eFields  -\u0026gt; columns\u003ch3 id=\"api\"\u003eAPI\u003c/h3\u003e\n\u003c/li\u003e\n\u003cli\u003eDocument\u003cul\u003e\n\u003cli\u003eSingle\u003cul\u003e\n\u003cli\u003eIndex: Adds or updates typed JSON doc in specific index, making it searchable\u003cpre\u003e\u003ccode\u003ePOST \u0026lt;index-name\u0026gt;/\u0026lt;type-name\u0026gt;/\u0026lt;id\u0026gt;\n{\n\u0026quot;key1\u0026quot;: \u0026quot;value1\u0026quot;\n}\u003c/code\u003e\u003c/pre\u003e\u003c/li\u003e\n\u003cli\u003eGet\u003cpre\u003e\u003ccode\u003eGET /\u0026lt;index-name\u0026gt;/\u0026lt;type-name\u0026gt;/_search?size=20\u003c/code\u003e\u003c/pre\u003e\u003c/li\u003e\n\u003cli\u003eDelete\u003cpre\u003e\u003ccode\u003eDELETE /\u0026lt;index-name\u0026gt;/\u0026lt;type-name\u0026gt;/\u0026lt;id\u0026gt;\u003c/code\u003e\u003c/pre\u003e\u003c/li\u003e\n\u003cli\u003eUpdate\u003cpre\u003e\u003ccode\u003ePOST \u0026lt;index-name\u0026gt;/\u0026lt;type-name\u0026gt;/\u0026lt;id\u0026gt;/update\n{\n\u0026quot;script\u0026quot;: {\n\u0026quot;source\u0026quot;: \u0026quot;ctx._source.Age=params.val\u0026quot;,\n\u0026quot;lang\u0026quot;: \u0026quot;painless\u0026quot;,\n\u0026quot;params\u0026quot;: {\n\u0026quot;val\u0026quot;: {\n  \u0026quot;Age\u0026quot;: 32,\n  \u0026quot;Gender\u0026quot;: \u0026quot;Female\u0026quot;\n}\n}\n}\n}\u003c/code\u003e\u003c/pre\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eMulti\u003cul\u003e\n\u003cli\u003eGet\u003cpre\u003e\u003ccode\u003eGET /_mget\n{\n\u0026quot;abc\u0026quot;: [\n{\n\u0026quot;_index\u0026quot;: \u0026quot;index-name\u0026quot;,\n\u0026quot;_type\u0026quot;: \u0026quot;type-name\u0026quot;\n},\n{\n\u0026quot;_index\u0026quot;: \u0026quot;\u0026quot;,\n\u0026quot;_type\u0026quot;: \u0026quot;\u0026quot;\n}\n]\n}\u003c/code\u003e\u003c/pre\u003e\u003c/li\u003e\n\u003cli\u003eBulk\u003c/li\u003e\n\u003cli\u003eDelete by query\u003cpre\u003e\u003ccode\u003ePOST /\u0026lt;index-name\u0026gt;/_delete_by_query\n{\n\u0026quot;query\u0026quot;: {\n\u0026quot;match\u0026quot;: {\n\u0026quot;name\u0026quot;: \u0026quot;xyz\u0026quot;\n}\n}\n}\u003c/code\u003e\u003c/pre\u003e\u003c/li\u003e\n\u003cli\u003eUpdate by query\u003c/li\u003e\n\u003cli\u003eReindex\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eSearch\u003c/li\u003e\n\u003cli\u003eIndices\u003c/li\u003e\n\u003cli\u003eCat\u003c/li\u003e\n\u003cli\u003eCluster\u003ch3 id=\"mac-1\"\u003eMac\u003c/h3\u003e\n\u003c/li\u003e\n\u003cli\u003eData storage location: \u003ccode\u003e~/logs/logstash/elasticsearch-7.3.1/data/nodes/0\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eGo to \u003ccode\u003ehttp://localhost:9200/_cat/indices\u003c/code\u003e to see the list of indexes created.\u003c/li\u003e\n\u003cli\u003ewhen indices status is \u003ccode\u003eyellow\u003c/code\u003e in development machine, setting \u003ccode\u003eindex.number_of_replicas\u003c/code\u003e to \u003ccode\u003e0\u003c/code\u003e will resolve the issue. It will be available in kibana UI -\u0026gt; management menu -\u0026gt; elasticsearch -\u0026gt; index management -\u0026gt; edit settings\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"filebeat\"\u003eFilebeat\u003c/h2\u003e\n\u003ch3 id=\"mac-2\"\u003eMac\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003ewhile using filebeat with any module, we need to enable it. for that, the following config setting needs to be done:\u003cpre\u003e\u003ccode\u003efilebeat.config.modules:\nenabled: true\npath: ${path.config}/modules.d/*.yml\u003c/code\u003e\u003c/pre\u003efollowed by\u003cpre\u003e\u003ccode\u003e./filebeat modules enable logstash\u003c/code\u003e\u003c/pre\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"analysis\"\u003eAnalysis\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eQuery\u003c/li\u003e\n\u003cli\u003eMapping parameter\u003c/li\u003e\n\u003cli\u003eIndex setting\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"analyzer\"\u003eAnalyzer\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eIt tokenises the text i.e. it splits them into tokens using tokeniser\u003c/li\u003e\n\u003cli\u003eThen we have n number of token filters to filter, say, \u003cul\u003e\n\u003cli\u003estop words like ‘a’, ‘the’ etc\u003c/li\u003e\n\u003cli\u003euppercase to lowercase\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eapi\u003cpre\u003e\u003ccode\u003ePOST \u0026lt;index-name\u0026gt;/_analyze\u003c/code\u003e\u003c/pre\u003e\u003c/li\u003e\n\u003cli\u003etypes\u003cul\u003e\n\u003cli\u003estandard\u003c/li\u003e\n\u003cli\u003ewhitespace\u003c/li\u003e\n\u003cli\u003esimple\u003c/li\u003e\n\u003cli\u003ekeyword\u003c/li\u003e\n\u003cli\u003estop: stop word, stopword_path\u003c/li\u003e\n\u003cli\u003epattern: stopword, stopword_path, pattern, lowercase\u003c/li\u003e\n\u003cli\u003ecustom: tokeniser, char_filter, filter\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"tokeniser\"\u003eTokeniser\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eword\u003cul\u003e\n\u003cli\u003estandard\u003c/li\u003e\n\u003cli\u003elowercase\u003c/li\u003e\n\u003cli\u003ewhitespace\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003epartial\u003cul\u003e\n\u003cli\u003engram\u003c/li\u003e\n\u003cli\u003eedge_ngram\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003estructured\u003cul\u003e\n\u003cli\u003ekeyword\u003c/li\u003e\n\u003cli\u003epattern\u003c/li\u003e\n\u003cli\u003esimple_pattern\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n","frontmatter":"title: ELK with filebeats"}},{"location":"/effective-communication/","markdown":{"attributes":{"title":"Effective Communication"},"body":"","frontmatter":"title: Effective Communication"}},{"location":"/effective-communication/presentation/","markdown":{"attributes":{"title":"Effective Presentation"},"body":"\u003ch1 id=\"effective-presentation\"\u003eEffective Presentation\u003c/h1\u003e\n\u003ch2 id=\"intro--start\"\u003eIntro / Start\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eBegin with a question that is going to get answered in the presentation. E.g:- \u003ca href=\"https://www.youtube.com/watch?v=1WM-LsH6tKc\u0026amp;list=PLMPZQTftRCS8Pp4wiiUruly5ODScvAwcQ\u0026amp;index=20\"\u003ehttps://www.youtube.com/watch?v=1WM-LsH6tKc\u0026amp;list=PLMPZQTftRCS8Pp4wiiUruly5ODScvAwcQ\u0026amp;index=20\u003c/a\u003e\u003ch3 id=\"key-ideas\"\u003eKey Ideas\u003c/h3\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n","frontmatter":"title: Effective Presentation"}},{"location":"/docker/","markdown":{"attributes":{"title":"Docker Introduction"},"body":"\u003ch1 id=\"docker\"\u003eDocker\u003c/h1\u003e\n\u003ch3 id=\"network\"\u003eNetwork\u003c/h3\u003e\n\u003ch3 id=\"network-namespace\"\u003eNetwork namespace\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003emultiple instances can be run in a \u003ccode\u003enetwork namespace\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eThe containers in a namespace or in separate namespace can be attached to one or more network(s)\u003c/li\u003e\n\u003cli\u003eDifference between having two containers in same network and network namespace is that, in the former the containers can freely communicate over all ports in network whereas in latter, they communicate on all ports using localhost itself \u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"volumes\"\u003eVolumes\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003enamed declarations can be done like\n\u003ccode\u003e--volume \u0026lt;vol_name\u0026gt;:/path/to/mount\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003enamed volumes will be created when not exists, or else reused everytime\u003c/li\u003e\n\u003cli\u003eWhen being used in Mac/Windows, docker runs on VM. So, we cannot view the files directly. To view the filesystem, use:\u003cpre\u003e\u003ccode class=\"language-bash\"\u003edocker run --rm -it -v /:/vm-root alpine:edge ls -l /vm-root\u003c/code\u003e\u003c/pre\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003cem\u003eRef*\u003c/em\u003e: \u003ca href=\"https://forums.docker.com/t/host-path-of-volume/12277/2\"\u003ehttps://forums.docker.com/t/host-path-of-volume/12277/2\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"to-dos\"\u003eTo-Dos:\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eDistroless implementation \u003ca href=\"https://github.com/GoogleContainerTools/distroless/blob/master/examples/nodejs/Dockerfile\"\u003edistroless/Dockerfile at master · GoogleContainerTools/distroless · GitHub\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n","frontmatter":"title: Docker Introduction"}},{"location":"/docker/shell-vs-exec-form/","markdown":{"attributes":{"title":"Shell vs Exec Form"},"body":"\u003ch1 id=\"shell-vs-exec-form\"\u003eShell vs Exec Form\u003c/h1\u003e\n\u003cp\u003e\u003ccode\u003eSHELL\u003c/code\u003e form uses \u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e/bin/bash -c \u0026quot;command\u0026quot;\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eHere, the command will be child of \u003ccode\u003e/bin/bash\u003c/code\u003e. When we use \u003ccode\u003edocker exec\u003c/code\u003e, it will be hard to send signal to command because it will be sent to \u003ccode\u003e/bin/bash\u003c/code\u003e instead of getting sent to the command itself. \u003ccode\u003eExec\u003c/code\u003e form will be executed without a shell, directly it will be run.\nWhen both \u003ccode\u003eENTRYPOINT\u003c/code\u003e and \u003ccode\u003eCMD\u003c/code\u003e are used, \u003ccode\u003eCMD\u003c/code\u003e strings are appended to \u003ccode\u003eENTRYPOINT\u003c/code\u003e. So, the argument which we supposed to be easily overridden are specified in \u003ccode\u003eCMD\u003c/code\u003e, other parent or less frequently changing ones by \u003ccode\u003eENTRYPOINT\u003c/code\u003e. During this combination, always we use \u003ccode\u003eEXEC\u003c/code\u003e form.\u003c/p\u003e\n","frontmatter":"title: Shell vs Exec Form"}},{"location":"/docker/entrypoint-vs-cmd/","markdown":{"attributes":{"title":"Entrypoint vs CMD"},"body":"\u003ch1 id=\"entrypoint-vs-cmd\"\u003eEntrypoint vs CMD\u003c/h1\u003e\n\u003cp\u003eFor a image to be runnable, it should have \u003ccode\u003eENTRYPOINT\u003c/code\u003e or \u003ccode\u003eCMD\u003c/code\u003e. Without that, the image will result in an error. They are default executable which user can override. \u003ccode\u003eCMD\u003c/code\u003e can be overridden directly as below:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003edocker run --name ubuntu_bash -it ubuntu:latest bash\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWhereas, \u003ccode\u003eENTRYPOINT\u003c/code\u003e can be overridden as:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003edocker run --entrypoint \u0026lt;command\u0026gt;\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eDue to ease of override, \u003ccode\u003eCMD\u003c/code\u003e is preferred. In scenarios where we do not expect the user to override, we can opt for \u003ccode\u003eENTRYPOINT\u003c/code\u003e.\u003c/p\u003e\n","frontmatter":"title: Entrypoint vs CMD"}},{"location":"/docker/docker-machine/","markdown":{"attributes":{"title":"Docker Machine"},"body":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e$ docker-machine create --driver virtualbox default\n\n$ docker-machine ls\nNAME      ACTIVE   DRIVER       STATE     URL                         SWARM   DOCKER     ERRORS\ndefault   -        virtualbox   Running   tcp://192.168.99.106:2376           v19.03.5   \u003c/code\u003e\u003c/pre\u003e\n","frontmatter":"title: Docker Machine"}},{"location":"/docker/automations/","markdown":{"attributes":{"title":"Docker One-liner automations"},"body":"\u003cpre\u003e\u003ccode\u003edocker images | while read img; do\n    docker image rm $(grep -E \u0026#39;^\u0026lt;none\u0026gt;\u0026#39; | awk \u0026#39;{print $3}\u0026#39;);\ndone\u003c/code\u003e\u003c/pre\u003e","frontmatter":"title: Docker One-liner automations"}},{"location":"/db/","markdown":{"attributes":{"title":"Database Systems"},"body":"","frontmatter":"title: Database Systems"}},{"location":"/db/mongodb/","markdown":{"attributes":{"title":"Mongo DB"},"body":"","frontmatter":"title: Mongo DB"}},{"location":"/db/mongodb/client-cli/","markdown":{"attributes":{"title":"Tips working on Mongo Client CLI"},"body":"\u003ch2 id=\"prettify-cli-output\"\u003ePrettify CLI output\u003c/h2\u003e\n\u003ch3 id=\"temporary\"\u003eTemporary\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003edb.collection.find().pretty()\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"permananent\"\u003ePermananent\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003eDBQuery.prototype._prettyShell = true\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eRef: \u003ca href=\"https://stackoverflow.com/questions/9146123/pretty-print-in-mongodb-shell-as-default\"\u003ehttps://stackoverflow.com/questions/9146123/pretty-print-in-mongodb-shell-as-default\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"db-admin-commands\"\u003eDB Admin commands\u003c/h2\u003e\n\u003cpre\u003e\u003ccode\u003e# To restore from dump into different db and collection name\nmongorestore -v --host localhost:27017 -d \u0026quot;database_name\u0026quot; -c \u0026quot;collection_name\u0026quot; --dir /path/to/dump/data.bson  --objcheck\u003c/code\u003e\u003c/pre\u003e","frontmatter":"title: Tips working on Mongo Client CLI"}},{"location":"/dart/","markdown":{"attributes":{"title":"Dart - Introduction"},"body":"","frontmatter":"title: Dart - Introduction"}},{"location":"/dart/flutter/","markdown":{"attributes":{"title":"Flutter App - Introduction"},"body":"","frontmatter":"title: Flutter App - Introduction"}},{"location":"/dart/flutter/json_serializable/","markdown":{"attributes":{"title":"Dart Flutter json_serializable","description":"Utility to serialize and deserialize JSON objects in Dart / Flutter. This package depends on json_annotations and build_runner"},"body":"\u003ch1 id=\"json_serializable\"\u003ejson_serializable\u003c/h1\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eUnlike languages like NodeJs / Javascript or Python, which handles JSON values very easily, statically typed languages like Dart can be little challenging to implement the serialization and deserialization. For small projects, we can write serialization and deserialization by hand. For larger projects the boilerplate code itself will consume a lot of dev hours. So, we switch to \u003ca href=\"https://pub.dev/packages/json_serializable\"\u003ejson_serializable | Dart Package\u003c/a\u003e.\u003c/p\u003e\n\u003cp\u003eHere, we take an example of \u0026quot;Books - Authors - Publishers\u0026quot;.\u003c/p\u003e\n\u003ch2 id=\"installation\"\u003eInstallation\u003c/h2\u003e\n\u003cp\u003eIn \u003ccode\u003epubspec.yaml\u003c/code\u003e file, you can declare the dependencies it as follows:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-yaml\"\u003edependencies:\n  json_annotation: ^3.0.1\n\ndev_dependencies:\n  build_runner: ^1.7.2\n  json_serializable: ^3.2.5\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow you can \u003ccode\u003epub get\u003c/code\u003e to install all the dependencies.\u003c/p\u003e\n\u003ch2 id=\"usage\"\u003eUsage\u003c/h2\u003e\n\u003ch3 id=\"project-directory-structure\"\u003eProject directory structure\u003c/h3\u003e\n\u003cp\u003eGenerally, we have \u003ccode\u003edart\u003c/code\u003e file in a \u003ccode\u003emodels\u003c/code\u003e directory like below\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003elib\n├── layout\n│   ├── primary.dart\n│   └── campaign.dart\n├── main.dart\n├── models\n│   ├── book.dart\n│   ├── author.dart\n│   ├── publisher.dart\n├── screens\n│   ├── dashboard.dart\n│   ├── loading.dart\n│   ├── login.dart\n│   ├── root.dart\n└── widgets\n    ├── book_list.dart\n    ├── author_list.dart\n    ├── publisher_list.dart\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id=\"class-declaration\"\u003eClass declaration\u003c/h3\u003e\n\u003cp\u003eInside \u003ccode\u003ebook.dart\u003c/code\u003e, we would have defined the class \u003ccode\u003eBook\u003c/code\u003e.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-dart\"\u003eclass Book {\n  String name;\n  String ISBN;\n  List\u0026lt;Author\u0026gt; authors;\n  Publisher publisher;\n  double price;\n}\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eSimilarly for \u003ccode\u003eAuthor\u003c/code\u003e and \u003ccode\u003ePublisher\u003c/code\u003e, we have something like:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-dart\"\u003eclass Author {\n    String name;\n    int age;\n    int id;\n    List\u0026lt;Book\u0026gt; booksAuthored;\n}\n\nclass Publisher {\n    String name;\n    List\u0026lt;Book\u0026gt; booksPublished;\n}\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id=\"the-main-part\"\u003eThe main part\u003c/h3\u003e\n\u003cp\u003eSimply adding the annotation \u003ccode\u003e@JsonSerializable\u003c/code\u003e is enough to create the corresponding part files during build time.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-dart\"\u003eimport \u0026#39;package:json_annotation/json_annotation.dart\u0026#39;;\n\npart \u0026#39;book.g.dart\u0026#39;;\n\n@JsonSerializable\nclass Book {\n    // ...\n}\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003eLine 1: Since we are adding annotations to the file, we need to import \u003ccode\u003ejson_annotation\u003c/code\u003e package added in \u003ccode\u003edependencies\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003eLine 3: The build will generate a file with name \u003ccode\u003e\u0026lt;filename\u0026gt;.g.dart\u003c/code\u003e. So, the definitions for \u003ccode\u003efromJson\u003c/code\u003e and \u003ccode\u003etoJson\u003c/code\u003e will be available there. If the reference those functions from here, it will throw error. Since part of this file is separately available under another file named \u003ccode\u003ebook.g.dart\u003c/code\u003e, we need to add this line here.\u003c/li\u003e\n\u003cli\u003eLine 5: Annotation to generate the necessary functions like \u003ccode\u003e_$bookFromJson\u003c/code\u003e and \u003ccode\u003e_$bookToJson\u003c/code\u003e. These names are auto generated by the package.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"build\"\u003eBuild\u003c/h2\u003e\n\u003cp\u003eWe need to trigger the build to generate the corresponding \u003ccode\u003ebook.g.dart\u003c/code\u003e, \u003ccode\u003eauthor.g.dart\u003c/code\u003e and \u003ccode\u003epublishser.g.dart\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"references\"\u003eReferences\u003c/h2\u003e\n\u003cp\u003eTwo examples are give as part of main library itself:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/dart-lang/json_serializable/blob/master/example/lib/example.dart\"\u003ejson_serializable/example.dart at master · dart-lang/json_serializable · GitHub\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/dart-lang/json_serializable/blob/master/example/lib/json_converter_example.dart\"\u003ejson_serializable/json_converter_example.dart at master · dart-lang/json_serializable · GitHub\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n","frontmatter":"title: Dart Flutter json_serializable\ndescription: Utility to serialize and deserialize JSON objects in Dart / Flutter. This package depends on json_annotations and build_runner"}},{"location":"/cpp/","markdown":{"attributes":{"title":"CPP Introduction"},"body":"\u003ch1 id=\"c-basics\"\u003eC++ Basics\u003c/h1\u003e\n\u003col\u003e\n\u003cli\u003ePreprocessing\u003c/li\u003e\n\u003cli\u003eCompiling\u003c/li\u003e\n\u003cli\u003eAssembling compiled files\u003c/li\u003e\n\u003cli\u003eLinking object code file to create executable\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"preprocessing\"\u003ePreprocessing\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eheader files declarations are replace with the whole file, creating an expanded source code\u003c/li\u003e\n\u003cli\u003ethis is compiled to assembly lang code\u003c/li\u003e\n\u003cli\u003eassembler converts it into object code\u003c/li\u003e\n\u003cli\u003eobject code file is linked together with object coe files for any library functions to produce executables\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"include-guards\"\u003eInclude guards\u003c/h3\u003e\n\u003cp\u003eWhen we include a header file, which gets included as a part of some other header file, multiple definitions occur. This can be overcome by:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-cpp\"\u003e#ifndef \u0026lt;unique_name\u0026gt;\n  #define \u0026lt;unique_name\u0026gt;\n#endif\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003ee.g:- While including \u003ccode\u003elogger.hpp\u003c/code\u003e, we can define the \u003ccode\u003eunique_name\u003c/code\u003e as \u003ccode\u003eLOGGER_HPP\u003c/code\u003e.\u003c/p\u003e\n\u003ch2 id=\"compiling\"\u003eCompiling\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eSyntax check\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"compiler\"\u003eCompiler\u003c/h3\u003e\n\u003ch4 id=\"options\"\u003eOptions\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003e-c\u003c/code\u003e: compiles the source code into object code file instead of generating the executable.\u003cpre\u003e\u003ccode class=\"language-sh\"\u003eg++ -c -o myfile.obj myfile.cpp\u003c/code\u003e\u003c/pre\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e-I\u003c/code\u003e: when we include custom header files, we need to specify its \u003ccode\u003einclude\u003c/code\u003e directory\u003cpre\u003e\u003ccode class=\"language-sh\"\u003eg++ -c -I include/ -o myfile.obj myfile.cpp\u003c/code\u003e\u003c/pre\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"linking\"\u003eLinking\u003c/h2\u003e\n\u003cpre\u003e\u003ccode class=\"language-sh\"\u003eg++ main.obj mylib.obj -o main\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eTo compile source files without producing intermediate state:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-sh\"\u003eg++ -I include/ mylib.cpp main.cpp -o main\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"datatypes\"\u003eDatatypes\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eint (4 bytes)\u003c/li\u003e\n\u003cli\u003eshort int ()\u003c/li\u003e\n\u003cli\u003elong int ()\u003c/li\u003e\n\u003cli\u003elong long int ()\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"debugging\"\u003eDebugging\u003c/h2\u003e\n\u003ch3 id=\"lldb\"\u003elldb\u003c/h3\u003e\n\u003ch4 id=\"examples\"\u003eexamples\u003c/h4\u003e\n\u003ch5 id=\"console-debug\"\u003econsole debug\u003c/h5\u003e\n\u003cul\u003e\n\u003cli\u003eEvaluating variables and methods\u003cul\u003e\n\u003cli\u003ep (int)strlen(str)\n(int) $1 = 4\u003c/li\u003e\n\u003cli\u003ep (char*)str\n(char *) $2 = \u0026quot;abc\u0026quot;\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n","frontmatter":"title: CPP Introduction"}},{"location":"/cpp/debugging/","markdown":{"attributes":{"title":"CPP Debugging"},"body":"\u003ch1 id=\"c-debugger\"\u003eC++ debugger\u003c/h1\u003e\n\u003ch2 id=\"gdb\"\u003egdb\u003c/h2\u003e\n\u003cp\u003eIn \u003ccode\u003egdb\u003c/code\u003e we have got \u003ccode\u003enext\u003c/code\u003e and \u003ccode\u003estep\u003c/code\u003e which are equivalent of pressing \u003ccode\u003eF10\u003c/code\u003e and \u003ccode\u003eF11\u003c/code\u003e respectively i.e. \u003ccode\u003enext\u003c/code\u003e goes to the following line by executing the function, if any, in the current line. Whereas \u003ccode\u003estep\u003c/code\u003e steps into the code of the function in current line, if any.\u003c/p\u003e\n\u003ch2 id=\"lldb-macosx\"\u003elldb (macOSx)\u003c/h2\u003e\n","frontmatter":"title: CPP Debugging"}},{"location":"/computing-theory/","markdown":{"attributes":{"title":"Computing Theory"},"body":"","frontmatter":"title: Computing Theory"}},{"location":"/computing-theory/DNS/","markdown":{"attributes":{"title":"DNS Basics simplified","keywords":"DNS,records,zones"},"body":"\u003ch1 id=\"dns-basics\"\u003eDNS Basics\u003c/h1\u003e\n\u003ch2 id=\"tools\"\u003eTools\u003c/h2\u003e\n\u003ch3 id=\"dig\"\u003edig\u003c/h3\u003e\n\u003ch2 id=\"records\"\u003eRecords\u003c/h2\u003e\n\u003ch3 id=\"a-record\"\u003eA record\u003c/h3\u003e\n\u003ch3 id=\"soa-record\"\u003eSOA record\u003c/h3\u003e\n\u003ch3 id=\"ns-record\"\u003eNS record\u003c/h3\u003e\n\u003ch3 id=\"cname-record\"\u003eCNAME record\u003c/h3\u003e\n\u003ch3 id=\"alias-record\"\u003eALIAS record\u003c/h3\u003e\n\u003ch3 id=\"aaaa-record\"\u003eAAAA record\u003c/h3\u003e\n\u003ch3 id=\"txt-record\"\u003eTXT record\u003c/h3\u003e\n\u003ch3 id=\"srv-record\"\u003eSRV record\u003c/h3\u003e\n\u003ch3 id=\"cert-record\"\u003eCERT record\u003c/h3\u003e\n\u003ch3 id=\"ptr-record\"\u003ePTR record\u003c/h3\u003e\n\u003ch2 id=\"dns-zones\"\u003eDNS Zones\u003c/h2\u003e\n\u003ch3 id=\"zone-files\"\u003eZone files\u003c/h3\u003e\n\u003ch2 id=\"classifications\"\u003eClassifications\u003c/h2\u003e\n\u003ch3 id=\"dns-queries\"\u003eDNS Queries\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eRecursive\u003c/li\u003e\n\u003cli\u003eIterative\u003c/li\u003e\n\u003cli\u003eNon-Recursive\u003ch3 id=\"dns-server-types\"\u003eDNS Server types\u003c/h3\u003e\n\u003c/li\u003e\n\u003cli\u003eDNS Resolver\u003c/li\u003e\n\u003cli\u003eDNS Root Server\u003c/li\u003e\n\u003cli\u003eAuthoritative Name Server\u003c/li\u003e\n\u003c/ul\u003e\n","frontmatter":"title: DNS Basics simplified\nkeywords: DNS,records,zones"}},{"location":"/aws/","markdown":{"attributes":{"title":"AWS"},"body":"","frontmatter":"title: AWS"}},{"location":"/aws/xray/","markdown":{"attributes":{"title":"AWS X-Ray"},"body":"","frontmatter":"title: AWS X-Ray"}},{"location":"/aws/xray/basics/","markdown":{"attributes":{"title":"X-ray basics - AWS"},"body":"\u003ch1 id=\"aws-x-ray-basics\"\u003eAWS X-Ray basics\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/aws/aws-xray-sdk-node/issues/85#issuecomment-448821172\"\u003ehttps://github.com/aws/aws-xray-sdk-node/issues/85#issuecomment-448821172\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"references\"\u003eReferences\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/functionalone/aws-least-privilege\"\u003eGitHub - functionalone/aws-least-privilege: Use AWS X-Ray to reach Least Privilege\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://medium.com/@glicht/using-aws-x-ray-to-achieve-least-privilege-permissions-93dfd6701318\"\u003eUsing AWS X-Ray to achieve Least Privilege Permissions\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/glicht/serverless-stack-demo-api/tree/add-xray\"\u003eGitHub - glicht/serverless-stack-demo-api at add-xray\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n","frontmatter":"title: X-ray basics - AWS"}},{"location":"/aws/vpc/","markdown":{"attributes":{"title":"VPC - AWS"},"body":"","frontmatter":"title: VPC - AWS"}},{"location":"/aws/vpc/best-practices/","markdown":{"attributes":{"title":"VPC Best Practices - AWS"},"body":"","frontmatter":"title: VPC Best Practices - AWS"}},{"location":"/aws/vpc/best-practices/new-aws-account-configure/","markdown":{"attributes":{"title":"New account best practices"},"body":"\u003ch2 id=\"cloudformation\"\u003eCloudformation\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eAssign a service role to the stack for creating the resources rather than directly using the permissions of a console/CLI user.\u003c/li\u003e\n\u003cli\u003eSecurity posture of VPC can be improved by configuring CFN to use an interface VPC endpoint. \n  Ref:- \u003ca href=\"https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/cfn-vpce-bucketnames.html\"\u003eSetting Up VPC Endpoints for AWS CloudFormation - AWS CloudFormation\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eOn empty/new AWS account, we need to create the following before proceeding to launch a CFN stack:\u003cul\u003e\n\u003cli\u003eS3 bucket to store the CFN stack template\u003c/li\u003e\n\u003cli\u003eservice role for CFN\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"resouces-required\"\u003eResouces required\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eAWS::EC2::SecurityGroup\u003c/li\u003e\n\u003cli\u003eNACL\u003c/li\u003e\n\u003cli\u003eAWS::EC2::VPC\u003c/li\u003e\n\u003cli\u003eSubnets\u003c/li\u003e\n\u003cli\u003eInternet gateway\u003c/li\u003e\n\u003c/ul\u003e\n","frontmatter":"title: New account best practices"}},{"location":"/aws/serverless/","markdown":{"attributes":{"title":"AWS Serverless"},"body":"","frontmatter":"title: AWS Serverless"}},{"location":"/aws/serverless/sam/","markdown":{"attributes":{"title":"AWS SAM serverless"},"body":"\u003ch1 id=\"aws-sam-serverless\"\u003eAWS SAM serverless\u003c/h1\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003ch2 id=\"steps\"\u003eSteps\u003c/h2\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003esam init\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"troubleshoot\"\u003eTroubleshoot\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e403 - \u0026quot;message forbidden\u0026quot;\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre\u003e\u003ccode class=\"language-json\"\u003e{ \u0026quot;message\u0026quot;: \u0026quot;forbidden\u0026quot; }\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe is a good probability that when API Gateway Endpoints are created, the path we hit should have \u0026quot;stage\u0026quot; included.\u003c/p\u003e\n\u003ch2 id=\"extra-miles\"\u003eExtra miles\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eWhen \u003ccode\u003esam deploy\u003c/code\u003e fails, it is pushed to \u003ccode\u003eROLLBACK_COMPLETE\u003c/code\u003e state. We need to delete it and proceed with re-deployment.\u003c/li\u003e\n\u003cli\u003eWe need to package SAM template before we deploy, else it will not detect changes to create \u003ccode\u003echangeSets\u003c/code\u003e.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"references\"\u003eReferences\u003c/h2\u003e\n\u003ch3 id=\"examples\"\u003eExamples\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/awslabs/serverless-application-model/blob/master/examples/2016-10-31/api_swagger_cors/template.yaml\"\u003eserverless-application-model/template.yaml at master · awslabs/serverless-application-model · GitHub\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n","frontmatter":"title: AWS SAM serverless"}},{"location":"/aws/serverless/sam/troubleshoot/","markdown":{"attributes":{"title":"SAM Lambda troubleshoot - AWS"},"body":"\u003ch1 id=\"aws-sam-lambda-troubleshoot\"\u003eAWS SAM Lambda troubleshoot\u003c/h1\u003e\n\u003ch2 id=\"sam-unable-to-connect-endpoint-url\"\u003eSAM unable to connect endpoint URL\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/awslabs/aws-sam-cli/issues/102#issuecomment-326177151\"\u003ehttps://github.com/awslabs/aws-sam-cli/issues/102#issuecomment-326177151\u003c/a\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003esudo ifconfig lo0 alias 172.16.123.1\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"language-javascript\"\u003eAWS.config.update({\n    endpoint: \u0026quot;http://172.16.123.1:8000\u0026quot;\n});\u003c/code\u003e\u003c/pre\u003e\n","frontmatter":"title: SAM Lambda troubleshoot - AWS"}},{"location":"/aws/serverless/sam/debugging/","markdown":{"attributes":{"title":"Debugging SAM lambda - AWS"},"body":"\u003ch1 id=\"aws-sam-lambda-local-debugging\"\u003eAWS SAM Lambda local debugging\u003c/h1\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003e# General Syntax\n# sam local invoke \u0026lt;FunctionName\u0026gt; -e \u0026lt;eventFile.json\u0026gt; -d 5858\n# Example:\nsam local invoke HelloWorldFunction -e event.json -d 5858\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWe will get the URL to attach the debugger\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://pasteboard.co/IyQHOV3.png\"\u003eSAM local invoke debugging - Image on Pasteboard\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eOur function will be available in the docker container under \u003ccode\u003e/var/task/index.js\u003c/code\u003e. The SDK inbuilt function will be available in \u003ccode\u003e/var/runtime\u003c/code\u003e directory. \u003c/p\u003e\n\u003cp\u003eIn debugger, until we require/import the files, we will not able to see them listed. for that, we need to go to \u003ccode\u003e/var/runtime/UserFunction.js\u003c/code\u003e and place debugger in \u003ccode\u003e_tryRequire\u003c/code\u003e function. Once it resolves path and loads the file using \u003ccode\u003e_canLoadAsFile\u003c/code\u003e, we can view the files listed in the debugger to place the breakpoints.\u003c/p\u003e\n\u003cp\u003eHappy debugging..!\u003c/p\u003e\n","frontmatter":"title: Debugging SAM lambda - AWS"}},{"location":"/aws/opsworks/","markdown":{"attributes":{"title":"OpsWorks"},"body":"","frontmatter":"title: OpsWorks"}},{"location":"/aws/opsworks/detailed-introduction/","markdown":{"attributes":{"title":"Opsworks detailed introduction - AWS"},"body":"\u003ch1 id=\"aws-opsworks---detailed-introduction\"\u003eAWS Opsworks - Detailed Introduction\u003c/h1\u003e\n\u003ch2 id=\"opsworks-inner-workings\"\u003eOpsworks inner workings\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eRuby interpreter is located at \u003ccode\u003e/opt/aws/opsworks/local/bin/ruby\u003c/code\u003e\nOther executables are present at \u003ccode\u003e/opt/aws/opsworks/current\u003c/code\u003e like \u003ccode\u003eopsworks-agent\u003c/code\u003e, \u003ccode\u003eopsworks-agent-cli\u003c/code\u003e etc\u003c/li\u003e\n\u003cli\u003eWhen setup is run again \u003ccode\u003eaws_opsworks_users::default\u003c/code\u003e recipe is run, which includes the following actions:\u003cul\u003e\n\u003cli\u003ekill all processes of users\u003c/li\u003e\n\u003cli\u003eremove user (-r) options, which clears its home directory\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eWhen creating \u003ccode\u003euser\u003c/code\u003e using \u003ccode\u003echef\u003c/code\u003e, following things we need to be careful about\u003cul\u003e\n\u003cli\u003eThe application that we deploy as a user should be in directory other than its home directory because if some process executes \u003ccode\u003euserdel -r \u0026lt;username\u0026gt;\u003c/code\u003e all our files will be lost, especially persistent storage\u003c/li\u003e\n\u003cli\u003eWe need to be careful about \u003ccode\u003emanage_home\u003c/code\u003e being set to \u003ccode\u003etrue\u003c/code\u003e because of following line of command:\n\u003ccode\u003e/opt/aws/opsworks/current/vendor/bundle/ruby/\u0026lt;ruby_version\u0026gt;/gems/chef-\u0026lt;chef_version\u0026gt;/spec/support/shared/unit/provider/useradd_based_user_provider.rb:    it \u0026quot;should run userdel with the new resources user name and -r if manage_home is true\u0026quot; do\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eLogs for each run is stored in \u003ccode\u003e/var/chef/runs\u003c/code\u003e,\navailable at \u003ccode\u003ehttps://console.aws.amazon.com/opsworks/home?region=\u0026lt;region_name\u0026gt;#/stack/\u0026lt;stack_id\u0026gt;/instances/\u0026lt;instance_id\u0026gt;/log/\u0026lt;run_id\u0026gt;\u003c/code\u003e\n(Here, run id is obtained from \u003ccode\u003e/var/chef/runs\u003c/code\u003e)\u003c/li\u003e\n\u003c/ul\u003e\n","frontmatter":"title: Opsworks detailed introduction - AWS"}},{"location":"/aws/kms/","markdown":{"attributes":{"title":"KMS Encryption and Decryption","description":"Encrypt and decrypt secure text, passwords and keys using AWS KMS service using CLI"},"body":"\u003ch1 id=\"encrypt-and-decrypt-keys-using-aws-kms\"\u003eEncrypt and Decrypt Keys using AWS KMS\u003c/h1\u003e\n\u003ch2 id=\"encryption\"\u003eEncryption\u003c/h2\u003e\n\u003cp\u003eFor this we need to create a \u0026quot;Customer Managed Key\u0026quot; using either console or CLI, or any other programmatic way. Once we do that, we obtain a \u003ccode\u003ekey-id\u003c/code\u003e to use for encryption. We do not require \u003ccode\u003ekey-id\u003c/code\u003e for decryption. The reason is that, the encrypted hash will be self sufficiently having all the required data for decryption. We can set alias name and description for the keys along with tags for easy identification of the key\u0026#39;s purpose.\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003eaws kms encrypt \\\n--key-id XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX \\\n--plaintext \u0026quot;secret text for encryption\u0026quot; \\\n--output text \\\n--query CiphertextBlob\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eThe drawback with above method is, if someone or admin checks the history, it will be visible as clear text and in many organisation it will be a clear violation of security policies. For that, we can store the password in a text file and call that file here. Say,\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003eaws kms encrypt \\\n--key-id XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX \\\n--plaintext fileb://secretfile \\\n--output text \\\n--query CiphertextBlob\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eWhen we do this, the resulting hash will be \u003ccode\u003ebase64\u003c/code\u003e encoded. If we decode it, it will result in a binary value which we cannot store in yaml file. Or else, we can have the binary string written to a separate file and reference that file in our yaml files.\nFor decoding and storing in a file,\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003eaws kms encrypt \\\n--key-id XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX \\\n--plaintext fileb://secretfile \\\n--output text \\\n--query CiphertextBlob | base64 --decode \u0026gt; binaryFileName\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"decryption\"\u003eDecryption\u003c/h2\u003e\n\u003cp\u003eFor decryption,\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003eaws kms decrypt \\\n--ciphertext-blob fileb://binaryFileName\n--output text \\\n--query Plaintext\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e\u003cstrong\u003eNote:- Again, the resulting text will be base64 encoded\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eIf you have an encrypted base64 text string to obtain back the original secret key, you can do:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003eaws kms decrypt \\\n--ciphertext-blob fileb://\u0026lt;(echo \u0026quot;encryptedBase64EncodedString\u0026quot; | base64 --decode)\n--output text \\\n--query Plaintext | base64 --decode\u003c/code\u003e\u003c/pre\u003e\n","frontmatter":"title: KMS Encryption and Decryption\ndescription: Encrypt and decrypt secure text, passwords and keys using AWS KMS service using CLI"}},{"location":"/aws/iam/instance-profile/","markdown":{"attributes":{"title":"IAM instance profile","description":"Role of Instance profile in EC2 application access management and IAM Role containment"},"body":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003eUsing the console, when we create IAM Role, an instance profile is automatically created with same name as that of the role.\u003c/li\u003e\n\u003cli\u003eRelation from instance profile to IAM role is one to one but the reverse is one to many i.e. only one role can be added to an instance profile but same role can be part of many instance profiles.\u003c/li\u003e\n\u003cli\u003eFrom instance metadata, security credentials can be retrieved from the path \u003ccode\u003eiam/security-credentials/\u0026lt;role_name\u0026gt;\u003c/code\u003e. So the application will get access to all the resources and actions allowed for the role.\u003c/li\u003e\n\u003cli\u003eAccording to AWS Documentation, instance profile is a container for IAM role to pass role information from AWS to EC2 after boot because the applications within EC2 machines run within a VM abstraction / enclosure.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"temporary-security-credentials\"\u003eTemporary Security Credentials\u003c/h2\u003e\n\u003cp\u003eThe temporary credentials can be obtained:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003efor AWS CLI, we can use roles for EC2\u003c/li\u003e\n\u003cli\u003eor for SDKs, use AWS STS API - \u003ca href=\"https://sts.amazonaws.com\"\u003eAWS Identity \u0026amp; Access Management - Amazon Web Services\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"curl\"\u003eCurl\u003c/h3\u003e\n\u003cp\u003eUsing curl, if we hit \u003ccode\u003ehttp://169.254.169.254/latest/meta-data/iam/security-credentials/\u0026lt;role_name\u0026gt;\u003c/code\u003e, we will obtain a JSON with following structure:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-json\"\u003e{\n  \u0026quot;Code\u0026quot; : \u0026quot;Success\u0026quot;,\n  \u0026quot;LastUpdated\u0026quot; : \u0026quot;2020-01-02T10:31:04Z\u0026quot;,\n  \u0026quot;Type\u0026quot; : \u0026quot;AWS-HMAC\u0026quot;,\n  \u0026quot;AccessKeyId\u0026quot; : \u0026quot;XXXXXXXXXXXXXXXXXX\u0026quot;,\n  \u0026quot;SecretAccessKey\u0026quot; : \u0026quot;xxxxxxxxxxxxxxxxxxxxxxxxx\u0026quot;,\n  \u0026quot;Token\u0026quot; : \u0026quot;xxxxxxxxxxxxxxxxxxxxxxxxxx==\u0026quot;,\n  \u0026quot;Expiration\u0026quot; : \u0026quot;2020-01-02T16:35:14Z\u0026quot;\n}\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eusing the above values we can set the following global variables:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-bash\"\u003eexport AWS_ACCESS_KEY_ID=\u0026quot;XXXXXXXXXXXXXXXXXX\u0026quot;\nexport AWS_SECRET_ACCESS_KEY=\u0026quot;xxxxxxxxxxxxxxxxxxxxxxxxx\u0026quot;\nexpoert AWS_SESSION_TOKEN=\u0026quot;xxxxxxxxxxxxxxxxxxxxxxxxxx==\u0026quot;\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eNow, we are ready use the AWS CLI or SDK.\u003c/p\u003e\n","frontmatter":"title: IAM instance profile\ndescription: Role of Instance profile in EC2 application access management and IAM Role containment"}},{"location":"/aws/dynamodb/","markdown":{"attributes":{"title":"DynamoDB Introduction - AWS"},"body":"\u003ch1 id=\"dynamodb\"\u003eDynamoDB\u003c/h1\u003e\n\u003ch2 id=\"theory---behind-the-time\"\u003eTheory - behind the time\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eStrong consistency model - RDBMS, bcz one change in table reflects everywhere.\u003c/li\u003e\n\u003cli\u003eTo achieve speed geographically, user needs to write consistently to all DBs in world -\u0026gt; slow.\u003c/li\u003e\n\u003cli\u003eAt large scale, data were denormalized for reducing join cost. Only \u003cul\u003e\n\u003cli\u003e10% of queries are join. \u003c/li\u003e\n\u003cli\u003e70% are on primary key.\u003c/li\u003e\n\u003cli\u003e20% operate on single returned value.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eConsistency is important for financial sectors. But speed and availability is more important than consistency in other sectors, which is gained by compromising the latter -\u0026gt; eventual consistency model.\u003c/li\u003e\n\u003cli\u003eConsistent Hashing to spread rows across nodes for infinite scaling.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"expression\"\u003eExpression\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eConditional - conditional manipulation of item\u003c/li\u003e\n\u003cli\u003eProjection\u003c/li\u003e\n\u003cli\u003eUpdate\u003c/li\u003e\n\u003cli\u003eKey condition - query table with composite key and limit selected item\u003c/li\u003e\n\u003cli\u003efilter - reduce resultset\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"options\"\u003eOptions\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003econdition-expression\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eexpression-attribute-names\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eexpression-attribute-values\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ekey\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eupdate-expression\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"condition-expression-function-list\"\u003e\u003ccode\u003econdition-expression\u003c/code\u003e function list\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003eattribute_exists\u003c/li\u003e\n\u003cli\u003eattribute_not_exists\u003c/li\u003e\n\u003cli\u003eattribute_type\u003c/li\u003e\n\u003cli\u003ebegins_with\u003c/li\u003e\n\u003cli\u003econtains\u003c/li\u003e\n\u003cli\u003esize\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eHASH key supports only equal comparison operations\u003c/p\u003e\n\u003ch4 id=\"range-key-operations\"\u003eRANGE key operations\u003c/h4\u003e\n\u003cp\u003eThese expressions are valid only on RANGE and secondary indexes, not on HASH keys\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eBETWEEN AND\u003c/li\u003e\n\u003cli\u003erelational operators\u003c/li\u003e\n\u003cli\u003eBEGINS_WITH\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"update-expression-clauses\"\u003e\u003ccode\u003eupdate-expression\u003c/code\u003e clauses\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eSET\u003c/code\u003e - add or modify attr\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eREMOVE\u003c/code\u003e - remove attr\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eADD\u003c/code\u003e - increment/decrement number/set\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eDELETE\u003c/code\u003e - remove item from set\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch4 id=\"reason-for-using-expression-attribute-names\"\u003eReason for using \u003ccode\u003eexpression-attribute-names\u003c/code\u003e\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://docs.aws.amazon.com/amazondynamodb/latest/developerguide/ReservedWords.html\"\u003eReserved Words in DynamoDB - Amazon DynamoDB\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003econtains dot - to access nested items\u003c/li\u003e\n\u003cli\u003ename begins with number\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"multi-item-actions\"\u003eMulti-item actions\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003ecannot use the UpdateItem API call with a BatchWriteItem request\u003c/li\u003e\n\u003cli\u003ecannot specify conditions for your Put and Delete operations \u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ekey-condition-expression\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eselect\u003c/code\u003e -\u0026gt; \u003ccode\u003e--select COUNT\u003c/code\u003e to return just no of elements\u003c/li\u003e\n\u003cli\u003eparallel scan on \u003ccode\u003esegments\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"secondary-index\"\u003eSecondary index\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003esparse index (item with missing attribute dropped in indexing)\u003ch3 id=\"lsi\"\u003eLSI\u003c/h3\u003e\n\u003c/li\u003e\n\u003cli\u003eonly on composite key\u003c/li\u003e\n\u003cli\u003eonly during creation time\u003c/li\u003e\n\u003cli\u003ecan choose strong vs eventual consistency\u003ch3 id=\"gsi\"\u003eGSI\u003c/h3\u003e\n\u003c/li\u003e\n\u003cli\u003eseparate throughtput\u003c/li\u003e\n\u003cli\u003eeventual consistency\u003c/li\u003e\n\u003cli\u003eboth simple/complex schema\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"references\"\u003eReferences\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://t.co/OwhN4xzkSV\"\u003ehttps://www.youtube.com/watch?v=HaEPXoXVf2k\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf\"\u003eAmazon DynamoDB research paper\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.allthingsdistributed.com/2017/10/a-decade-of-dynamo.html\"\u003eA Decade of Dynamo: Powering the next wave of high-performance, internet-scale applications - All Things Distributed\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://en.wikipedia.org/wiki/Consistent_hashing\"\u003eConsistent hashing - Wikipedia\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n","frontmatter":"title: DynamoDB Introduction - AWS"}},{"location":"/aws/cloudformation/","markdown":{"attributes":{"title":"Cloudformation"},"body":"","frontmatter":"title: Cloudformation"}},{"location":"/aws/cloudformation/introduction-basics/","markdown":{"attributes":{"title":"Basics of AWS Cloudformation"},"body":"\u003ch1 id=\"introduction\"\u003eIntroduction\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eResources\u003c/code\u003e is mandatory\u003c/li\u003e\n\u003cli\u003eEach resource in \u003ccode\u003eResources\u003c/code\u003e is given a logical name which can be referenced in other parts of the template using \u003ccode\u003eFn::Ref\u003c/code\u003e of \u003ccode\u003e!Ref\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eResources\u003c/code\u003e declaration requires \u003ccode\u003eProperties\u003c/code\u003e attribute to specify the resource details.\u003c/li\u003e\n\u003cli\u003eWhen AWS CloudFormation creates the resource, it generates a physical name that is based on the combination of the logical name, the stack name, and a unique ID.\u003c/li\u003e\n\u003cli\u003ePseudo parameters are resolved by AWS CloudFormation when you create the stack.\u003c/li\u003e\n\u003cli\u003eBy default, the cfn-hup daemon runs every 15 minutes, so it may take up to 15 minutes for the application to change once the stack has been updated.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"cloudformation-built-in-functions\"\u003eCloudformation built in functions\u003c/h2\u003e\n\u003ch3 id=\"cookbook\"\u003eCookbook\u003c/h3\u003e\n\u003ch4 id=\"cross-reference\"\u003eCross reference\u003c/h4\u003e\n\u003cp\u003eSay, we have a S3 resource with name \u003ccode\u003eRawDataStorage\u003c/code\u003e and we output the bucket\u0026#39;s name. We can get it from some other resource defined in the template as:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e!GetAtt RawDataStorage.Outputs.BucketName\u003c/code\u003e\u003c/pre\u003e","frontmatter":"title: Basics of AWS Cloudformation"}},{"location":"/aws/case-study/","markdown":{"attributes":{"title":"AWS Case studies"},"body":"","frontmatter":"title: AWS Case studies"}},{"location":"/aws/case-study/node-expressjs-s3-integration/","markdown":{"attributes":{"title":"Node ExpressJS and S3 Integration","description":"Basic code snippet for pushing data from a ExpressJS POST call to AWS S3 bucket"},"body":"\u003cpre\u003e\u003ccode class=\"language-javascript\"\u003econst express = require(\u0026#39;express\u0026#39;);\nconst AWS = require(\u0026#39;aws-sdk\u0026#39;);\n\nAWS.config.update({\n    accessKeyId: \u0026#39;xxxxxxxxxx\u0026#39;,\n    secretAccessKey: \u0026#39;XXXXXXXXXXXXXXXXX\u0026#39;,\n    region: \u0026#39;us-east-1\u0026#39;\n});\nconst s3 = new AWS.S3();\nconst PORT = parseInt(process.env.PORT, 10) || 3000;\nconst app = express();\napp.use(express.json());\n\napp.get(\u0026#39;/list-objects\u0026#39;, (req, res) =\u0026gt; {\n    s3.listObjects({\n        Bucket: \u0026#39;bucket-name\u0026#39;\n    }, (err, data) =\u0026gt; {\n        if (err) {\n            res.status(400).send(err);\n        } else {\n            res.status(200).send(\n                JSON.stringify(data, null, 4)\n            );\n        }\n    });\n});\n\napp.post(\u0026#39;/push-object\u0026#39;, (req, res) =\u0026gt; {\n    const fileStamp = Date.now().toString();\n    const data = JSON.stringify(req.body);\n    if (data) {\n        s3.upload({\n            Bucket: \u0026#39;bucket-name\u0026#39;,\n            Key: fileStamp,\n            Body: \n        }, (err, data) =\u0026gt; {\n            if (err) {\n                res.status(err.statusCode).send(err);\n            } else {\n                res.status(200).send(\u0026#39;Ok\u0026#39;);\n            }\n        });\n    } else {\n        res.status(400).send(\u0026#39;Empty body\u0026#39;);\n    }\n});\n\napp.listen(PORT, () =\u0026gt; console.log(`Started at Port: ${PORT}`));\n\u003c/code\u003e\u003c/pre\u003e\n","frontmatter":"title: Node ExpressJS and S3 Integration\ndescription: Basic code snippet for pushing data from a ExpressJS POST call to AWS S3 bucket"}},{"location":"/aws/EKS/","markdown":{"attributes":{"title":"EKS Introduction"},"body":"\u003ch2 id=\"gotchas\"\u003eGotchas\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eWhen creating a role for associating with a EKS cluster using console, Instance profile will not be created\u003cblockquote\u003e\n\u003cp\u003eThe console does not create an instance profile for a role that is not associated with Amazon EC2.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003c/li\u003e\n\u003cli\u003eRef:- \u003ca href=\"https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2_instance-profiles.html\"\u003ehttps://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_switch-role-ec2_instance-profiles.html\u003c/a\u003e*\u003c/li\u003e\n\u003c/ul\u003e\n","frontmatter":"title: EKS Introduction"}},{"location":"/aws/EFS/","markdown":{"attributes":{"title":"EFS Introduction - AWS"},"body":"\u003ch1 id=\"efs\"\u003eEFS\u003c/h1\u003e\n\u003ch4 id=\"gotchas\"\u003eGotchas\u003c/h4\u003e\n\u003cul\u003e\n\u003cli\u003efor mounting an EFS in an EC2, they should be having same security group.\u003c/li\u003e\n\u003cli\u003eCheck if NFS inbound port 2049 is needed to be in open\u003c/li\u003e\n\u003c/ul\u003e\n","frontmatter":"title: EFS Introduction - AWS"}},{"location":"/aws/Cloudtrail/","markdown":{"attributes":{"title":"Cloudtrail Introduction - AWS"},"body":"\u003ch1 id=\"cloudtrail\"\u003eCloudTrail\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003emonitoring APA activity from\u003cul\u003e\n\u003cli\u003econsole\u003c/li\u003e\n\u003cli\u003eaws-cli\u003c/li\u003e\n\u003cli\u003eSDKs\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eExample when data events logging for s3 are enable in cloudTrail, cloudWatch event rule is used to trigger lambda for authorization\u003c/li\u003e\n\u003cli\u003eWhen certain APA activity causes outage, we can view a list of those activities in cloutTrail and revert them\u003c/li\u003e\n\u003c/ul\u003e\n","frontmatter":"title: Cloudtrail Introduction - AWS"}},{"location":"/SEO/","markdown":{"attributes":{"title":"Search Engine Optimization - SEO","description":"Basics introduction points for search engine optimization like meta information and other important aspects"},"body":"\u003ch2 id=\"meta-data\"\u003eMeta Data\u003c/h2\u003e\n\u003ch4 id=\"title\"\u003eTitle\u003c/h4\u003e\n\u003cpre\u003e\u003ccode\u003elimits: 55 characters\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003ccode\u003e\u0026lt;title\u0026gt;\u003c/code\u003e is very important for SEO which is the top line displayed by search engines in SERP (Search Engine Results Page).\u003c/p\u003e\n\u003ch4 id=\"description\"\u003eDescription\u003c/h4\u003e\n\u003cpre\u003e\u003ccode\u003elimits: 150 - 165 characters\u003c/code\u003e\u003c/pre\u003e\u003ch4 id=\"keywords\"\u003eKeywords\u003c/h4\u003e\n","frontmatter":"title: Search Engine Optimization - SEO\ndescription: Basics introduction points for search engine optimization like meta information and other important aspects"}},{"location":"/SEO/reference-sites/","markdown":{"attributes":{"title":"SEO - Reference sites"},"body":"\u003ch1 id=\"reference-sites-for-seo\"\u003eReference Sites for SEO\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.impactbnd.com/blog/seo-statistics\"\u003ehttps://www.impactbnd.com/blog/seo-statistics\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://seotribunal.com/blog/stats-to-understand-seo/\"\u003ehttps://seotribunal.com/blog/stats-to-understand-seo/\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://unbounce.com/landing-pages/7-page-speed-stats-for-marketers/\"\u003ehttps://unbounce.com/landing-pages/7-page-speed-stats-for-marketers/\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n","frontmatter":"title: SEO - Reference sites"}},{"location":"/IDE/","markdown":{"attributes":{"title":"Code Editors / IDEs"},"body":"","frontmatter":"title: Code Editors / IDEs"}},{"location":"/IDE/VSCode/","markdown":{"attributes":{"title":"Microsoft Visual Code - VS Code"},"body":"","frontmatter":"title: Microsoft Visual Code - VS Code"}},{"location":"/IDE/VSCode/Debugging/","markdown":{"attributes":{"title":"VSCode Debugging"},"body":"\u003cp\u003eVS Code Debugging\u003c/p\u003e\n\u003ch2 id=\"launchjson-configurations\"\u003e\u003ccode\u003elaunch.json\u003c/code\u003e configurations\u003c/h2\u003e\n\u003ch3 id=\"cwd\"\u003e\u003ccode\u003ecwd\u003c/code\u003e\u003c/h3\u003e\n\u003cp\u003eWhen we refer any configure files, it is searched in the \u003ccode\u003eworkspaceRoot\u003c/code\u003e unless we set \u003ccode\u003ecwd\u003c/code\u003e. \u003ca href=\"\"\u003eReference\u003c/a\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-json\"\u003e{\n    \u0026quot;version\u0026quot;: \u0026quot;0.2.0\u0026quot;,\n    \u0026quot;configurations\u0026quot;: [\n        {\n            \u0026quot;type\u0026quot;: \u0026quot;node\u0026quot;,\n            \u0026quot;request\u0026quot;: \u0026quot;launch\u0026quot;,\n            \u0026quot;name\u0026quot;: \u0026quot;programName\u0026quot;,\n            \u0026quot;cwd\u0026quot;: \u0026quot;${workspaceRoot}/packages\u0026quot;,\n            \u0026quot;program\u0026quot;: \u0026quot;${workspaceFolder}/src/index.js\u0026quot;,\n            \u0026quot;env\u0026quot;: {\n                \u0026quot;NODE_CONFIG_ENV\u0026quot;: \u0026quot;dev\u0026quot;\n            },\n            \u0026quot;outFiles\u0026quot;: [\u0026quot;${cwd}/dist/**/*.js\u0026quot;],\n            \u0026quot;sourceMaps\u0026quot;: true,\n            \u0026quot;smartStep\u0026quot;: true  \n        }\n    ]\n}\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id=\"args\"\u003eargs\u003c/h3\u003e\n\u003cp\u003eWe can specify array of CLI arguments as an array of string. The arguments can include command flags as well.\u003c/p\u003e\n\u003ch2 id=\"different-debugging-scenarios\"\u003eDifferent debugging scenarios\u003c/h2\u003e\n\u003ch3 id=\"setting-environment-variables\"\u003eSetting Environment variables\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-json\"\u003e{\n    \u0026quot;type\u0026quot;: \u0026quot;node\u0026quot;,\n    \u0026quot;request\u0026quot;: \u0026quot;launch\u0026quot;,\n    \u0026quot;name\u0026quot;: \u0026quot;module1\u0026quot;,\n    \u0026quot;restart\u0026quot;: true,\n    \u0026quot;console\u0026quot;: \u0026quot;integratedTerminal\u0026quot;,\n    \u0026quot;cwd\u0026quot;: \u0026quot;${workspaceRoot}/src\u0026quot;,\n    \u0026quot;program\u0026quot;: \u0026quot;${workspaceFolder}/src/index.js\u0026quot;,\n    \u0026quot;env\u0026quot;: {\n        \u0026quot;NODE_CONFIG_ENV\u0026quot;: \u0026quot;dev\u0026quot;\n    }\n}\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eHere, we are using npm package called \u003ccode\u003econfig\u003c/code\u003e, which expect the environment variable \u003ccode\u003eNODE_CONFIG_ENV\u003c/code\u003e to be set in order to load, say \u003ccode\u003edev.json\u003c/code\u003e, in this example\u003c/p\u003e\n\u003ch3 id=\"executing-process-monitoring-tools-like-pm2--nodemon\"\u003eExecuting process monitoring tools like pm2 / nodemon\u003c/h3\u003e\n\u003cpre\u003e\u003ccode class=\"language-json\"\u003e{\n    \u0026quot;type\u0026quot;: \u0026quot;node\u0026quot;,\n    \u0026quot;request\u0026quot;: \u0026quot;launch\u0026quot;,\n    \u0026quot;name\u0026quot;: \u0026quot;module1\u0026quot;,\n    \u0026quot;runtimeExecutable\u0026quot;: \u0026quot;nodemon\u0026quot;,\n    \u0026quot;restart\u0026quot;: true,\n    \u0026quot;console\u0026quot;: \u0026quot;integratedTerminal\u0026quot;,\n    \u0026quot;cwd\u0026quot;: \u0026quot;${workspaceRoot}/src\u0026quot;,\n    \u0026quot;program\u0026quot;: \u0026quot;${workspaceFolder}/src/index.js\u0026quot;,\n}\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eHere, the \u003ccode\u003eruntimeExecutable\u003c/code\u003e is used to launch the instance of the node script. Similarly other executables can be used for the same.\u003c/p\u003e\n\u003ch3 id=\"multi-module-debugging\"\u003eMulti-module debugging\u003c/h3\u003e\n\u003cp\u003eWhen we have setup like client-server or multi-repo managed by lerna, we can set the debug configurations for node apps as given below:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-json\"\u003e    \u0026quot;configurations\u0026quot;: [\n        {\n            \u0026quot;type\u0026quot;: \u0026quot;node\u0026quot;,\n            \u0026quot;request\u0026quot;: \u0026quot;launch\u0026quot;,\n            \u0026quot;name\u0026quot;: \u0026quot;module1\u0026quot;,\n            \u0026quot;restart\u0026quot;: true,\n            \u0026quot;console\u0026quot;: \u0026quot;integratedTerminal\u0026quot;,\n            \u0026quot;cwd\u0026quot;: \u0026quot;${workspaceRoot}/packages/abc\u0026quot;,\n            \u0026quot;program\u0026quot;: \u0026quot;${workspaceFolder}/packages/abc/src/index.js\u0026quot;,\n            \u0026quot;sourceMaps\u0026quot;: true\n        }, \n        {\n            \u0026quot;type\u0026quot;: \u0026quot;node\u0026quot;,\n            \u0026quot;request\u0026quot;: \u0026quot;launch\u0026quot;,\n            \u0026quot;name\u0026quot;: \u0026quot;module2\u0026quot;,\n            \u0026quot;cwd\u0026quot;: \u0026quot;${workspaceRoot}/packages/def\u0026quot;,\n            \u0026quot;program\u0026quot;: \u0026quot;${workspaceFolder}/packages/def/src/index.js\u0026quot;,\n            \u0026quot;args\u0026quot;: [\u0026quot;arg1\u0026quot;],\n            \u0026quot;sourceMaps\u0026quot;: true\n        }\n    ]\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eHere, we are mentioning the \u003ccode\u003ecwd\u003c/code\u003e (current working directory) of each of the repo in the workspace.\u003c/p\u003e\n\u003cp\u003eIn the scenario where we want to launch more than one module\u0026#39;s debugging session, the \u003ccode\u003elaunch.json\u003c/code\u003e can be configured as follows:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-json\"\u003e\u0026quot;compounds\u0026quot;: [\n        {\n            \u0026quot;name\u0026quot;: \u0026quot;abc/def\u0026quot;,\n            \u0026quot;configurations\u0026quot;: [\n                \u0026quot;module1\u0026quot;,\n                \u0026quot;module2\u0026quot;\n            ]\n        }\n    ]\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eBut in the above scenario, where one module depends on the launch of the next, it is desirable to have some delay which will give sufficient time to launch the former. This can be done by using \u003ccode\u003esleep\u003c/code\u003e command while defining \u003ccode\u003etasks\u003c/code\u003e.\u003c/p\u003e\n\u003cp\u003eBoth the \u003ccode\u003etasks.json\u003c/code\u003e and \u003ccode\u003elaunch.json\u003c/code\u003e is attached below for reference:\u003c/p\u003e\n\u003cpre\u003e\u003ccode class=\"language-json\"\u003e{\n    \u0026quot;version\u0026quot;: \u0026quot;2.0.0\u0026quot;,\n    \u0026quot;tasks\u0026quot;: [\n        {\n            \u0026quot;label\u0026quot;: \u0026quot;Sleep\u0026quot;,\n            \u0026quot;type\u0026quot;: \u0026quot;shell\u0026quot;,\n            \u0026quot;command\u0026quot;: \u0026quot;sleep 3\u0026quot;,\n            \u0026quot;windows\u0026quot;: {\n                \u0026quot;command\u0026quot;: \u0026quot;ping 127.0.0.1 -n 6 \u0026gt; nul\u0026quot;\n            },\n            \u0026quot;group\u0026quot;: \u0026quot;none\u0026quot;,\n            \u0026quot;presentation\u0026quot;: {\n                \u0026quot;reveal\u0026quot;: \u0026quot;silent\u0026quot;,\n                \u0026quot;panel\u0026quot;: \u0026quot;new\u0026quot;\n            }\n        }\n    ]\n}\u003c/code\u003e\u003c/pre\u003e\n\u003cpre\u003e\u003ccode class=\"language-json\"\u003e{\n    \u0026quot;version\u0026quot;: \u0026quot;0.2.0\u0026quot;,\n    \u0026quot;configurations\u0026quot;: [\n        {\n            \u0026quot;type\u0026quot;: \u0026quot;node\u0026quot;,\n            \u0026quot;request\u0026quot;: \u0026quot;launch\u0026quot;,\n            \u0026quot;name\u0026quot;: \u0026quot;module3\u0026quot;,\n            \u0026quot;cwd\u0026quot;: \u0026quot;${workspaceRoot}/packages/module3\u0026quot;,\n            \u0026quot;program\u0026quot;: \u0026quot;${workspaceFolder}/packages/module3/src/index.js\u0026quot;,\n            \u0026quot;env\u0026quot;: {\n                \u0026quot;NODE_CONFIG_ENV\u0026quot;: \u0026quot;dev\u0026quot;\n            },\n            \u0026quot;sourceMaps\u0026quot;: true\n        },\n        {\n            \u0026quot;type\u0026quot;: \u0026quot;node\u0026quot;,\n            \u0026quot;request\u0026quot;: \u0026quot;launch\u0026quot;,\n            \u0026quot;name\u0026quot;: \u0026quot;module1\u0026quot;,\n            \u0026quot;runtimeExecutable\u0026quot;: \u0026quot;nodemon\u0026quot;,\n            \u0026quot;restart\u0026quot;: true,\n            \u0026quot;console\u0026quot;: \u0026quot;integratedTerminal\u0026quot;,\n            \u0026quot;cwd\u0026quot;: \u0026quot;${workspaceRoot}/packages/module1\u0026quot;,\n            \u0026quot;program\u0026quot;: \u0026quot;${workspaceFolder}/packages/module1/src/index.js\u0026quot;,\n            \u0026quot;env\u0026quot;: {\n                \u0026quot;NODE_CONFIG_ENV\u0026quot;: \u0026quot;dev\u0026quot;\n            },\n            \u0026quot;sourceMaps\u0026quot;: true\n        }, \n        {\n            \u0026quot;type\u0026quot;: \u0026quot;node\u0026quot;,\n            \u0026quot;request\u0026quot;: \u0026quot;launch\u0026quot;,\n            \u0026quot;name\u0026quot;: \u0026quot;module2\u0026quot;,\n            \u0026quot;cwd\u0026quot;: \u0026quot;${workspaceRoot}/packages/module2\u0026quot;,\n            \u0026quot;program\u0026quot;: \u0026quot;${workspaceFolder}/packages/module2/src/index.js\u0026quot;,\n            \u0026quot;env\u0026quot;: {\n                \u0026quot;NODE_CONFIG_ENV\u0026quot;: \u0026quot;dev\u0026quot;\n            },\n            \u0026quot;preLaunchTask\u0026quot;: \u0026quot;Sleep\u0026quot;,\n            \u0026quot;sourceMaps\u0026quot;: true\n        }\n    ],\n    \u0026quot;compounds\u0026quot;: [\n        {\n            \u0026quot;name\u0026quot;: \u0026quot;module1/module2\u0026quot;,\n            \u0026quot;configurations\u0026quot;: [\n                \u0026quot;module1\u0026quot;,\n                \u0026quot;module2\u0026quot;\n            ]\n        }\n    ]\n}\u003c/code\u003e\u003c/pre\u003e\n","frontmatter":"title: VSCode Debugging"}},{"location":"/Crypto/","markdown":{"attributes":{"title":"Cryptography"},"body":"","frontmatter":"title: Cryptography"}},{"location":"/Crypto/public-private-keys/","markdown":{"attributes":{"title":"Public Private keys - Cryptography / Security"},"body":"\u003ch1 id=\"public-private-keys\"\u003ePublic Private keys\u003c/h1\u003e\n\u003cp\u003eWe need to generate public and private key to ssh into remote machines and for authentication/authorization\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003essh-keygen\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eWhen automating servers, we need to add IP address of remote servers in known hosts\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003essh-keyscan github.com \u0026gt;\u0026gt; ~/.ssh/known_hosts\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eWhen we have got multiple github accounts, we can use one pub in for one account only. We need to generate another pair of pub-private key pair to add to another github account. We need to add the newly generated file name/location\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003essh-add /path/to/new/rsa/file\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eWhen we want to test from CLI that which github username is active:\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003essh -T git@github.com\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eWhen we want to specifically muse a particular RSA key,\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003essh -i /file/to/private_key\u003c/code\u003e\u003c/pre\u003e","frontmatter":"title: Public Private keys - Cryptography / Security"}}],"buildId":"c_R24dhd8hjJEXWGIGUO-","nextExport":true}</script><script nomodule="" src="/_next/static/runtime/polyfills-5fa5b8189f4681d353e9.js"></script><script async="" data-next-page="/articleHomepage" src="/_next/static/c_R24dhd8hjJEXWGIGUO-/pages/articleHomepage.js"></script><script async="" data-next-page="/_app" src="/_next/static/c_R24dhd8hjJEXWGIGUO-/pages/_app.js"></script><script src="/_next/static/runtime/webpack-9369c5c69dbf6d4912cb.js" async=""></script><script src="/_next/static/chunks/commons.b6dc333151af4a74b05a.js" async=""></script><script src="/_next/static/runtime/main-5b3d9dcbbf35909ee5a1.js" async=""></script></body></html>